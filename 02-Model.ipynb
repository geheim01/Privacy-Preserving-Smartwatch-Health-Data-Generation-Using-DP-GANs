{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/nils/miniconda3/envs/cgan_clean/lib/python3.8/site-packages (2.0.1)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /Users/nils/miniconda3/envs/cgan_clean/lib/python3.8/site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/nils/miniconda3/envs/cgan_clean/lib/python3.8/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/nils/miniconda3/envs/cgan_clean/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/nils/miniconda3/envs/cgan_clean/lib/python3.8/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/nils/miniconda3/envs/cgan_clean/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in /Users/nils/miniconda3/envs/cgan_clean/lib/python3.8/site-packages (3.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/nils/miniconda3/envs/cgan_clean/lib/python3.8/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.20 in /Users/nils/miniconda3/envs/cgan_clean/lib/python3.8/site-packages (from matplotlib) (1.23.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/nils/miniconda3/envs/cgan_clean/lib/python3.8/site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/nils/miniconda3/envs/cgan_clean/lib/python3.8/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/nils/miniconda3/envs/cgan_clean/lib/python3.8/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/nils/miniconda3/envs/cgan_clean/lib/python3.8/site-packages (from matplotlib) (5.12.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/nils/miniconda3/envs/cgan_clean/lib/python3.8/site-packages (from matplotlib) (9.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/nils/miniconda3/envs/cgan_clean/lib/python3.8/site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/nils/miniconda3/envs/cgan_clean/lib/python3.8/site-packages (from matplotlib) (4.39.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/nils/miniconda3/envs/cgan_clean/lib/python3.8/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/nils/miniconda3/envs/cgan_clean/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.15.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/nils/miniconda3/envs/cgan_clean/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: plotly in /Users/nils/miniconda3/envs/cgan_clean/lib/python3.8/site-packages (5.14.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Users/nils/miniconda3/envs/cgan_clean/lib/python3.8/site-packages (from plotly) (8.2.2)\n",
      "Requirement already satisfied: packaging in /Users/nils/miniconda3/envs/cgan_clean/lib/python3.8/site-packages (from plotly) (23.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "\n",
    "import tensorflow_privacy\n",
    "from tensorflow_privacy.privacy.analysis import compute_dp_sgd_privacy\n",
    "from tensorflow_privacy.privacy.optimizers import dp_optimizer_keras\n",
    "\n",
    "from synthesizers.cgan.model import ConditionalGAN, GANMonitor\n",
    "from synthesizers.preprocessing.wesad import Subject, WESADDataset\n",
    "from synthesizers.utils.training import data_split, buildDataCTST, generate_and_plot_data, synthetic_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'data/wesad/wesad_preprocessed_1hz.csv'\n",
    "SAMPLING_RATE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_PATH, index_col=0)\n",
    "df_label = df['label']\n",
    "df_stress = df[df['label']==1]\n",
    "df_no_stress = df[df['label']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, label_trainX = WESADDataset.create_windows(df, 1)\n",
    "mos, _ = WESADDataset.create_windows(df_stress, SAMPLING_RATE)\n",
    "non_mos, _ = WESADDataset.create_windows(df_no_stress,SAMPLING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 60, 7)\n",
      "(34, 60, 7)\n",
      "(308, 60, 7)\n",
      "(78, 60, 7)\n"
     ]
    }
   ],
   "source": [
    "num_split = 0.8\n",
    "trainmos, testmos = data_split(mos, num_split)\n",
    "trainnomos, testnomos = data_split(non_mos, num_split)\n",
    "\n",
    "print(trainmos.shape)\n",
    "print(testmos.shape)\n",
    "print(trainnomos.shape)\n",
    "print(testnomos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=(TensorSpec(shape=(None, 60, 7), dtype=tf.float64, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training Hyperparameters\n",
    "NUM_FEATURES = trainX.shape[2]\n",
    "SEQ_LENGTH = 60\n",
    "LATENT_DIM = SEQ_LENGTH\n",
    "BATCH_SIZE = 32\n",
    "HIDDEN_UNITS = 16\n",
    "EPOCHS = 10\n",
    "\n",
    "# load dataset into tf dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((trainX, label_trainX))\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(BATCH_SIZE)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomTrainMos = tf.random.normal(shape=(trainmos.shape[0], LATENT_DIM))\n",
    "randomTrainNoMos = tf.random.normal(shape=(trainnomos.shape[0], LATENT_DIM))\n",
    "randomTestMos = tf.random.normal(shape=(testmos.shape[0], LATENT_DIM))\n",
    "randomTestNoMos = tf.random.normal(shape=(testnomos.shape[0], LATENT_DIM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.DPOptimizerClass` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.DPOptimizerClass`.\n"
     ]
    }
   ],
   "source": [
    "l2_norm_clip = 1.5\n",
    "noise_multiplier = 1.3\n",
    "num_microbatches = 250\n",
    "learning_rate = 0.25\n",
    "\n",
    "optimizer = tensorflow_privacy.DPKerasSGDOptimizer(\n",
    "    l2_norm_clip=l2_norm_clip,\n",
    "    noise_multiplier=noise_multiplier,\n",
    "    num_microbatches=num_microbatches,\n",
    "    learning_rate=learning_rate\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "in user code:\n\n    File \"/Users/nils/miniconda3/envs/cgan_clean/lib/python3.8/site-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/nils/miniconda3/envs/cgan_clean/lib/python3.8/site-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/nils/miniconda3/envs/cgan_clean/lib/python3.8/site-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/nils/thesis/Data_Generation/synthesizers/cgan/model.py\", line 216, in train_step\n        self.d_optimizer.apply_gradients(\n    File \"/Users/nils/miniconda3/envs/cgan_clean/lib/python3.8/site-packages/tensorflow_privacy/privacy/optimizers/dp_optimizer_keras.py\", line 230, in apply_gradients\n        assert self._was_dp_gradients_called, (\n\n    AssertionError: Neither _compute_gradients() or get_gradients() on the differentially private optimizer was called. This means the training is not differentially private. It may be the case that you need to upgrade to TF 2.4 or higher to use this particular optimizer.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 22\u001b[0m\n\u001b[1;32m      1\u001b[0m cond_gan \u001b[39m=\u001b[39m ConditionalGAN(\n\u001b[1;32m      2\u001b[0m     num_features\u001b[39m=\u001b[39mNUM_FEATURES,\n\u001b[1;32m      3\u001b[0m     seq_length\u001b[39m=\u001b[39mSEQ_LENGTH,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     )\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     16\u001b[0m cond_gan\u001b[39m.\u001b[39mcompile(\n\u001b[1;32m     17\u001b[0m     d_optimizer\u001b[39m=\u001b[39m optimizer, \u001b[39m#Adam(learning_rate=0.0002, beta_1=0.5), #optimizer\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     g_optimizer\u001b[39m=\u001b[39moptimizer, \u001b[39m#Adam(learning_rate=0.0002, beta_1=0.5), #optimizer\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     loss_fn\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mBinaryCrossentropy(from_logits\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m),\n\u001b[1;32m     20\u001b[0m )\n\u001b[0;32m---> 22\u001b[0m history \u001b[39m=\u001b[39m cond_gan\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     23\u001b[0m     dataset,\n\u001b[1;32m     24\u001b[0m     epochs\u001b[39m=\u001b[39;49mEPOCHS,\n\u001b[1;32m     25\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[\n\u001b[1;32m     26\u001b[0m         GANMonitor(\n\u001b[1;32m     27\u001b[0m             trainmos,\n\u001b[1;32m     28\u001b[0m             trainnomos,\n\u001b[1;32m     29\u001b[0m             testmos,\n\u001b[1;32m     30\u001b[0m             testnomos,\n\u001b[1;32m     31\u001b[0m             randomTrainMos,\n\u001b[1;32m     32\u001b[0m             randomTrainNoMos,\n\u001b[1;32m     33\u001b[0m             randomTestMos,\n\u001b[1;32m     34\u001b[0m             randomTestNoMos,\n\u001b[1;32m     35\u001b[0m             num_seq\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,\n\u001b[1;32m     36\u001b[0m             seq_length\u001b[39m=\u001b[39;49mSEQ_LENGTH,\n\u001b[1;32m     37\u001b[0m             num_features\u001b[39m=\u001b[39;49mNUM_FEATURES,\n\u001b[1;32m     38\u001b[0m         )\n\u001b[1;32m     39\u001b[0m     ],\n\u001b[1;32m     40\u001b[0m )\n\u001b[1;32m     42\u001b[0m cond_gan\u001b[39m.\u001b[39mgenerator\u001b[39m.\u001b[39msave(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmodels/cond_generator_\u001b[39m\u001b[39m{\u001b[39;00mEPOCHS\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     43\u001b[0m cond_gan\u001b[39m.\u001b[39mdiscriminator\u001b[39m.\u001b[39msave(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmodels/cond_discriminator_\u001b[39m\u001b[39m{\u001b[39;00mEPOCHS\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/cgan_clean/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/3k/sjklqbj91hg9fgb_kbwpy1p40000gn/T/__autograph_generated_file5w0lricu.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/thesis/Data_Generation/synthesizers/cgan/model.py:216\u001b[0m, in \u001b[0;36mConditionalGAN.train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    214\u001b[0m     d_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_fn(labels, predictions)\n\u001b[1;32m    215\u001b[0m grads \u001b[39m=\u001b[39m tape\u001b[39m.\u001b[39mgradient(d_loss, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdiscriminator\u001b[39m.\u001b[39mtrainable_weights)\n\u001b[0;32m--> 216\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49md_optimizer\u001b[39m.\u001b[39;49mapply_gradients(\n\u001b[1;32m    217\u001b[0m     \u001b[39mzip\u001b[39;49m(grads, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdiscriminator\u001b[39m.\u001b[39;49mtrainable_weights)\n\u001b[1;32m    218\u001b[0m )\n\u001b[1;32m    220\u001b[0m \u001b[39m# Sample random points in the latent space.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m random_latent_vectors \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mnormal(\n\u001b[1;32m    223\u001b[0m     shape\u001b[39m=\u001b[39m(batch_size, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlatent_dim), dtype\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mdtypes\u001b[39m.\u001b[39mfloat64\n\u001b[1;32m    224\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/cgan_clean/lib/python3.8/site-packages/tensorflow_privacy/privacy/optimizers/dp_optimizer_keras.py:230\u001b[0m, in \u001b[0;36mmake_keras_optimizer_class.<locals>.DPOptimizerClass.apply_gradients\u001b[0;34m(self, grads_and_vars, global_step, name)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_gradients\u001b[39m(\u001b[39mself\u001b[39m, grads_and_vars, global_step\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    229\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"DP-SGD version of base class method.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 230\u001b[0m   \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_was_dp_gradients_called, (\n\u001b[1;32m    231\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mNeither _compute_gradients() or get_gradients() on the \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    232\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mdifferentially private optimizer was called. This means the \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    233\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mtraining is not differentially private. It may be the case that \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    234\u001b[0m       \u001b[39m'\u001b[39m\u001b[39myou need to upgrade to TF 2.4 or higher to use this particular \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    235\u001b[0m       \u001b[39m'\u001b[39m\u001b[39moptimizer.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    236\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m(DPOptimizerClass,\n\u001b[1;32m    237\u001b[0m                \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mapply_gradients(grads_and_vars, global_step, name)\n",
      "\u001b[0;31mAssertionError\u001b[0m: in user code:\n\n    File \"/Users/nils/miniconda3/envs/cgan_clean/lib/python3.8/site-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/nils/miniconda3/envs/cgan_clean/lib/python3.8/site-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/nils/miniconda3/envs/cgan_clean/lib/python3.8/site-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/nils/thesis/Data_Generation/synthesizers/cgan/model.py\", line 216, in train_step\n        self.d_optimizer.apply_gradients(\n    File \"/Users/nils/miniconda3/envs/cgan_clean/lib/python3.8/site-packages/tensorflow_privacy/privacy/optimizers/dp_optimizer_keras.py\", line 230, in apply_gradients\n        assert self._was_dp_gradients_called, (\n\n    AssertionError: Neither _compute_gradients() or get_gradients() on the differentially private optimizer was called. This means the training is not differentially private. It may be the case that you need to upgrade to TF 2.4 or higher to use this particular optimizer.\n"
     ]
    }
   ],
   "source": [
    "cond_gan = ConditionalGAN(\n",
    "    num_features=NUM_FEATURES,\n",
    "    seq_length=SEQ_LENGTH,\n",
    "    latent_dim=LATENT_DIM,\n",
    "    discriminator=ConditionalGAN.conditional_discriminator(\n",
    "        seq_length=SEQ_LENGTH, \n",
    "        num_features=NUM_FEATURES), \n",
    "    generator=ConditionalGAN.conditional_generator(\n",
    "        hidden_units=HIDDEN_UNITS, \n",
    "        seq_length=SEQ_LENGTH, \n",
    "        latent_dim=LATENT_DIM,\n",
    "        num_features=NUM_FEATURES\n",
    "    )\n",
    ")\n",
    "\n",
    "cond_gan.compile(\n",
    "    d_optimizer= optimizer, #Adam(learning_rate=0.0002, beta_1=0.5), #optimizer\n",
    "    g_optimizer=optimizer, #Adam(learning_rate=0.0002, beta_1=0.5), #optimizer\n",
    "    loss_fn=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    ")\n",
    "\n",
    "history = cond_gan.fit(\n",
    "    dataset,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[\n",
    "        GANMonitor(\n",
    "            trainmos,\n",
    "            trainnomos,\n",
    "            testmos,\n",
    "            testnomos,\n",
    "            randomTrainMos,\n",
    "            randomTrainNoMos,\n",
    "            randomTestMos,\n",
    "            randomTestNoMos,\n",
    "            num_seq=50,\n",
    "            seq_length=SEQ_LENGTH,\n",
    "            num_features=NUM_FEATURES,\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "cond_gan.generator.save(f\"models/cond_generator_{EPOCHS}\")\n",
    "cond_gan.discriminator.save(f\"models/cond_discriminator_{EPOCHS}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cgan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
