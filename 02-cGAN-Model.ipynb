{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02: Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow_privacy.privacy.optimizers import dp_optimizer_vectorized\n",
    "from tensorflow_privacy.privacy.analysis import compute_dp_sgd_privacy\n",
    "from tensorflow_privacy.privacy.analysis.compute_noise_from_budget_lib import compute_noise\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "\n",
    "from synthesizers.cgan.model import (\n",
    "    ConditionalGAN, \n",
    "    GANMonitor\n",
    ")\n",
    "from synthesizers.preprocessing.wesad import (\n",
    "    WESADDataset, \n",
    "    LabelType\n",
    ")\n",
    "from synthesizers.utils.training import data_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLING_RATE = 1\n",
    "USE_SLIDING_WINDOWS = True\n",
    "\n",
    "# Training Hyperparameters\n",
    "DP_TRAINING = False\n",
    "NUM_FEATURES = 6\n",
    "SEQ_LENGTH = 60\n",
    "LATENT_DIM = SEQ_LENGTH\n",
    "BATCH_SIZE = 8\n",
    "HIDDEN_UNITS = 64\n",
    "EPOCHS = 10\n",
    "ACTIVATION = \"relu\"\n",
    "RANDOM_SEED = 42\n",
    "LEARNING_RATE = 0.0002\n",
    "LOSS_FN = \"binary_cross_entropy\"\n",
    "D_ARCHITECTURE = \"lstm\"\n",
    "LOSO_TRAINING_WITHOUT_SUBJECT = \"4\"\n",
    "\n",
    "# DP Training Hyperparameter\n",
    "L2_NORM_CLIP = 1.0\n",
    "NUM_MICROBATCHES = BATCH_SIZE\n",
    "DP_LEARNING_RATE = 1e-3\n",
    "DELTA = 1e-4\n",
    "\n",
    "\n",
    "# Define run config\n",
    "config = {\n",
    "    \"activation_function\": ACTIVATION,\n",
    "    \"hidden_units\": HIDDEN_UNITS,\n",
    "    \"epochs\": EPOCHS,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"random_seed\": RANDOM_SEED,\n",
    "    \"num_features\": NUM_FEATURES,\n",
    "    \"seq_length\": SEQ_LENGTH,\n",
    "    \"dp_training\": DP_TRAINING,\n",
    "    \"learning_rate\": LEARNING_RATE,\n",
    "    \"loss_function\": LOSS_FN,\n",
    "    \"d_architecture\": D_ARCHITECTURE,\n",
    "    \"use_sliding_windows\": USE_SLIDING_WINDOWS\n",
    "}\n",
    "\n",
    "if LOSO_TRAINING_WITHOUT_SUBJECT:\n",
    "    config[\"WESAD_WITHOUT_SUBJ\"] = LOSO_TRAINING_WITHOUT_SUBJECT\n",
    "\n",
    "if DP_TRAINING:\n",
    "    config[\"l2_norm_clip\"] = L2_NORM_CLIP\n",
    "    config[\"num_microbatches\"] = NUM_MICROBATCHES\n",
    "    config[\"dp_learning_rate\"] = DP_LEARNING_RATE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 60, 6)\n",
      "(64, 60, 6)\n",
      "(610, 60, 6)\n",
      "(153, 60, 6)\n"
     ]
    }
   ],
   "source": [
    "windows = np.load('data/wesad/wesad_windows.npy')\n",
    "labels = np.load('data/wesad/wesad_labels.npy')\n",
    "\n",
    "if USE_SLIDING_WINDOWS:\n",
    "    mos = windows[labels == 1]\n",
    "    non_mos = windows[labels == 0]\n",
    "else:\n",
    "    windows, labels = WESADDataset.create_windows(dataframe=df, samples_per_sec=1, label_type=LabelType.MOST_COMMON)\n",
    "    mos = windows[labels == 1]\n",
    "    non_mos = windows[labels == 0]\n",
    "\n",
    "windows = np.delete(windows, 6, axis=2)\n",
    "mos = np.delete(mos, 6, axis=2)\n",
    "non_mos = np.delete(non_mos, 6, axis=2)\n",
    "\n",
    "num_split = 0.8\n",
    "trainmos, testmos = data_split(mos, num_split)\n",
    "trainnomos, testnomos = data_split(non_mos, num_split)\n",
    "\n",
    "print(trainmos.shape)\n",
    "print(testmos.shape)\n",
    "print(trainnomos.shape)\n",
    "print(testnomos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DP-SGD with sampling rate = 1.48% and noise_multiplier = 16.12046258767009 iterated over 1353 steps satisfies differential privacy with eps = 0.1 and delta = 0.0001.\n",
      "DP-SGD with sampling rate = 1.48% and noise_multiplier = 2.0764687025749686 iterated over 1353 steps satisfies differential privacy with eps = 1 and delta = 0.0001.\n",
      "DP-SGD with sampling rate = 1.48% and noise_multiplier = 0.6352029180324079 iterated over 1353 steps satisfies differential privacy with eps = 10 and delta = 0.0001.\n",
      "{0.1: 16.12046258767009, 1: 2.0764687025749686, 10: 0.6352029180324079}\n",
      "DP-SGD with sampling rate = 1.48% and noise_multiplier = 16.12046258767009 iterated over 1353 steps satisfies differential privacy with eps = 0.1 and delta = 0.0001.\n",
      "The optimal RDP order is 128.0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.09999999999999867, 128.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get needed noise for target epsilon\n",
    "min_noise = 1e-5\n",
    "target_epsilons = [0.1, 1, 10]\n",
    "noise_multipliers = {target_epsilon : compute_noise(\n",
    "    windows.shape[0] // 2,\n",
    "    BATCH_SIZE,\n",
    "    target_epsilon,\n",
    "    EPOCHS * 2,\n",
    "    DELTA,\n",
    "    min_noise\n",
    ") for target_epsilon in target_epsilons}\n",
    "print(noise_multipliers)\n",
    "\n",
    "compute_dp_sgd_privacy.compute_dp_sgd_privacy(n=windows.shape[0] // 2,\n",
    "                                              batch_size=BATCH_SIZE,\n",
    "                                              noise_multiplier=noise_multipliers[target_epsilons[0]],\n",
    "                                              epochs=EPOCHS*2,\n",
    "                                              delta=DELTA)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sweep Config only for sweep case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: xx9xjr2j\n",
      "Sweep URL: https://wandb.ai/nw20hewo/dp_cgan_epsilon_sweep/sweeps/xx9xjr2j\n"
     ]
    }
   ],
   "source": [
    "# Define sweep config\n",
    "sweep_configuration = {\n",
    "    'method': 'grid',\n",
    "    'name': 'sweep',\n",
    "    'metric': {'goal': 'minimize', 'name': 'c2st_score'},\n",
    "    'parameters': \n",
    "    {   \n",
    "        'target_epsilon': {'values': list(noise_multipliers.keys())}\n",
    "        #'d_architecture': {'values': [\"lstm\", \"fcn\", \"transformer\"]}\n",
    "\n",
    "        #'batch_size': {'values': [32]},\n",
    "        #'d_lr': {'max': 0.2, 'min': 0.0001},\n",
    "        #'g_lr': {'max': 0.1, 'min': 0.0001},\n",
    "        #'head_size': {'values': [16, 32, 64, 128, 256]},\n",
    "        #'hidden_units': {'values': [16, 32, 64, 128, 256]},\n",
    "        # 'filter1': {'values': [32, 64]},\n",
    "        # 'filter2': {'values': [64, 128]},\n",
    "        # 'filter3': {'values': [32, 64]},\n",
    "        # 'activation_function': {'values': ['sigmoid', 'tanh', 'relu', 'linear']},\n",
    "        #'kernel_size1': {'values': [3, 5, 7]},\n",
    "        #'kernel_size2': {'values': [3, 5, 7]},\n",
    "        #'kernel_size3': {'values': [3, 5, 7]},\n",
    "        #'optimizer': {\n",
    "        #    'values': ['adam', 'sgd']\n",
    "        #},\n",
    "    }\n",
    "}\n",
    "\n",
    "# Initialize sweep by passing in config. \n",
    "# (Optional) Provide a name of the project.\n",
    "sweep_id = wandb.sweep(\n",
    "sweep=sweep_configuration, \n",
    "#project='cgan_d_arch_sweep'\n",
    "project='dp_cgan_epsilon_sweep'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset into tf dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((windows, labels))\n",
    "\n",
    "# Shuffle, cache, and batch the dataset\n",
    "dataset = dataset.shuffle(buffer_size=1024)\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "randomTrainMos = tf.random.normal(shape=(trainmos.shape[0], LATENT_DIM))\n",
    "\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "randomTrainNoMos = tf.random.normal(shape=(trainnomos.shape[0], LATENT_DIM))\n",
    "\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "randomTestMos = tf.random.normal(shape=(testmos.shape[0], LATENT_DIM))\n",
    "\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "randomTestNoMos = tf.random.normal(shape=(testnomos.shape[0], LATENT_DIM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    run = wandb.init(\n",
    "       project=\"cgan_4\" if not DP_TRAINING else \"dpcgan\",\n",
    "       config=config\n",
    "    )\n",
    "\n",
    "\n",
    "    cond_gan = ConditionalGAN(\n",
    "        num_features=NUM_FEATURES,\n",
    "        seq_length=SEQ_LENGTH,\n",
    "        latent_dim=LATENT_DIM,\n",
    "        discriminator=ConditionalGAN.conditional_discriminator(\n",
    "            hidden_units=SEQ_LENGTH, \n",
    "            seq_length=SEQ_LENGTH, \n",
    "            num_features=NUM_FEATURES,\n",
    "            filters=[32, 64, 32],\n",
    "            activation_function= ACTIVATION,\n",
    "            architecture=D_ARCHITECTURE, \n",
    "            #head_size=wandb.config.head_size#wandb.config.d_architecture\n",
    "            #filters=[wandb.config.filter1, wandb.config.filter2, wandb.config.filter3],\n",
    "            #kernel_sizes=[wandb.config.kernel_size1, wandb.config.kernel_size2, wandb.config.kernel_size3]\n",
    "            ),\n",
    "        generator=ConditionalGAN.conditional_generator(\n",
    "            hidden_units=SEQ_LENGTH, \n",
    "            seq_length=SEQ_LENGTH, \n",
    "            latent_dim=LATENT_DIM,\n",
    "            num_features=NUM_FEATURES,\n",
    "            activation_function=ACTIVATION\n",
    "        )\n",
    "    )\n",
    "    if DP_TRAINING:\n",
    "\n",
    "        config[\"noise_multiplier\"] = noise_multipliers[wandb.config.target_epsilon]\n",
    "\n",
    "        d_optimizer = dp_optimizer_vectorized.VectorizedDPAdamOptimizer( #vectorized adam am schnellsten\n",
    "            l2_norm_clip=L2_NORM_CLIP,\n",
    "            noise_multiplier=noise_multipliers[wandb.config.target_epsilon],\n",
    "            num_microbatches=NUM_MICROBATCHES,\n",
    "            learning_rate=DP_LEARNING_RATE\n",
    "        )\n",
    "    else:\n",
    "        d_optimizer = Adam(learning_rate=LEARNING_RATE, beta_1=0.5) # get_optimizer(0.0002, wandb.config.optimizer)#\n",
    "\n",
    "    g_optimizer = Adam(learning_rate=LEARNING_RATE, beta_1=0.5) # get_optimizer(0.0002, wandb.config.optimizer)#\n",
    "\n",
    "    cond_gan.compile(\n",
    "        d_optimizer= d_optimizer, # Adam(learning_rate=0.0002, beta_1=0.5),\n",
    "        g_optimizer= g_optimizer, # Adam(learning_rate=0.0002, beta_1=0.5), #optimizer\n",
    "        loss_fn=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    )\n",
    "\n",
    "    print(f\"{cond_gan.d_optimizer} is used\")\n",
    "\n",
    "    if DP_TRAINING:\n",
    "        generator_save_path = f\"models/dp/{wandb.run.name}/\"\n",
    "    else:\n",
    "        generator_save_path = f\"models/no_dp/{wandb.run.name}/\"\n",
    "\n",
    "    logger_callback = WandbCallback()\n",
    "\n",
    "    history = cond_gan.fit(\n",
    "        dataset,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[\n",
    "            GANMonitor(\n",
    "                trainmos,\n",
    "                trainnomos,\n",
    "                testmos,\n",
    "                testnomos,\n",
    "                randomTrainMos,\n",
    "                randomTrainNoMos,\n",
    "                randomTestMos,\n",
    "                randomTestNoMos,\n",
    "                num_seq=50,\n",
    "                save_path=generator_save_path,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                seq_length=SEQ_LENGTH,\n",
    "                num_features=NUM_FEATURES,\n",
    "                dp=DP_TRAINING,\n",
    "            ),\n",
    "            logger_callback\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    if DP_TRAINING:\n",
    "        base_path = f\"models/dp/{wandb.run.name}/\"\n",
    "        cond_gan.generator.save(f\"{base_path}cgan_generator\")\n",
    "        cond_gan.discriminator.save(f\"{base_path}cgan_discriminator\")\n",
    "    elif LOSO_TRAINING_WITHOUT_SUBJECT:\n",
    "        base_path = f\"models/no_dp/loso/sub{LOSO_TRAINING_WITHOUT_SUBJECT}/{wandb.run.name}/\"\n",
    "        cond_gan.generator.save(f\"{base_path}cgan_generator\")\n",
    "        cond_gan.discriminator.save(f\"{base_path}cgan_discriminator\")\n",
    "    else:\n",
    "        base_path = f\"models/no_dp/{wandb.run.name}/\"\n",
    "        cond_gan.generator.save(f\"{base_path}cgan_generator\")\n",
    "        cond_gan.discriminator.save(f\"{base_path}cgan_discriminator\")\n",
    "    wandb.finish()\n",
    "wandb.login()\n",
    "main()\n",
    "wandb.finish()\n",
    "#wandb.agent(sweep_id, function=main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system(\"say 'C GAN IST FERTIG'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best run vital-sweep-3 with 0.8536036036036037% c2st_score\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "api = wandb.Api()\n",
    "\n",
    "sweep = api.sweep(\"nw20hewo/cgan_d_arch_sweep/mloanunf\")\n",
    "runs = sorted(sweep.runs,\n",
    "  key=lambda run: run.summary.get(\"c2st_score\", 0), reverse=False)\n",
    "val_acc = runs[0].summary.get(\"c2st_score\", 0)\n",
    "print(f\"Best run {runs[0].name} with {val_acc}% c2st_score\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cgan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
