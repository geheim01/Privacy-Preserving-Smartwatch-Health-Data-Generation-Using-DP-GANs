{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Stress Detection From Wearables](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Stress Detection From Wearables](#toc1_)    \n",
    "    - [Imports](#toc1_1_1_)    \n",
    "  - [Data Preprocessing](#toc1_2_)    \n",
    "    - [Window](#toc1_2_1_)    \n",
    "  - [Model](#toc1_3_)    \n",
    "    - [Imports](#toc1_3_1_)    \n",
    "    - [Build model](#toc1_3_2_)    \n",
    "    - [Train model](#toc1_3_3_)    \n",
    "    - [64hz](#toc1_3_4_)    \n",
    "    - [1 hz](#toc1_3_5_)    \n",
    "  - [Evaluation](#toc1_4_)    \n",
    "    - [64hz](#toc1_4_1_)    \n",
    "  - [Prediction](#toc1_5_)    \n",
    "  - [MISC](#toc1_6_)    \n",
    "- [Training with synthetic data](#toc2_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_1_'></a>[Imports](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import scipy.signal\n",
    "from scipy import fft\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from synthesizers.preprocessing.wesad import WESADDataset\n",
    "from typing import List, Tuple, Dict\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_2_'></a>[Data Preprocessing](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'data/wesad/preprocessed_1hz.csv'\n",
    "SAMPLING_RATE = 1\n",
    "\n",
    "df = pd.read_csv(DATA_PATH, index_col=0)\n",
    "trainX, label_trainX = WESADDataset.create_windows(df, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_1_'></a>[Window](#toc0_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Creating the windows\n",
    "2. Create subwindows from the windows\n",
    "3. Calculate the fft of the subwindows\n",
    "4. Average the subwindows\n",
    "\n",
    "![fft](../images/fft.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Subwindow length of the biosignals\n",
    "signal_subwindow_dict = {\n",
    "    'ACC_x': 7,\n",
    "    'ACC_y': 7,\n",
    "    'ACC_z': 7,\n",
    "    'BVP': 30,\n",
    "    'EDA': 30,\n",
    "    'TEMP': 35\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# most frequent element in list\n",
    "def most_common(lst):\n",
    "    return max(set(lst), key=lst.count)\n",
    "\n",
    "# if stress occurress in time interval return 1\n",
    "def check_for_stress(lst):\n",
    "    return max(set(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_windows(df: pd.DataFrame, fs: int) -> tuple[np.ndarray,list]:\n",
    "    \"\"\"Creates windows from the dataframe and returns the windows and the labels.\n",
    "    If the window is assigned to multiple labels, the most common label is chosen for that period.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Subject DataFrame\n",
    "        fs (int): Samples per second\n",
    "\n",
    "    Returns:\n",
    "        tuple[np.ndarray,list]: Windows representing the activity of the subject in one minute and the corresponding labels.\n",
    "    \"\"\"\n",
    "    # Create an empty list for the windows and labels\n",
    "    windows = []\n",
    "    labels = []\n",
    "\n",
    "    # Calculate the window length in samples\n",
    "    window_len = fs * 60\n",
    "\n",
    "    # Loop over the rows in the DataFrame to create the windows\n",
    "    for i in range(0, df.shape[0]-window_len, window_len):\n",
    "        # Get the window data and label\n",
    "        window = df[i:i+window_len]\n",
    "        label = int(check_for_stress(df['label'][i:i+window_len].to_list()))\n",
    "\n",
    "        # Convert the window data to a numpy array\n",
    "        window = window.to_numpy()\n",
    "\n",
    "        # Add the window and label to the list\n",
    "        windows.append(window)\n",
    "        labels.append(label)\n",
    "\n",
    "    # Convert the windows and labels to numpy arrays\n",
    "    windows = np.array(windows)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Return the windows and labels as a tuple\n",
    "    return windows, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_subwindows(window: np.array, signal_subwindow_len: int, signal_name: str, fs: int) -> np.array:\n",
    "    \"\"\"The function creates subwindows from the windows.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Windows representing the activity of the subject in one minute.\n",
    "        signal_subwindow_len (int): Length of the subwindows.\n",
    "        signal_name (str): Name of the signal.\n",
    "        fs (int): Samples per second\n",
    "\n",
    "    Returns:\n",
    "        list: Subwindows of the signal in the window.\n",
    "    \"\"\"\n",
    "\n",
    "    subwindow_len = fs * signal_subwindow_len # fs = 64 and sub-window length in seconds = 30\n",
    "    window_len = fs * 60 # fs = 64 and window length in seconds = 60\n",
    "    window_shift = 1 if fs < 4 else int(fs * 0.25) # fs = 64 and window shift in seconds = 0.25\n",
    "\n",
    "    subwindows = np.asarray([window[i:i+subwindow_len] for i in range(0, window_len - subwindow_len + 1, window_shift)])\n",
    "            \n",
    "    return subwindows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft_subwindows(subwindows: list, duration: int, fs: int) -> list:\n",
    "    \"\"\"Calculates the fft of the subwindows.\n",
    "\n",
    "    Args:\n",
    "        subwindows (list): C\n",
    "        duration (int): _description_\n",
    "        f_s (int): _description_\n",
    "\n",
    "    Returns:\n",
    "        list: Fft coefficients of the subwindows.\n",
    "    \"\"\"\n",
    "    freqs= []\n",
    "    yfs = []\n",
    "    for subwindow in subwindows:\n",
    "        y = np.array(subwindow)\n",
    "        yf = scipy.fft.fft(y)\n",
    "        l = len(yf)\n",
    "        N = fs * duration\n",
    "        freq = scipy.fft.fftfreq(N, 1/fs)\n",
    "\n",
    "        l //= 2\n",
    "        amps = np.abs(yf[0:l])\n",
    "        freq = np.abs(freq[0:l])\n",
    "\n",
    "        # Sort descending amp   \n",
    "        p = amps.argsort()[::-1]\n",
    "        freq = freq[p]\n",
    "        amps = amps[p]\n",
    "\n",
    "        freqs.append(freq)\n",
    "        yfs.append(amps)\n",
    "    return np.asarray(freqs), np.asarray(yfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_along_axis(array: np.ndarray, target_length: int, axis: int = 0) -> np.ndarray:\n",
    "\n",
    "    pad_size = target_length - array.shape[axis]\n",
    "\n",
    "    if pad_size <= 0:\n",
    "        return array\n",
    "\n",
    "    npad = [(0, 0)] * array.ndim\n",
    "    npad[axis] = (0, pad_size)\n",
    "\n",
    "    return np.pad(array, pad_width=npad, mode='constant', constant_values=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fft_subwindows(subwindows: list, duration: int, fs: int) -> list:\n",
    "    \"\"\"Calculates the fft of the subwindows.\n",
    "\n",
    "    Args:\n",
    "        subwindows (list): C\n",
    "        duration (int): _description_\n",
    "        f_s (int): _description_\n",
    "\n",
    "    Returns:\n",
    "        list: Fft coefficients of the subwindows.\n",
    "    \"\"\"\n",
    "    freqs= []\n",
    "    yfs = []\n",
    "    for subwindow in subwindows:\n",
    "        y = np.array(subwindow)\n",
    "        yf = scipy.fft.fft(y)\n",
    "        l = len(yf)\n",
    "        N = fs * duration\n",
    "        freq = scipy.fft.fftfreq(N, 1/fs)\n",
    "\n",
    "        l //= 2\n",
    "        amps = np.abs(yf[0:l])\n",
    "        freq = np.abs(freq[0:l])\n",
    "\n",
    "        # Sort descending amp   \n",
    "        p = amps.argsort()[::-1]\n",
    "        freq = freq[p]\n",
    "        amps = amps[p]\n",
    "\n",
    "        freqs.append(freq)\n",
    "        yfs.append(amps)\n",
    "    return np.asarray(freqs), np.asarray(yfs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def average_window(subwindows_fft: list) -> list:\n",
    "    \"\"\"Calculates the average of the fft coefficients of the subwindows.\n",
    "\n",
    "    Args:\n",
    "        subwindows_fft (list): List of fft coefficients of the subwindows.\n",
    "\n",
    "    Returns:\n",
    "        list: Average of the fft coefficients of the subwindow for signals.\n",
    "    \"\"\"\n",
    "    len_yfs = len(subwindows_fft[0])\n",
    "    avg_yfs = []\n",
    "    for i in range(len_yfs):\n",
    "        i_yfs = []\n",
    "        for yf in subwindows_fft:\n",
    "            try:\n",
    "                i_yfs.append(yf[i])\n",
    "            except IndexError:\n",
    "                pass\n",
    "        avg_yfs.append(sum(i_yfs)/len(i_yfs))\n",
    "    return avg_yfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_training_data_per_subject(fs, windows, yfs_per_min_for_signal):\n",
    "        \n",
    "    X = []\n",
    "    for i in range(0,len(windows) - 1):\n",
    "        yfs_averages = []\n",
    "        for j, signal in enumerate(signal_subwindow_dict.keys()):\n",
    "            duration_in_sec = signal_subwindow_dict[signal]\n",
    "            subwindows = create_subwindows(windows[i,:,j], signal_subwindow_len=duration_in_sec, signal_name=signal, fs=fs)\n",
    "            _, yfs = fft_subwindows(subwindows, duration_in_sec, fs=fs)\n",
    "            padded_yfs = pad_along_axis(yfs, target_length=210, axis=1) \n",
    "            yfs_averages.append(average_window(padded_yfs)[:210])\n",
    "                \n",
    "        X.append(yfs_averages)\n",
    "    return np.array(X)\n",
    "\n",
    "def create_preprocessed_subjects_data(subjects_data: dict, fs: int = 64) -> dict:\n",
    "# Creates averaged windows for all subjects from dataframes\n",
    "\n",
    "    subjects_preprosessed_data = {}\n",
    "    for subject_name, subject_df in subjects_data.items():\n",
    "        subjects_preprosessed_data[subject_name] = {}\n",
    "        windows, labels = create_windows(subject_df, fs=fs)\n",
    "        yfs_per_min_for_signal = {}\n",
    "        X = create_training_data_per_subject(fs, windows, yfs_per_min_for_signal)\n",
    "        y = np.array((labels[:len(windows)-1]))\n",
    "\n",
    "        subjects_preprosessed_data[subject_name]['X'] = X\n",
    "        subjects_preprosessed_data[subject_name]['y'] = y\n",
    "    \n",
    "    return subjects_preprosessed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_data_per_subject_gen(fs, windows):\n",
    "        \n",
    "    X = []\n",
    "    for i in range(0,len(windows) - 1):\n",
    "        yfs_averages = []\n",
    "        for j, signal in enumerate(signal_subwindow_dict.keys()):\n",
    "            duration_in_sec = signal_subwindow_dict[signal]\n",
    "            subwindows = create_subwindows(windows[i,:,j], signal_subwindow_len=duration_in_sec, signal_name=signal, fs=fs)\n",
    "            # print(\"Subwindow Shape: \", subwindows.shape)\n",
    "            _, yfs = fft_subwindows(subwindows, duration_in_sec, fs=fs)\n",
    "            \n",
    "            # print(\"fft_subwindows Shape: \", yfs.shape)\n",
    "            padded_yfs = pad_along_axis(yfs, target_length=210, axis=1) \n",
    "            # orint(\"padded fft_subwindows Shape: \", padded_yfs.shape)\n",
    "            yfs_averages.append(average_window(padded_yfs)[:210])\n",
    "                \n",
    "        X.append(yfs_averages)\n",
    "    return np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_preprocessed_subjects_data_gen(windows: np.array, fs: int = 64) -> Tuple:\n",
    "# Creates averaged windows for all subjects from dataframes\n",
    "\n",
    "    print(\"Windows Shape: \", windows.shape)\n",
    "    yfs_per_min_for_signal = {}\n",
    "    X = create_training_data_per_subject_gen(fs, windows)\n",
    "    \n",
    "    y = np.array((X[:,0,6][:len(X)]))\n",
    "\n",
    "    print(f\"X Shape:\", X.shape)\n",
    "    print(f\"y Shape:\", y.shape)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_subject_window_data(subjects_preprosessed_data: Dict) -> Tuple[List, List]:\n",
    "    # Created train and test data for leave one out cross validation\n",
    "    all_subjects_X = [subject_data['X'] for subject_data in subjects_preprosessed_data.values()]\n",
    "    all_subjects_y = [subject_data['y'] for subject_data in subjects_preprosessed_data.values()]\n",
    "    \n",
    "    return all_subjects_X, all_subjects_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataType(Enum):\n",
    "    CGAN = 0\n",
    "    DGAN = 1\n",
    "    REAL = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/Users/nils/master/Stress-Detection-From-Wearables/data/WESAD'\n",
    "SYNTHETIC_DGAN_DATA_PATH = '/Users/nils/thesis/gretel-synthetics/src/syn_df_30000_1hz'\n",
    "SYNTHETIC_CGAN_DATA_PATH = 'data/syn/cond_syn_gen.npy'\n",
    "# SYNTHETIC_DATA_PATH = \"/Users/nils/thesis/gretel-synthetics/syn_df\"\n",
    "SAMPLING_RATE = 1\n",
    "SUBJECT_IDS = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_subject_data(subjects_data, save_path: str):\n",
    "    # save dictionary as pickle file\n",
    "    with open(save_path, 'wb') as f:\n",
    "        pickle.dump(subjects_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_type: DataType, sampling_rate: int, synthetic_data_path: str) -> Tuple[List, List]:\n",
    "    \"\"\"\n",
    "    Load preprocessed data from disk or create it from scratch.\n",
    "\n",
    "    Args:\n",
    "        data_type: The type of data to load (real or synthetic).\n",
    "        sampling_rate: The sampling rate of the data.\n",
    "        data_path: The path to the data directory.\n",
    "        subject_ids: The list of subject IDs to include in the data.\n",
    "        synthetic_data_path: The path to the synthetic data CSV file.\n",
    "        load_from_disk: Whether to load data from disk or create it from scratch.\n",
    "\n",
    "    Returns:\n",
    "        A tuple of NumPy arrays containing the windowed data and corresponding labels.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If the data file is not found.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # load dictionary from pickle file\n",
    "        print(\"*** Try to load data from disk ***\\n\")\n",
    "        with open(f'data/wesad/subject_data_{sampling_rate}hz.pickle', 'rb') as f:\n",
    "            subjects_data = pickle.load(f)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"*** File not found ***\")\n",
    "        print(\"*** Preprocess data ***\")\n",
    "        dataset = WESADDataset(DATA_PATH, SUBJECT_IDS)\n",
    "        subjects_data = dataset.get_subject_dataframes(sampling_rate=sampling_rate)\n",
    "        save_subject_data(subjects_data, f\"data/wesad/subject_data_{sampling_rate}hz.pickle\")\n",
    "\n",
    "    if data_type == DataType.DGAN:\n",
    "        print(\"*** Add synthetic data to DGAN ***\")\n",
    "        syn_df = pd.read_csv(synthetic_data_path, index_col=0)\n",
    "        subjects_data['SYN'] = syn_df\n",
    "    \n",
    "    subjects_preprocessed_data = create_preprocessed_subjects_data(subjects_data, fs=sampling_rate)\n",
    "    all_subjects_X, all_subjects_y = get_subject_window_data(subjects_preprocessed_data)\n",
    "\n",
    "    if data_type == DataType.CGAN:\n",
    "        print(\"*** Add synthetic data to CGAN ***\")\n",
    "        with open(synthetic_data_path, \"rb\") as f:\n",
    "            gen_data = np.load(f) \n",
    "        X, y = create_preprocessed_subjects_data_gen(gen_data, fs=1)\n",
    "\n",
    "        all_subjects_X.append(X)\n",
    "        all_subjects_y.append(y)\n",
    "    \n",
    "    return all_subjects_X, all_subjects_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Try to load data from disk ***\n",
      "\n",
      "*** Add synthetic data to CGAN ***\n",
      "Windows Shape:  (500, 60, 7)\n",
      "X Shape: (499, 6, 210)\n",
      "y Shape: (499,)\n"
     ]
    }
   ],
   "source": [
    "all_subjects_X, all_subjects_y = load_data(DataType.CGAN, sampling_rate=1, synthetic_data_path=SYNTHETIC_CGAN_DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![OS_Sensors](../images/os_sensors.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIGNALS = ['ACC_x', 'ACC_y', 'ACC_z', 'TEMP', 'EDA', 'BVP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SMARTWATCH_OS = {\n",
    "    'E4': ['ACC_x', 'ACC_y', 'ACC_z', 'TEMP', 'EDA', 'BVP'],\n",
    "    'E4_DGAN': ['ACC_x', 'ACC_y', 'ACC_z', 'TEMP', 'EDA', 'BVP'],\n",
    "    'E4_CGAN': ['ACC_x', 'ACC_y', 'ACC_z', 'TEMP', 'EDA', 'BVP'],\n",
    "    #'Tizen': ['ACC_x', 'ACC_y', 'ACC_z', 'TEMP', 'BVP'],\n",
    "    #'WearOS_watchOS': ['ACC_x', 'ACC_y', 'ACC_z', 'TEMP'],\n",
    "    #'Fitbit': ['ACC_x', 'ACC_y', 'ACC_z', 'TEMP', 'EDA'],\n",
    "    #'PiaOS': ['TEMP', 'EDA', 'BVP']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_for_smartwatch_os(smartwatch_os_name: str, all_subjects_X: list) -> list:\n",
    "    # Adjusts the data for the smartwatch os\n",
    "    all_subjects_X_adjusted_for_smartwatch_os = []\n",
    "    for subject_data in all_subjects_X:\n",
    "        subject_adjusted_for_smartwatch_os = []\n",
    "        for window in subject_data:\n",
    "            subject_adjusted_for_smartwatch_os.append(window.loc[SMARTWATCH_OS[smartwatch_os_name]])\n",
    "        all_subjects_X_adjusted_for_smartwatch_os.append(subject_adjusted_for_smartwatch_os)\n",
    "    return all_subjects_X_adjusted_for_smartwatch_os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_for_smartwatch_os_new(smartwatch_os_name: str, all_subjects_X: list) -> list:\n",
    "    # Adjusts the data for the smartwatch os\n",
    "    all_subjects_X_adjusted_for_smartwatch_os = []\n",
    "    for subject_data in all_subjects_X:\n",
    "        subject_adjusted_for_smartwatch_os = []\n",
    "        for window in subject_data:\n",
    "            subject_adjusted_for_smartwatch_os.append(window.loc[SMARTWATCH_OS[smartwatch_os_name]])\n",
    "        all_subjects_X_adjusted_for_smartwatch_os.append(subject_adjusted_for_smartwatch_os)\n",
    "    return all_subjects_X_adjusted_for_smartwatch_os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_for_smartwatch_os('E4', all_subjects_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_3_'></a>[Model](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_3_1_'></a>[Imports](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_3_2_'></a>[Build model](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![model_architecture](../images/model_architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_signals: int = 6, num_output_class: int = 2) -> tf.keras.models.Sequential:\n",
    "\n",
    "    num_output_class = 2\n",
    "    # Define the model architecture\n",
    "    model = tf.keras.Sequential()\n",
    "    # input_shape = 14 Signale (bei uns max. 6) X 210 Inputs (aus Tabelle nach Fourier)\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape=[num_signals, 210, 1]))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=64, activation='relu', kernel_size=(1,3), strides=1, padding='same')) \n",
    "    model.add(tf.keras.layers.Dropout(rate=0.3))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=64, activation='relu', kernel_size=(1,3), strides=1, padding='same'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(1,2)))\n",
    "    model.add(tf.keras.layers.Dropout(rate=0.3))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=64, activation='relu', kernel_size=(1,3), strides=1, padding='same'))\n",
    "    model.add(tf.keras.layers.Dropout(rate=0.3))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(1,2)))\n",
    "    model.add(tf.keras.layers.Dropout(rate=0.3))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(units=128, activation='relu', kernel_initializer='glorot_uniform'))\n",
    "    model.add(tf.keras.layers.Dropout(rate=0.3))\n",
    "    model.add(tf.keras.layers.Dense(units=64, activation='relu', kernel_initializer='glorot_uniform'))\n",
    "    model.add(tf.keras.layers.Dropout(rate=0.3))\n",
    "    # Anzahl der Units = Anzahl der Klassen (2 - non-stress vs stress)\n",
    "    model.add(tf.keras.layers.Dense(units=num_output_class, activation='sigmoid')) # sigmoid statt softmax, da nur 2 Klassen\n",
    "\n",
    "\n",
    "    optimizer = \"rmsprop\"\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy', \n",
    "        metrics=[\n",
    "        'accuracy', \n",
    "        tf.keras.metrics.Precision(), \n",
    "        tf.keras.metrics.Recall()\n",
    "        ]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_3_3_'></a>[Train model](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_ids = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(smart_os, signals, all_subjects_X, all_subjects_y, data_type: DataType, num_epochs: int):\n",
    "    print(f'\\n\\n\\nSmartwatchOS: {smart_os}')\n",
    "    print(f'DataType: {data_type}')\n",
    "    print(f'Signals: {\" \".join(signals)}')\n",
    "    print(f'Number of signals: {len(signals)}')\n",
    "\n",
    "    # changed - no filter for smartwatch\n",
    "    # all_subjects_X_os = filter_for_smartwatch_os(os, all_subjects_X)\n",
    "    all_subjects_X_os = all_subjects_X\n",
    "    if data_type in (DataType.DGAN, DataType.CGAN):\n",
    "        groups_set = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "        subject_ids = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 'SYN'] # ids for subjects in WESAD dataset\n",
    "    if data_type == DataType.REAL:\n",
    "        groups_set = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
    "        subject_ids = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17] # ids for subjects in WESAD dataset\n",
    "    num_signals = len(signals) # Number of signals in the WESAD dataset measured by the empatica e4\n",
    "    num_output_class = 2 # Number of output classes (2 - non-stress vs stress)\n",
    "    # num_epochs = 100\n",
    "\n",
    "    for i in groups_set:\n",
    "        \n",
    "        test_index = groups_set[i]\n",
    "        train_index = [x for x in groups_set if x != test_index]\n",
    "\n",
    "        print(f'Train on: {train_index}')\n",
    "        print(f'Test  on: {test_index}')\n",
    "\n",
    "        X_train = np.concatenate(np.array([all_subjects_X_os[x] for x in train_index], dtype=object))\n",
    "        y_train = np.concatenate(np.array([all_subjects_y[y] for y in train_index], dtype=object))\n",
    "        X_test = all_subjects_X_os[test_index]\n",
    "        y_test = all_subjects_y[test_index]\n",
    "        \n",
    "        weight_balance = y_train.tolist().count(0)/y_train.tolist().count(1)\n",
    "\n",
    "        X_train = np.asarray(X_train)\n",
    "        X_test = np.asarray(X_test)\n",
    "        y_train = np.asarray(y_train)\n",
    "        y_test = np.asarray(y_test)\n",
    "\n",
    "        y_train = tf.keras.utils.to_categorical(y_train, num_output_class)\n",
    "        y_test = tf.keras.utils.to_categorical(y_test, num_output_class)\n",
    "\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "        model = build_model(num_signals, num_output_class)\n",
    "\n",
    "        if data_type == DataType.REAL:\n",
    "            model_path = f\"models/stress_detector/real/{num_epochs}/wesad_s{subject_ids[test_index]}.h5\"  # Path to save the model file\n",
    "        if data_type == DataType.DGAN:\n",
    "            model_path = f\"models/stress_detector/syn/dgan_30000/{num_epochs}/wesad_s{subject_ids[test_index]}.h5\"\n",
    "        if data_type == DataType.CGAN:\n",
    "            model_path = f\"models/stress_detector/syn/cgan/{num_epochs}/wesad_s{subject_ids[test_index]}.h5\"\n",
    "\n",
    "        callbacks = [\n",
    "            tf.keras.callbacks.ModelCheckpoint(\n",
    "                model_path,\n",
    "                # f\"models/{smart_os}/wesad_{smart_os}_binary_s_syn_{num_epochs}.h5\",  # Path to save the model file\n",
    "                # f\"models/syn/wesad_{smart_os}_binary_s_syn_{num_epochs}.h5\",  # Path to save the model file\n",
    "                monitor=\"loss\", # The metric name to monitor\n",
    "                save_best_only=True # If True, it only saves the \"best\" model according to the quantity monitored \n",
    "            ),\n",
    "            tf.keras.callbacks.EarlyStopping(monitor=\"loss\", patience=10)  \n",
    "        ]\n",
    "        \n",
    "    \n",
    "        history = model.fit(\n",
    "            X_train, \n",
    "            y_train,\n",
    "            epochs=num_epochs, \n",
    "            batch_size=50,\n",
    "            verbose=1,\n",
    "            class_weight={0: 1, 1: weight_balance}, # to address the imbalance of the class labels\n",
    "            callbacks = callbacks,\n",
    "            validation_data=(X_test, y_test)\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Try to load data from disk ***\n",
      "\n",
      "*** Add synthetic data to CGAN ***\n",
      "Windows Shape:  (36, 60, 7)\n",
      "X Shape: (35, 6, 210)\n",
      "y Shape: (35,)\n"
     ]
    }
   ],
   "source": [
    "all_subjects_X, all_subjects_y = load_data(DataType.CGAN, 1, synthetic_data_path=SYNTHETIC_CGAN_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "SmartwatchOS: E4\n",
      "DataType: DataType.CGAN\n",
      "Signals: ACC_x ACC_y ACC_z TEMP EDA BVP\n",
      "Number of signals: 6\n",
      "Train on: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "Test  on: 0\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 21:04:35.072929: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - ETA: 0s - loss: 0.9707 - accuracy: 0.6384 - precision: 0.6128 - recall: 0.6648"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 21:05:18.156606: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 47s 3s/step - loss: 0.9707 - accuracy: 0.6384 - precision: 0.6128 - recall: 0.6648 - val_loss: 0.5992 - val_accuracy: 0.7941 - val_precision: 0.7941 - val_recall: 0.7941\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 5s 428ms/step - loss: 0.8218 - accuracy: 0.7401 - precision: 0.7158 - recall: 0.7495 - val_loss: 0.5159 - val_accuracy: 0.8824 - val_precision: 0.9286 - val_recall: 0.7647\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 7s 460ms/step - loss: 0.7487 - accuracy: 0.7458 - precision: 0.7481 - recall: 0.7382 - val_loss: 0.5651 - val_accuracy: 0.8235 - val_precision: 0.8621 - val_recall: 0.7353\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 3s 337ms/step - loss: 0.6733 - accuracy: 0.8079 - precision: 0.8090 - recall: 0.8136 - val_loss: 0.5561 - val_accuracy: 0.8235 - val_precision: 0.8889 - val_recall: 0.7059\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 2s 205ms/step - loss: 0.6123 - accuracy: 0.7947 - precision: 0.8034 - recall: 0.7928 - val_loss: 0.3424 - val_accuracy: 0.8235 - val_precision: 0.8235 - val_recall: 0.8235\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 1s 67ms/step - loss: 0.5975 - accuracy: 0.8456 - precision: 0.8498 - recall: 0.8418 - val_loss: 0.4256 - val_accuracy: 0.8529 - val_precision: 0.8750 - val_recall: 0.8235\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 3s 293ms/step - loss: 0.5972 - accuracy: 0.8211 - precision: 0.8232 - recall: 0.8154 - val_loss: 0.3588 - val_accuracy: 0.8529 - val_precision: 0.8529 - val_recall: 0.8529\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 2s 161ms/step - loss: 0.5949 - accuracy: 0.8286 - precision: 0.8283 - recall: 0.8267 - val_loss: 0.4495 - val_accuracy: 0.8529 - val_precision: 0.8788 - val_recall: 0.8529\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.6366 - accuracy: 0.8041 - precision: 0.8140 - recall: 0.8079 - val_loss: 0.4111 - val_accuracy: 0.9412 - val_precision: 0.9143 - val_recall: 0.9412\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 1s 103ms/step - loss: 0.5760 - accuracy: 0.8380 - precision: 0.8293 - recall: 0.8324 - val_loss: 0.3351 - val_accuracy: 0.8235 - val_precision: 0.8235 - val_recall: 0.8235\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 4s 396ms/step - loss: 0.5541 - accuracy: 0.8418 - precision: 0.8324 - recall: 0.8418 - val_loss: 0.3097 - val_accuracy: 0.8235 - val_precision: 0.8235 - val_recall: 0.8235\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 1s 91ms/step - loss: 0.5692 - accuracy: 0.8230 - precision: 0.8167 - recall: 0.8305 - val_loss: 0.3686 - val_accuracy: 0.8824 - val_precision: 0.8824 - val_recall: 0.8824\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 1s 129ms/step - loss: 0.5042 - accuracy: 0.8606 - precision: 0.8582 - recall: 0.8550 - val_loss: 0.3327 - val_accuracy: 0.8529 - val_precision: 0.8529 - val_recall: 0.8529\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 1s 90ms/step - loss: 0.5296 - accuracy: 0.8437 - precision: 0.8460 - recall: 0.8380 - val_loss: 0.3533 - val_accuracy: 0.8824 - val_precision: 0.8788 - val_recall: 0.8529\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 2s 171ms/step - loss: 0.5424 - accuracy: 0.8399 - precision: 0.8402 - recall: 0.8418 - val_loss: 0.3066 - val_accuracy: 0.8529 - val_precision: 0.8529 - val_recall: 0.8529\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 1s 100ms/step - loss: 0.5320 - accuracy: 0.8493 - precision: 0.8491 - recall: 0.8475 - val_loss: 0.3460 - val_accuracy: 0.8824 - val_precision: 0.9355 - val_recall: 0.8529\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.5513 - accuracy: 0.8399 - precision: 0.8434 - recall: 0.8418 - val_loss: 0.3112 - val_accuracy: 0.8824 - val_precision: 0.8788 - val_recall: 0.8529\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 1s 63ms/step - loss: 0.5231 - accuracy: 0.8606 - precision: 0.8588 - recall: 0.8588 - val_loss: 0.4146 - val_accuracy: 0.8529 - val_precision: 0.8529 - val_recall: 0.8529\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.5346 - accuracy: 0.8418 - precision: 0.8399 - recall: 0.8493 - val_loss: 0.3090 - val_accuracy: 0.8529 - val_precision: 0.8529 - val_recall: 0.8529\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.5280 - accuracy: 0.8588 - precision: 0.8588 - recall: 0.8588 - val_loss: 0.3174 - val_accuracy: 0.8824 - val_precision: 0.8824 - val_recall: 0.8824\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 0.5110 - accuracy: 0.8625 - precision: 0.8561 - recall: 0.8625 - val_loss: 0.3028 - val_accuracy: 0.8824 - val_precision: 0.8824 - val_recall: 0.8824\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 37ms/step - loss: 0.5095 - accuracy: 0.8550 - precision: 0.8558 - recall: 0.8606 - val_loss: 0.3800 - val_accuracy: 0.9118 - val_precision: 0.9118 - val_recall: 0.9118\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 1s 117ms/step - loss: 0.5076 - accuracy: 0.8531 - precision: 0.8531 - recall: 0.8531 - val_loss: 0.2699 - val_accuracy: 0.8824 - val_precision: 0.8824 - val_recall: 0.8824\n",
      "Train on: [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "Test  on: 1\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 21:06:01.090583: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - ETA: 0s - loss: 0.9735 - accuracy: 0.6121 - precision: 0.6082 - recall: 0.6139"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 21:06:43.224828: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 46s 3s/step - loss: 0.9735 - accuracy: 0.6121 - precision: 0.6082 - recall: 0.6139 - val_loss: 0.6314 - val_accuracy: 0.6765 - val_precision: 0.6765 - val_recall: 0.6765\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 10s 990ms/step - loss: 0.8775 - accuracy: 0.7119 - precision: 0.7028 - recall: 0.7081 - val_loss: 0.6015 - val_accuracy: 0.6765 - val_precision: 0.6389 - val_recall: 0.6765\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 3s 258ms/step - loss: 0.7311 - accuracy: 0.7872 - precision: 0.7759 - recall: 0.7891 - val_loss: 0.6266 - val_accuracy: 0.6765 - val_precision: 0.6765 - val_recall: 0.6765\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 3s 276ms/step - loss: 0.6691 - accuracy: 0.7834 - precision: 0.7854 - recall: 0.7928 - val_loss: 0.5624 - val_accuracy: 0.7353 - val_precision: 0.7353 - val_recall: 0.7353\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 3s 277ms/step - loss: 0.5851 - accuracy: 0.8305 - precision: 0.8296 - recall: 0.8343 - val_loss: 0.5917 - val_accuracy: 0.7059 - val_precision: 0.7059 - val_recall: 0.7059\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 2s 215ms/step - loss: 0.5774 - accuracy: 0.8437 - precision: 0.8472 - recall: 0.8456 - val_loss: 0.5707 - val_accuracy: 0.7059 - val_precision: 0.7059 - val_recall: 0.7059\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 2s 194ms/step - loss: 0.6191 - accuracy: 0.8249 - precision: 0.8233 - recall: 0.8249 - val_loss: 0.5199 - val_accuracy: 0.7059 - val_precision: 0.7059 - val_recall: 0.7059\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 3s 264ms/step - loss: 0.5644 - accuracy: 0.8437 - precision: 0.8434 - recall: 0.8418 - val_loss: 0.5609 - val_accuracy: 0.7059 - val_precision: 0.6970 - val_recall: 0.6765\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 1s 140ms/step - loss: 0.5168 - accuracy: 0.8512 - precision: 0.8612 - recall: 0.8531 - val_loss: 0.4838 - val_accuracy: 0.7941 - val_precision: 0.8387 - val_recall: 0.7647\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 45ms/step - loss: 0.5179 - accuracy: 0.8493 - precision: 0.8531 - recall: 0.8418 - val_loss: 0.5283 - val_accuracy: 0.7647 - val_precision: 0.7647 - val_recall: 0.7647\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 1s 74ms/step - loss: 0.5963 - accuracy: 0.8305 - precision: 0.8240 - recall: 0.8286 - val_loss: 0.4717 - val_accuracy: 0.7353 - val_precision: 0.7353 - val_recall: 0.7353\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 0.5183 - accuracy: 0.8644 - precision: 0.8679 - recall: 0.8663 - val_loss: 0.4938 - val_accuracy: 0.7353 - val_precision: 0.7353 - val_recall: 0.7353\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 3s 318ms/step - loss: 0.5548 - accuracy: 0.8286 - precision: 0.8318 - recall: 0.8286 - val_loss: 0.5506 - val_accuracy: 0.6765 - val_precision: 0.6857 - val_recall: 0.7059\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 1s 82ms/step - loss: 0.5308 - accuracy: 0.8475 - precision: 0.8447 - recall: 0.8606 - val_loss: 0.5150 - val_accuracy: 0.7353 - val_precision: 0.7143 - val_recall: 0.7353\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 1s 140ms/step - loss: 0.5066 - accuracy: 0.8701 - precision: 0.8719 - recall: 0.8719 - val_loss: 0.5180 - val_accuracy: 0.7353 - val_precision: 0.7027 - val_recall: 0.7647\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.5258 - accuracy: 0.8475 - precision: 0.8489 - recall: 0.8569 - val_loss: 0.4946 - val_accuracy: 0.7059 - val_precision: 0.7742 - val_recall: 0.7059\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 40ms/step - loss: 0.5014 - accuracy: 0.8644 - precision: 0.8655 - recall: 0.8606 - val_loss: 0.4926 - val_accuracy: 0.7353 - val_precision: 0.7143 - val_recall: 0.7353\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 1s 57ms/step - loss: 0.4969 - accuracy: 0.8588 - precision: 0.8577 - recall: 0.8512 - val_loss: 0.4775 - val_accuracy: 0.7353 - val_precision: 0.7576 - val_recall: 0.7353\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 0.4878 - accuracy: 0.8682 - precision: 0.8696 - recall: 0.8663 - val_loss: 0.5051 - val_accuracy: 0.7059 - val_precision: 0.7059 - val_recall: 0.7059\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 1s 87ms/step - loss: 0.4924 - accuracy: 0.8814 - precision: 0.8778 - recall: 0.8795 - val_loss: 0.4800 - val_accuracy: 0.7647 - val_precision: 0.7879 - val_recall: 0.7647\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 0.5314 - accuracy: 0.8550 - precision: 0.8612 - recall: 0.8531 - val_loss: 0.4597 - val_accuracy: 0.7941 - val_precision: 0.7879 - val_recall: 0.7647\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 1s 135ms/step - loss: 0.4647 - accuracy: 0.8606 - precision: 0.8644 - recall: 0.8644 - val_loss: 0.5149 - val_accuracy: 0.7353 - val_precision: 0.7353 - val_recall: 0.7353\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 2s 147ms/step - loss: 0.4540 - accuracy: 0.8776 - precision: 0.8769 - recall: 0.8719 - val_loss: 0.5997 - val_accuracy: 0.7059 - val_precision: 0.7059 - val_recall: 0.7059\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.5047 - accuracy: 0.8606 - precision: 0.8596 - recall: 0.8644 - val_loss: 0.4394 - val_accuracy: 0.7941 - val_precision: 0.7879 - val_recall: 0.7647\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 41ms/step - loss: 0.4703 - accuracy: 0.8550 - precision: 0.8555 - recall: 0.8475 - val_loss: 0.4141 - val_accuracy: 0.7941 - val_precision: 0.7941 - val_recall: 0.7941\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.4369 - accuracy: 0.8851 - precision: 0.8849 - recall: 0.8832 - val_loss: 0.4766 - val_accuracy: 0.7941 - val_precision: 0.7941 - val_recall: 0.7941\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.4791 - accuracy: 0.8814 - precision: 0.8792 - recall: 0.8776 - val_loss: 0.4208 - val_accuracy: 0.7647 - val_precision: 0.8125 - val_recall: 0.7647\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 0.4330 - accuracy: 0.8776 - precision: 0.8811 - recall: 0.8795 - val_loss: 0.4571 - val_accuracy: 0.8529 - val_precision: 0.8286 - val_recall: 0.8529\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.4402 - accuracy: 0.8814 - precision: 0.8790 - recall: 0.8757 - val_loss: 0.4131 - val_accuracy: 0.7647 - val_precision: 0.7647 - val_recall: 0.7647\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 0.4190 - accuracy: 0.8757 - precision: 0.8731 - recall: 0.8814 - val_loss: 0.3888 - val_accuracy: 0.7941 - val_precision: 0.7941 - val_recall: 0.7941\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.4532 - accuracy: 0.8644 - precision: 0.8625 - recall: 0.8625 - val_loss: 0.3870 - val_accuracy: 0.8824 - val_precision: 0.8824 - val_recall: 0.8824\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.4325 - accuracy: 0.8757 - precision: 0.8771 - recall: 0.8870 - val_loss: 0.4747 - val_accuracy: 0.7353 - val_precision: 0.7353 - val_recall: 0.7353\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.4171 - accuracy: 0.8701 - precision: 0.8693 - recall: 0.8644 - val_loss: 0.4076 - val_accuracy: 0.7647 - val_precision: 0.7647 - val_recall: 0.7647\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.4466 - accuracy: 0.8625 - precision: 0.8577 - recall: 0.8625 - val_loss: 0.4078 - val_accuracy: 0.7647 - val_precision: 0.7647 - val_recall: 0.7647\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.3735 - accuracy: 0.8814 - precision: 0.8818 - recall: 0.8851 - val_loss: 0.3845 - val_accuracy: 0.8529 - val_precision: 0.8529 - val_recall: 0.8529\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.4168 - accuracy: 0.8644 - precision: 0.8647 - recall: 0.8663 - val_loss: 0.4874 - val_accuracy: 0.7647 - val_precision: 0.7647 - val_recall: 0.7647\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.4361 - accuracy: 0.8832 - precision: 0.8861 - recall: 0.8795 - val_loss: 0.3812 - val_accuracy: 0.7941 - val_precision: 0.7941 - val_recall: 0.7941\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.4108 - accuracy: 0.8851 - precision: 0.8887 - recall: 0.8870 - val_loss: 0.4099 - val_accuracy: 0.8529 - val_precision: 0.8485 - val_recall: 0.8235\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.3775 - accuracy: 0.8795 - precision: 0.8752 - recall: 0.8851 - val_loss: 0.3850 - val_accuracy: 0.7647 - val_precision: 0.7647 - val_recall: 0.7647\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3885 - accuracy: 0.8776 - precision: 0.8802 - recall: 0.8719 - val_loss: 0.4529 - val_accuracy: 0.7353 - val_precision: 0.7353 - val_recall: 0.7353\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.4021 - accuracy: 0.8908 - precision: 0.8929 - recall: 0.8945 - val_loss: 0.3562 - val_accuracy: 0.8235 - val_precision: 0.8438 - val_recall: 0.7941\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3623 - accuracy: 0.8945 - precision: 0.8860 - recall: 0.8927 - val_loss: 0.3806 - val_accuracy: 0.7941 - val_precision: 0.7879 - val_recall: 0.7647\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3651 - accuracy: 0.8983 - precision: 0.8953 - recall: 0.9021 - val_loss: 0.3815 - val_accuracy: 0.7941 - val_precision: 0.7941 - val_recall: 0.7941\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3372 - accuracy: 0.8889 - precision: 0.8960 - recall: 0.8927 - val_loss: 0.4915 - val_accuracy: 0.7353 - val_precision: 0.7429 - val_recall: 0.7647\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.3475 - accuracy: 0.8927 - precision: 0.8933 - recall: 0.8983 - val_loss: 0.3401 - val_accuracy: 0.8529 - val_precision: 0.8529 - val_recall: 0.8529\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.4327 - accuracy: 0.8738 - precision: 0.8708 - recall: 0.8757 - val_loss: 0.3659 - val_accuracy: 0.7941 - val_precision: 0.8182 - val_recall: 0.7941\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.3403 - accuracy: 0.8927 - precision: 0.8891 - recall: 0.8908 - val_loss: 0.3343 - val_accuracy: 0.8235 - val_precision: 0.8235 - val_recall: 0.8235\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.4018 - accuracy: 0.8964 - precision: 0.8895 - recall: 0.8945 - val_loss: 0.3438 - val_accuracy: 0.8529 - val_precision: 0.8333 - val_recall: 0.8824\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3398 - accuracy: 0.8851 - precision: 0.8889 - recall: 0.8889 - val_loss: 0.4699 - val_accuracy: 0.7647 - val_precision: 0.7647 - val_recall: 0.7647\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3653 - accuracy: 0.8908 - precision: 0.8912 - recall: 0.8945 - val_loss: 0.4465 - val_accuracy: 0.7647 - val_precision: 0.7647 - val_recall: 0.7647\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.3157 - accuracy: 0.9058 - precision: 0.9081 - recall: 0.9115 - val_loss: 0.4443 - val_accuracy: 0.7353 - val_precision: 0.7353 - val_recall: 0.7353\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3645 - accuracy: 0.8927 - precision: 0.8902 - recall: 0.8851 - val_loss: 0.4321 - val_accuracy: 0.7647 - val_precision: 0.7429 - val_recall: 0.7647\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3355 - accuracy: 0.8945 - precision: 0.8989 - recall: 0.9040 - val_loss: 0.4126 - val_accuracy: 0.7647 - val_precision: 0.7576 - val_recall: 0.7353\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3241 - accuracy: 0.9021 - precision: 0.9024 - recall: 0.9058 - val_loss: 0.5258 - val_accuracy: 0.7647 - val_precision: 0.7647 - val_recall: 0.7647\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3247 - accuracy: 0.9058 - precision: 0.9041 - recall: 0.9058 - val_loss: 0.4776 - val_accuracy: 0.7353 - val_precision: 0.7353 - val_recall: 0.7353\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3176 - accuracy: 0.8908 - precision: 0.8931 - recall: 0.8964 - val_loss: 0.4774 - val_accuracy: 0.7941 - val_precision: 0.7941 - val_recall: 0.7941\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3126 - accuracy: 0.9115 - precision: 0.9093 - recall: 0.9058 - val_loss: 0.3413 - val_accuracy: 0.7941 - val_precision: 0.8000 - val_recall: 0.8235\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.3266 - accuracy: 0.9077 - precision: 0.9038 - recall: 0.9021 - val_loss: 0.3721 - val_accuracy: 0.8235 - val_precision: 0.8235 - val_recall: 0.8235\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.3559 - accuracy: 0.8870 - precision: 0.8885 - recall: 0.8851 - val_loss: 0.4250 - val_accuracy: 0.7941 - val_precision: 0.7941 - val_recall: 0.7941\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2881 - accuracy: 0.9096 - precision: 0.9117 - recall: 0.9134 - val_loss: 0.3592 - val_accuracy: 0.8235 - val_precision: 0.8182 - val_recall: 0.7941\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.4127 - accuracy: 0.8795 - precision: 0.8727 - recall: 0.8776 - val_loss: 0.3572 - val_accuracy: 0.7941 - val_precision: 0.7941 - val_recall: 0.7941\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.2846 - accuracy: 0.9153 - precision: 0.9170 - recall: 0.9153 - val_loss: 0.4403 - val_accuracy: 0.7353 - val_precision: 0.7429 - val_recall: 0.7647\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2891 - accuracy: 0.9077 - precision: 0.9106 - recall: 0.9021 - val_loss: 0.4073 - val_accuracy: 0.7647 - val_precision: 0.7647 - val_recall: 0.7647\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.2809 - accuracy: 0.9058 - precision: 0.9053 - recall: 0.9002 - val_loss: 0.4573 - val_accuracy: 0.7647 - val_precision: 0.7647 - val_recall: 0.7647\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2919 - accuracy: 0.9153 - precision: 0.9117 - recall: 0.9134 - val_loss: 0.4933 - val_accuracy: 0.7647 - val_precision: 0.7647 - val_recall: 0.7647\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.3490 - accuracy: 0.8927 - precision: 0.8879 - recall: 0.8945 - val_loss: 0.3248 - val_accuracy: 0.8529 - val_precision: 0.8529 - val_recall: 0.8529\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3173 - accuracy: 0.9040 - precision: 0.9034 - recall: 0.8983 - val_loss: 0.3693 - val_accuracy: 0.7941 - val_precision: 0.7941 - val_recall: 0.7941\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.2878 - accuracy: 0.9115 - precision: 0.9115 - recall: 0.9115 - val_loss: 0.3499 - val_accuracy: 0.7941 - val_precision: 0.7941 - val_recall: 0.7941\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2730 - accuracy: 0.9115 - precision: 0.9148 - recall: 0.9096 - val_loss: 0.4134 - val_accuracy: 0.7647 - val_precision: 0.7647 - val_recall: 0.7647\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2851 - accuracy: 0.8983 - precision: 0.8953 - recall: 0.9021 - val_loss: 0.5950 - val_accuracy: 0.7647 - val_precision: 0.7429 - val_recall: 0.7647\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3221 - accuracy: 0.9002 - precision: 0.8933 - recall: 0.8983 - val_loss: 0.3945 - val_accuracy: 0.7647 - val_precision: 0.7714 - val_recall: 0.7941\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.2459 - accuracy: 0.9134 - precision: 0.9190 - recall: 0.9190 - val_loss: 0.6046 - val_accuracy: 0.8235 - val_precision: 0.8235 - val_recall: 0.8235\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2464 - accuracy: 0.9228 - precision: 0.9176 - recall: 0.9228 - val_loss: 0.3668 - val_accuracy: 0.8235 - val_precision: 0.8286 - val_recall: 0.8529\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3345 - accuracy: 0.9115 - precision: 0.9007 - recall: 0.9058 - val_loss: 0.4750 - val_accuracy: 0.7941 - val_precision: 0.7714 - val_recall: 0.7941\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.2820 - accuracy: 0.9058 - precision: 0.9067 - recall: 0.9153 - val_loss: 0.3338 - val_accuracy: 0.7941 - val_precision: 0.7941 - val_recall: 0.7941\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2588 - accuracy: 0.9115 - precision: 0.9115 - recall: 0.9115 - val_loss: 0.4661 - val_accuracy: 0.7941 - val_precision: 0.8000 - val_recall: 0.8235\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2461 - accuracy: 0.9266 - precision: 0.9199 - recall: 0.9303 - val_loss: 0.4139 - val_accuracy: 0.7647 - val_precision: 0.7714 - val_recall: 0.7941\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3009 - accuracy: 0.9115 - precision: 0.9019 - recall: 0.9171 - val_loss: 0.5094 - val_accuracy: 0.8235 - val_precision: 0.8485 - val_recall: 0.8235\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2555 - accuracy: 0.9134 - precision: 0.9069 - recall: 0.9171 - val_loss: 0.6001 - val_accuracy: 0.7941 - val_precision: 0.7941 - val_recall: 0.7941\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.2195 - accuracy: 0.9341 - precision: 0.9307 - recall: 0.9360 - val_loss: 0.7142 - val_accuracy: 0.7941 - val_precision: 0.7941 - val_recall: 0.7941\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2562 - accuracy: 0.9303 - precision: 0.9306 - recall: 0.9341 - val_loss: 0.3554 - val_accuracy: 0.7647 - val_precision: 0.7500 - val_recall: 0.7941\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2805 - accuracy: 0.9134 - precision: 0.9082 - recall: 0.9134 - val_loss: 0.5591 - val_accuracy: 0.7941 - val_precision: 0.7941 - val_recall: 0.7941\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.2823 - accuracy: 0.9209 - precision: 0.9196 - recall: 0.9266 - val_loss: 0.4362 - val_accuracy: 0.8235 - val_precision: 0.8235 - val_recall: 0.8235\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.2680 - accuracy: 0.9171 - precision: 0.9294 - recall: 0.9171 - val_loss: 0.5880 - val_accuracy: 0.7941 - val_precision: 0.7941 - val_recall: 0.7941\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2741 - accuracy: 0.9190 - precision: 0.9151 - recall: 0.9134 - val_loss: 0.6424 - val_accuracy: 0.8235 - val_precision: 0.8235 - val_recall: 0.8235\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2769 - accuracy: 0.9284 - precision: 0.9238 - recall: 0.9360 - val_loss: 0.4775 - val_accuracy: 0.7647 - val_precision: 0.7879 - val_recall: 0.7647\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2214 - accuracy: 0.9322 - precision: 0.9239 - recall: 0.9379 - val_loss: 0.6455 - val_accuracy: 0.7941 - val_precision: 0.7941 - val_recall: 0.7941\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.2792 - accuracy: 0.9266 - precision: 0.9302 - recall: 0.9284 - val_loss: 0.5809 - val_accuracy: 0.8235 - val_precision: 0.8000 - val_recall: 0.8235\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2866 - accuracy: 0.9303 - precision: 0.9283 - recall: 0.9266 - val_loss: 0.4795 - val_accuracy: 0.8235 - val_precision: 0.8235 - val_recall: 0.8235\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2482 - accuracy: 0.9341 - precision: 0.9311 - recall: 0.9416 - val_loss: 0.6461 - val_accuracy: 0.8235 - val_precision: 0.8235 - val_recall: 0.8235\n",
      "Train on: [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "Test  on: 2\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 21:07:49.618787: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - ETA: 0s - loss: 0.9723 - accuracy: 0.5868 - precision: 0.6125 - recall: 0.5906"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 21:08:35.575575: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 50s 3s/step - loss: 0.9723 - accuracy: 0.5868 - precision: 0.6125 - recall: 0.5906 - val_loss: 0.5850 - val_accuracy: 0.9143 - val_precision: 0.8462 - val_recall: 0.9429\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 10s 827ms/step - loss: 0.9054 - accuracy: 0.6642 - precision: 0.6598 - recall: 0.6623 - val_loss: 0.5038 - val_accuracy: 0.7143 - val_precision: 0.7143 - val_recall: 0.7143\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 2s 221ms/step - loss: 0.7908 - accuracy: 0.7604 - precision: 0.7439 - recall: 0.7453 - val_loss: 0.4124 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 3s 319ms/step - loss: 0.6563 - accuracy: 0.8000 - precision: 0.7929 - recall: 0.8019 - val_loss: 0.3242 - val_accuracy: 0.9143 - val_precision: 0.9143 - val_recall: 0.9143\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 4s 385ms/step - loss: 0.6804 - accuracy: 0.8019 - precision: 0.8049 - recall: 0.8019 - val_loss: 0.3066 - val_accuracy: 1.0000 - val_precision: 0.9722 - val_recall: 1.0000\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 2s 183ms/step - loss: 0.6316 - accuracy: 0.8019 - precision: 0.7948 - recall: 0.8038 - val_loss: 0.2289 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 2s 213ms/step - loss: 0.5939 - accuracy: 0.8358 - precision: 0.8365 - recall: 0.8396 - val_loss: 0.2670 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 2s 242ms/step - loss: 0.5857 - accuracy: 0.8358 - precision: 0.8333 - recall: 0.8396 - val_loss: 0.2119 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 1s 62ms/step - loss: 0.5791 - accuracy: 0.8321 - precision: 0.8324 - recall: 0.8340 - val_loss: 0.2074 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 2s 145ms/step - loss: 0.5952 - accuracy: 0.8396 - precision: 0.8431 - recall: 0.8415 - val_loss: 0.2230 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 38ms/step - loss: 0.5924 - accuracy: 0.8491 - precision: 0.8491 - recall: 0.8491 - val_loss: 0.1755 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 2s 173ms/step - loss: 0.5647 - accuracy: 0.8415 - precision: 0.8412 - recall: 0.8396 - val_loss: 0.1879 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 2s 161ms/step - loss: 0.5763 - accuracy: 0.8396 - precision: 0.8467 - recall: 0.8340 - val_loss: 0.1979 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 42ms/step - loss: 0.5877 - accuracy: 0.8340 - precision: 0.8343 - recall: 0.8264 - val_loss: 0.2477 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 1s 89ms/step - loss: 0.5466 - accuracy: 0.8566 - precision: 0.8553 - recall: 0.8585 - val_loss: 0.2248 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 1s 58ms/step - loss: 0.5147 - accuracy: 0.8642 - precision: 0.8631 - recall: 0.8566 - val_loss: 0.2581 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 1s 83ms/step - loss: 0.5565 - accuracy: 0.8453 - precision: 0.8431 - recall: 0.8415 - val_loss: 0.1883 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 0.5244 - accuracy: 0.8509 - precision: 0.8486 - recall: 0.8566 - val_loss: 0.2654 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 1s 74ms/step - loss: 0.5130 - accuracy: 0.8453 - precision: 0.8450 - recall: 0.8434 - val_loss: 0.1739 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.6187 - accuracy: 0.8283 - precision: 0.8211 - recall: 0.8226 - val_loss: 0.2243 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.9714\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.4893 - accuracy: 0.8660 - precision: 0.8649 - recall: 0.8698 - val_loss: 0.1562 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 1s 108ms/step - loss: 0.4884 - accuracy: 0.8679 - precision: 0.8652 - recall: 0.8717 - val_loss: 0.1050 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 1s 89ms/step - loss: 0.5181 - accuracy: 0.8415 - precision: 0.8444 - recall: 0.8396 - val_loss: 0.2669 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 4s 358ms/step - loss: 0.4737 - accuracy: 0.8566 - precision: 0.8531 - recall: 0.8547 - val_loss: 0.1414 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 2s 196ms/step - loss: 0.5358 - accuracy: 0.8321 - precision: 0.8321 - recall: 0.8321 - val_loss: 0.1973 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 1s 73ms/step - loss: 0.4711 - accuracy: 0.8792 - precision: 0.8816 - recall: 0.8849 - val_loss: 0.1632 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 1s 128ms/step - loss: 0.4738 - accuracy: 0.8660 - precision: 0.8689 - recall: 0.8755 - val_loss: 0.1782 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 0.4408 - accuracy: 0.8660 - precision: 0.8658 - recall: 0.8642 - val_loss: 0.1472 - val_accuracy: 0.9714 - val_precision: 1.0000 - val_recall: 0.9714\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.4812 - accuracy: 0.8509 - precision: 0.8571 - recall: 0.8491 - val_loss: 0.2009 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.4588 - accuracy: 0.8453 - precision: 0.8495 - recall: 0.8415 - val_loss: 0.1581 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.4142 - accuracy: 0.8642 - precision: 0.8710 - recall: 0.8660 - val_loss: 0.1164 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 0.4782 - accuracy: 0.8679 - precision: 0.8688 - recall: 0.8623 - val_loss: 0.1580 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.4239 - accuracy: 0.8868 - precision: 0.8764 - recall: 0.8830 - val_loss: 0.1162 - val_accuracy: 0.9714 - val_precision: 0.9722 - val_recall: 1.0000\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.4133 - accuracy: 0.8717 - precision: 0.8710 - recall: 0.8660 - val_loss: 0.1491 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.4137 - accuracy: 0.8698 - precision: 0.8682 - recall: 0.8698 - val_loss: 0.1456 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 0.4300 - accuracy: 0.8585 - precision: 0.8539 - recall: 0.8604 - val_loss: 0.1432 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 2s 176ms/step - loss: 0.4375 - accuracy: 0.8755 - precision: 0.8771 - recall: 0.8755 - val_loss: 0.1571 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 5s 524ms/step - loss: 0.4093 - accuracy: 0.8623 - precision: 0.8698 - recall: 0.8698 - val_loss: 0.1833 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.4027 - accuracy: 0.8736 - precision: 0.8701 - recall: 0.8717 - val_loss: 0.1143 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 0.3834 - accuracy: 0.8849 - precision: 0.8830 - recall: 0.8830 - val_loss: 0.1591 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 41ms/step - loss: 0.3722 - accuracy: 0.8774 - precision: 0.8767 - recall: 0.8717 - val_loss: 0.0934 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.3911 - accuracy: 0.8792 - precision: 0.8733 - recall: 0.8717 - val_loss: 0.0925 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3855 - accuracy: 0.8755 - precision: 0.8817 - recall: 0.8717 - val_loss: 0.1464 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.4493 - accuracy: 0.8679 - precision: 0.8686 - recall: 0.8604 - val_loss: 0.2032 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3799 - accuracy: 0.8736 - precision: 0.8741 - recall: 0.8774 - val_loss: 0.1742 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3669 - accuracy: 0.8792 - precision: 0.8764 - recall: 0.8830 - val_loss: 0.1140 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 0.3527 - accuracy: 0.8774 - precision: 0.8792 - recall: 0.8792 - val_loss: 0.1088 - val_accuracy: 0.9714 - val_precision: 1.0000 - val_recall: 0.9714\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.3546 - accuracy: 0.8906 - precision: 0.8973 - recall: 0.8736 - val_loss: 0.1386 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3431 - accuracy: 0.8925 - precision: 0.8937 - recall: 0.8887 - val_loss: 0.1473 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3810 - accuracy: 0.8811 - precision: 0.8767 - recall: 0.8717 - val_loss: 0.1383 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3511 - accuracy: 0.8906 - precision: 0.8899 - recall: 0.8849 - val_loss: 0.1288 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3745 - accuracy: 0.8774 - precision: 0.8769 - recall: 0.8868 - val_loss: 0.1790 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3958 - accuracy: 0.8642 - precision: 0.8679 - recall: 0.8679 - val_loss: 0.1286 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3160 - accuracy: 0.8962 - precision: 0.8843 - recall: 0.8943 - val_loss: 0.1121 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3938 - accuracy: 0.8623 - precision: 0.8606 - recall: 0.8623 - val_loss: 0.1528 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3208 - accuracy: 0.8906 - precision: 0.8904 - recall: 0.8887 - val_loss: 0.1347 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3247 - accuracy: 0.8943 - precision: 0.8971 - recall: 0.8887 - val_loss: 0.1307 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.3612 - accuracy: 0.8925 - precision: 0.8935 - recall: 0.8868 - val_loss: 0.1292 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3277 - accuracy: 0.8981 - precision: 0.8962 - recall: 0.8962 - val_loss: 0.1130 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.3316 - accuracy: 0.8981 - precision: 0.9021 - recall: 0.9038 - val_loss: 0.1453 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3619 - accuracy: 0.9000 - precision: 0.8899 - recall: 0.9000 - val_loss: 0.1302 - val_accuracy: 0.9714 - val_precision: 0.9722 - val_recall: 1.0000\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3331 - accuracy: 0.9000 - precision: 0.8947 - recall: 0.8981 - val_loss: 0.1163 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3620 - accuracy: 0.8792 - precision: 0.8778 - recall: 0.8811 - val_loss: 0.1548 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3699 - accuracy: 0.8868 - precision: 0.8849 - recall: 0.8849 - val_loss: 0.1491 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Train on: [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "Test  on: 3\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 21:09:46.505711: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - ETA: 0s - loss: 0.9650 - accuracy: 0.6094 - precision: 0.6029 - recall: 0.6189"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 21:10:31.031116: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 48s 3s/step - loss: 0.9650 - accuracy: 0.6094 - precision: 0.6029 - recall: 0.6189 - val_loss: 0.6637 - val_accuracy: 0.6857 - val_precision: 0.6500 - val_recall: 0.7429\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 7s 616ms/step - loss: 0.8792 - accuracy: 0.6811 - precision: 0.6780 - recall: 0.6755 - val_loss: 0.5947 - val_accuracy: 0.7714 - val_precision: 0.7714 - val_recall: 0.7714\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 5s 486ms/step - loss: 0.7204 - accuracy: 0.7755 - precision: 0.7744 - recall: 0.7774 - val_loss: 0.3360 - val_accuracy: 0.9429 - val_precision: 0.9706 - val_recall: 0.9429\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 2s 187ms/step - loss: 0.6683 - accuracy: 0.8075 - precision: 0.8095 - recall: 0.8019 - val_loss: 0.2678 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 1s 98ms/step - loss: 0.6231 - accuracy: 0.8226 - precision: 0.8230 - recall: 0.8245 - val_loss: 0.2863 - val_accuracy: 0.9429 - val_precision: 0.9706 - val_recall: 0.9429\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 2s 168ms/step - loss: 0.6163 - accuracy: 0.8208 - precision: 0.8195 - recall: 0.8226 - val_loss: 0.2971 - val_accuracy: 0.9714 - val_precision: 0.9444 - val_recall: 0.9714\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 1s 142ms/step - loss: 0.5840 - accuracy: 0.8358 - precision: 0.8358 - recall: 0.8358 - val_loss: 0.2729 - val_accuracy: 0.9714 - val_precision: 0.9722 - val_recall: 1.0000\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 1s 93ms/step - loss: 0.5817 - accuracy: 0.8396 - precision: 0.8440 - recall: 0.8472 - val_loss: 0.4320 - val_accuracy: 0.8000 - val_precision: 0.8000 - val_recall: 0.8000\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 2s 246ms/step - loss: 0.5689 - accuracy: 0.8358 - precision: 0.8349 - recall: 0.8396 - val_loss: 0.3477 - val_accuracy: 0.8857 - val_precision: 0.8889 - val_recall: 0.9143\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 2s 206ms/step - loss: 0.5949 - accuracy: 0.8132 - precision: 0.8154 - recall: 0.8170 - val_loss: 0.2159 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 2s 151ms/step - loss: 0.5681 - accuracy: 0.8509 - precision: 0.8518 - recall: 0.8566 - val_loss: 0.2940 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 4s 353ms/step - loss: 0.5589 - accuracy: 0.8472 - precision: 0.8487 - recall: 0.8358 - val_loss: 0.3088 - val_accuracy: 0.9429 - val_precision: 0.9167 - val_recall: 0.9429\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 2s 156ms/step - loss: 0.5306 - accuracy: 0.8358 - precision: 0.8343 - recall: 0.8358 - val_loss: 0.1772 - val_accuracy: 0.9429 - val_precision: 0.9444 - val_recall: 0.9714\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.6196 - accuracy: 0.8132 - precision: 0.8187 - recall: 0.8094 - val_loss: 0.2306 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 1s 98ms/step - loss: 0.4942 - accuracy: 0.8472 - precision: 0.8498 - recall: 0.8434 - val_loss: 0.1865 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 1s 83ms/step - loss: 0.5297 - accuracy: 0.8509 - precision: 0.8512 - recall: 0.8528 - val_loss: 0.2547 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 1s 83ms/step - loss: 0.5495 - accuracy: 0.8377 - precision: 0.8405 - recall: 0.8453 - val_loss: 0.2347 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 1s 63ms/step - loss: 0.5213 - accuracy: 0.8491 - precision: 0.8480 - recall: 0.8528 - val_loss: 0.1629 - val_accuracy: 0.9714 - val_precision: 0.9722 - val_recall: 1.0000\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 39ms/step - loss: 0.5020 - accuracy: 0.8396 - precision: 0.8427 - recall: 0.8491 - val_loss: 0.1995 - val_accuracy: 0.9714 - val_precision: 0.9722 - val_recall: 1.0000\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 38ms/step - loss: 0.4995 - accuracy: 0.8642 - precision: 0.8558 - recall: 0.8623 - val_loss: 0.2852 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.5326 - accuracy: 0.8509 - precision: 0.8477 - recall: 0.8509 - val_loss: 0.1893 - val_accuracy: 0.9714 - val_precision: 0.9722 - val_recall: 1.0000\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.5037 - accuracy: 0.8321 - precision: 0.8406 - recall: 0.8358 - val_loss: 0.2567 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 7s 633ms/step - loss: 0.5130 - accuracy: 0.8604 - precision: 0.8588 - recall: 0.8604 - val_loss: 0.2197 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 1s 63ms/step - loss: 0.5283 - accuracy: 0.8491 - precision: 0.8488 - recall: 0.8472 - val_loss: 0.1993 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 1s 99ms/step - loss: 0.4875 - accuracy: 0.8547 - precision: 0.8537 - recall: 0.8585 - val_loss: 0.2080 - val_accuracy: 1.0000 - val_precision: 0.9459 - val_recall: 1.0000\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 2s 154ms/step - loss: 0.4734 - accuracy: 0.8736 - precision: 0.8743 - recall: 0.8660 - val_loss: 0.1310 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.5397 - accuracy: 0.8396 - precision: 0.8473 - recall: 0.8377 - val_loss: 0.3076 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.4763 - accuracy: 0.8509 - precision: 0.8464 - recall: 0.8528 - val_loss: 0.2756 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 1s 99ms/step - loss: 0.4610 - accuracy: 0.8755 - precision: 0.8722 - recall: 0.8755 - val_loss: 0.1516 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 1s 59ms/step - loss: 0.4891 - accuracy: 0.8585 - precision: 0.8547 - recall: 0.8547 - val_loss: 0.2611 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 2s 190ms/step - loss: 0.4197 - accuracy: 0.8698 - precision: 0.8710 - recall: 0.8660 - val_loss: 0.1274 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.4577 - accuracy: 0.8623 - precision: 0.8639 - recall: 0.8623 - val_loss: 0.2393 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.4532 - accuracy: 0.8698 - precision: 0.8703 - recall: 0.8736 - val_loss: 0.1703 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.4389 - accuracy: 0.8679 - precision: 0.8721 - recall: 0.8623 - val_loss: 0.2295 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.4603 - accuracy: 0.8755 - precision: 0.8762 - recall: 0.8679 - val_loss: 0.1248 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.4477 - accuracy: 0.8698 - precision: 0.8668 - recall: 0.8717 - val_loss: 0.0952 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.4286 - accuracy: 0.8755 - precision: 0.8719 - recall: 0.8736 - val_loss: 0.1259 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.3876 - accuracy: 0.8906 - precision: 0.8891 - recall: 0.8925 - val_loss: 0.1838 - val_accuracy: 0.9429 - val_precision: 0.9412 - val_recall: 0.9143\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.4296 - accuracy: 0.8698 - precision: 0.8679 - recall: 0.8679 - val_loss: 0.0909 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 1s 84ms/step - loss: 0.4248 - accuracy: 0.8774 - precision: 0.8817 - recall: 0.8717 - val_loss: 0.1138 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.4113 - accuracy: 0.8774 - precision: 0.8780 - recall: 0.8830 - val_loss: 0.1259 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3857 - accuracy: 0.8792 - precision: 0.8771 - recall: 0.8887 - val_loss: 0.2231 - val_accuracy: 0.9143 - val_precision: 0.9143 - val_recall: 0.9143\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.4145 - accuracy: 0.8774 - precision: 0.8750 - recall: 0.8717 - val_loss: 0.1549 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.4068 - accuracy: 0.8811 - precision: 0.8861 - recall: 0.8811 - val_loss: 0.0965 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3845 - accuracy: 0.8811 - precision: 0.8819 - recall: 0.8736 - val_loss: 0.0982 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3952 - accuracy: 0.8792 - precision: 0.8762 - recall: 0.8811 - val_loss: 0.1006 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3639 - accuracy: 0.8887 - precision: 0.8889 - recall: 0.8906 - val_loss: 0.1730 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.3891 - accuracy: 0.8868 - precision: 0.8897 - recall: 0.8830 - val_loss: 0.0936 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3677 - accuracy: 0.8849 - precision: 0.8906 - recall: 0.8906 - val_loss: 0.1292 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.3928 - accuracy: 0.8736 - precision: 0.8800 - recall: 0.8717 - val_loss: 0.0795 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.5958 - accuracy: 0.8434 - precision: 0.8343 - recall: 0.8358 - val_loss: 0.1171 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3586 - accuracy: 0.8774 - precision: 0.8780 - recall: 0.8830 - val_loss: 0.0956 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3468 - accuracy: 0.8887 - precision: 0.8943 - recall: 0.8943 - val_loss: 0.0964 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.3578 - accuracy: 0.8887 - precision: 0.8856 - recall: 0.8906 - val_loss: 0.0720 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3343 - accuracy: 0.8849 - precision: 0.8811 - recall: 0.8811 - val_loss: 0.1022 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3601 - accuracy: 0.8736 - precision: 0.8819 - recall: 0.8736 - val_loss: 0.0787 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3746 - accuracy: 0.8868 - precision: 0.8936 - recall: 0.8717 - val_loss: 0.1127 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3386 - accuracy: 0.8830 - precision: 0.8845 - recall: 0.8811 - val_loss: 0.2756 - val_accuracy: 0.8857 - val_precision: 0.8857 - val_recall: 0.8857\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.3509 - accuracy: 0.8811 - precision: 0.8849 - recall: 0.8849 - val_loss: 0.0500 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.9714\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3579 - accuracy: 0.8849 - precision: 0.8944 - recall: 0.8792 - val_loss: 0.1007 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3364 - accuracy: 0.8792 - precision: 0.8821 - recall: 0.8755 - val_loss: 0.0722 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.9714\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3464 - accuracy: 0.8849 - precision: 0.8866 - recall: 0.8849 - val_loss: 0.1058 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3293 - accuracy: 0.8906 - precision: 0.8906 - recall: 0.8906 - val_loss: 0.0756 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3403 - accuracy: 0.8887 - precision: 0.8837 - recall: 0.8887 - val_loss: 0.1159 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3380 - accuracy: 0.8830 - precision: 0.8811 - recall: 0.8811 - val_loss: 0.1707 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3127 - accuracy: 0.8943 - precision: 0.8912 - recall: 0.8962 - val_loss: 0.0786 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 0.3749 - accuracy: 0.8623 - precision: 0.8693 - recall: 0.8660 - val_loss: 0.1254 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3200 - accuracy: 0.8943 - precision: 0.9025 - recall: 0.8906 - val_loss: 0.0872 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.9714\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3420 - accuracy: 0.8830 - precision: 0.8946 - recall: 0.8811 - val_loss: 0.1002 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2831 - accuracy: 0.9113 - precision: 0.9075 - recall: 0.9075 - val_loss: 0.1066 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.9714\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3280 - accuracy: 0.8943 - precision: 0.8972 - recall: 0.9057 - val_loss: 0.2583 - val_accuracy: 0.9143 - val_precision: 0.9118 - val_recall: 0.8857\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3439 - accuracy: 0.8717 - precision: 0.8802 - recall: 0.8736 - val_loss: 0.0648 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3172 - accuracy: 0.8925 - precision: 0.8870 - recall: 0.8887 - val_loss: 0.1399 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3188 - accuracy: 0.8887 - precision: 0.8914 - recall: 0.8830 - val_loss: 0.0759 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.9714\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3895 - accuracy: 0.8981 - precision: 0.8990 - recall: 0.8906 - val_loss: 0.0847 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2934 - accuracy: 0.9019 - precision: 0.8998 - recall: 0.8981 - val_loss: 0.0943 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3205 - accuracy: 0.8887 - precision: 0.8946 - recall: 0.8811 - val_loss: 0.0914 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.9714\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3036 - accuracy: 0.9094 - precision: 0.9105 - recall: 0.9019 - val_loss: 0.0766 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.9714\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2811 - accuracy: 0.9094 - precision: 0.9138 - recall: 0.9000 - val_loss: 0.0809 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.2901 - accuracy: 0.9151 - precision: 0.9141 - recall: 0.9038 - val_loss: 0.0953 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2834 - accuracy: 0.9075 - precision: 0.9089 - recall: 0.9038 - val_loss: 0.0827 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.9714\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3145 - accuracy: 0.9113 - precision: 0.9034 - recall: 0.9000 - val_loss: 0.0602 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.9714\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3322 - accuracy: 0.8925 - precision: 0.9000 - recall: 0.8830 - val_loss: 0.1070 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.9714\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.2837 - accuracy: 0.9075 - precision: 0.9032 - recall: 0.8981 - val_loss: 0.0602 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.9714\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3281 - accuracy: 0.8849 - precision: 0.8880 - recall: 0.8830 - val_loss: 0.0807 - val_accuracy: 0.9714 - val_precision: 1.0000 - val_recall: 0.9714\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2930 - accuracy: 0.9038 - precision: 0.9006 - recall: 0.9057 - val_loss: 0.0989 - val_accuracy: 0.9714 - val_precision: 1.0000 - val_recall: 0.9714\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2680 - accuracy: 0.9208 - precision: 0.9271 - recall: 0.9113 - val_loss: 0.1376 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.9714\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2603 - accuracy: 0.9075 - precision: 0.9149 - recall: 0.9132 - val_loss: 0.0505 - val_accuracy: 0.9714 - val_precision: 1.0000 - val_recall: 0.9714\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2762 - accuracy: 0.9208 - precision: 0.9189 - recall: 0.9189 - val_loss: 0.1043 - val_accuracy: 0.9714 - val_precision: 1.0000 - val_recall: 0.9714\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3374 - accuracy: 0.8981 - precision: 0.8964 - recall: 0.8811 - val_loss: 0.0762 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.2738 - accuracy: 0.9094 - precision: 0.9189 - recall: 0.8981 - val_loss: 0.0966 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2829 - accuracy: 0.9151 - precision: 0.9086 - recall: 0.9189 - val_loss: 0.0733 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2932 - accuracy: 0.9226 - precision: 0.9202 - recall: 0.9132 - val_loss: 0.0733 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.9714\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2856 - accuracy: 0.9113 - precision: 0.9043 - recall: 0.9094 - val_loss: 0.0557 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.2716 - accuracy: 0.9132 - precision: 0.9112 - recall: 0.9094 - val_loss: 0.0755 - val_accuracy: 0.9714 - val_precision: 1.0000 - val_recall: 0.9714\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.2923 - accuracy: 0.9226 - precision: 0.9272 - recall: 0.9132 - val_loss: 0.0712 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2553 - accuracy: 0.9245 - precision: 0.9223 - recall: 0.9189 - val_loss: 0.0777 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3220 - accuracy: 0.9057 - precision: 0.9019 - recall: 0.9019 - val_loss: 0.0950 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.2645 - accuracy: 0.9189 - precision: 0.9215 - recall: 0.9075 - val_loss: 0.0828 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2773 - accuracy: 0.9189 - precision: 0.9121 - recall: 0.9208 - val_loss: 0.0578 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Train on: [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "Test  on: 4\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 21:11:47.431027: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - ETA: 0s - loss: 0.9937 - accuracy: 0.6509 - precision: 0.6201 - recall: 0.6623"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 21:12:24.106081: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 41s 3s/step - loss: 0.9937 - accuracy: 0.6509 - precision: 0.6201 - recall: 0.6623 - val_loss: 0.6178 - val_accuracy: 0.6571 - val_precision: 0.6970 - val_recall: 0.6571\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 8s 798ms/step - loss: 0.9165 - accuracy: 0.6717 - precision: 0.6692 - recall: 0.6717 - val_loss: 0.4921 - val_accuracy: 0.8571 - val_precision: 0.8571 - val_recall: 0.8571\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 6s 543ms/step - loss: 0.7669 - accuracy: 0.7509 - precision: 0.7429 - recall: 0.7415 - val_loss: 0.5139 - val_accuracy: 0.7143 - val_precision: 0.7143 - val_recall: 0.7143\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 3s 254ms/step - loss: 0.6981 - accuracy: 0.7906 - precision: 0.7887 - recall: 0.7887 - val_loss: 0.3250 - val_accuracy: 0.9143 - val_precision: 0.9143 - val_recall: 0.9143\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 3s 252ms/step - loss: 0.6494 - accuracy: 0.8245 - precision: 0.8156 - recall: 0.8264 - val_loss: 0.2346 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 2s 209ms/step - loss: 0.6182 - accuracy: 0.8340 - precision: 0.8302 - recall: 0.8302 - val_loss: 0.2415 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 1s 74ms/step - loss: 0.6040 - accuracy: 0.8283 - precision: 0.8346 - recall: 0.8189 - val_loss: 0.2672 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 3s 286ms/step - loss: 0.5859 - accuracy: 0.8358 - precision: 0.8305 - recall: 0.8321 - val_loss: 0.2654 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 1s 134ms/step - loss: 0.5422 - accuracy: 0.8264 - precision: 0.8261 - recall: 0.8245 - val_loss: 0.2794 - val_accuracy: 0.9429 - val_precision: 0.9412 - val_recall: 0.9143\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 0.5993 - accuracy: 0.8358 - precision: 0.8318 - recall: 0.8396 - val_loss: 0.2466 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 1s 64ms/step - loss: 0.5241 - accuracy: 0.8491 - precision: 0.8446 - recall: 0.8509 - val_loss: 0.2397 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 0.5491 - accuracy: 0.8453 - precision: 0.8402 - recall: 0.8434 - val_loss: 0.2501 - val_accuracy: 0.9143 - val_precision: 0.9412 - val_recall: 0.9143\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.6258 - accuracy: 0.8358 - precision: 0.8381 - recall: 0.8302 - val_loss: 0.2562 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.4964 - accuracy: 0.8623 - precision: 0.8590 - recall: 0.8623 - val_loss: 0.2410 - val_accuracy: 0.9143 - val_precision: 0.9143 - val_recall: 0.9143\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 1s 100ms/step - loss: 0.5089 - accuracy: 0.8547 - precision: 0.8598 - recall: 0.8679 - val_loss: 0.2687 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.5004 - accuracy: 0.8509 - precision: 0.8571 - recall: 0.8491 - val_loss: 0.2585 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 1s 122ms/step - loss: 0.5480 - accuracy: 0.8377 - precision: 0.8393 - recall: 0.8377 - val_loss: 0.2338 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 1s 88ms/step - loss: 0.5370 - accuracy: 0.8396 - precision: 0.8397 - recall: 0.8302 - val_loss: 0.2455 - val_accuracy: 0.9143 - val_precision: 0.9143 - val_recall: 0.9143\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.4715 - accuracy: 0.8717 - precision: 0.8701 - recall: 0.8717 - val_loss: 0.2296 - val_accuracy: 0.9143 - val_precision: 0.9143 - val_recall: 0.9143\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.5421 - accuracy: 0.8377 - precision: 0.8362 - recall: 0.8377 - val_loss: 0.2583 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.4712 - accuracy: 0.8623 - precision: 0.8585 - recall: 0.8585 - val_loss: 0.2186 - val_accuracy: 0.9143 - val_precision: 0.9412 - val_recall: 0.9143\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 6s 617ms/step - loss: 0.5393 - accuracy: 0.8453 - precision: 0.8475 - recall: 0.8491 - val_loss: 0.2365 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 2s 161ms/step - loss: 0.4630 - accuracy: 0.8623 - precision: 0.8609 - recall: 0.8642 - val_loss: 0.2311 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 1s 60ms/step - loss: 0.4689 - accuracy: 0.8679 - precision: 0.8760 - recall: 0.8660 - val_loss: 0.2592 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 2s 205ms/step - loss: 0.4610 - accuracy: 0.8453 - precision: 0.8541 - recall: 0.8396 - val_loss: 0.2367 - val_accuracy: 0.9143 - val_precision: 0.9143 - val_recall: 0.9143\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 2s 163ms/step - loss: 0.4588 - accuracy: 0.8642 - precision: 0.8650 - recall: 0.8585 - val_loss: 0.1754 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.4757 - accuracy: 0.8698 - precision: 0.8696 - recall: 0.8679 - val_loss: 0.2497 - val_accuracy: 0.9143 - val_precision: 0.9143 - val_recall: 0.9143\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.4342 - accuracy: 0.8736 - precision: 0.8717 - recall: 0.8717 - val_loss: 0.2445 - val_accuracy: 0.9143 - val_precision: 0.9143 - val_recall: 0.9143\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.4700 - accuracy: 0.8491 - precision: 0.8430 - recall: 0.8509 - val_loss: 0.2302 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.4280 - accuracy: 0.8792 - precision: 0.8819 - recall: 0.8736 - val_loss: 0.2343 - val_accuracy: 0.9429 - val_precision: 0.9167 - val_recall: 0.9429\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.4078 - accuracy: 0.8736 - precision: 0.8757 - recall: 0.8774 - val_loss: 0.2633 - val_accuracy: 0.9143 - val_precision: 0.9143 - val_recall: 0.9143\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.4191 - accuracy: 0.8830 - precision: 0.8828 - recall: 0.8811 - val_loss: 0.4034 - val_accuracy: 0.8857 - val_precision: 0.8857 - val_recall: 0.8857\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 0.4908 - accuracy: 0.8472 - precision: 0.8593 - recall: 0.8415 - val_loss: 0.2161 - val_accuracy: 0.9429 - val_precision: 0.9167 - val_recall: 0.9429\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.4151 - accuracy: 0.8792 - precision: 0.8731 - recall: 0.8698 - val_loss: 0.2312 - val_accuracy: 0.9143 - val_precision: 0.9143 - val_recall: 0.9143\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.4070 - accuracy: 0.8717 - precision: 0.8719 - recall: 0.8736 - val_loss: 0.2379 - val_accuracy: 0.9143 - val_precision: 0.9143 - val_recall: 0.9143\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3876 - accuracy: 0.8830 - precision: 0.8864 - recall: 0.8830 - val_loss: 0.2130 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.4388 - accuracy: 0.8698 - precision: 0.8750 - recall: 0.8717 - val_loss: 0.2411 - val_accuracy: 0.9143 - val_precision: 0.9118 - val_recall: 0.8857\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.4352 - accuracy: 0.8642 - precision: 0.8697 - recall: 0.8566 - val_loss: 0.1865 - val_accuracy: 0.9143 - val_precision: 0.9167 - val_recall: 0.9429\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 2s 176ms/step - loss: 0.3902 - accuracy: 0.8906 - precision: 0.8887 - recall: 0.8887 - val_loss: 0.1872 - val_accuracy: 0.9143 - val_precision: 0.9143 - val_recall: 0.9143\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3966 - accuracy: 0.8887 - precision: 0.8820 - recall: 0.8887 - val_loss: 0.2448 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.4509 - accuracy: 0.8604 - precision: 0.8596 - recall: 0.8660 - val_loss: 0.1623 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3826 - accuracy: 0.8830 - precision: 0.8872 - recall: 0.8755 - val_loss: 0.2274 - val_accuracy: 0.9143 - val_precision: 0.9118 - val_recall: 0.8857\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 0.3392 - accuracy: 0.8943 - precision: 0.9010 - recall: 0.8925 - val_loss: 0.1135 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3961 - accuracy: 0.8811 - precision: 0.8840 - recall: 0.8774 - val_loss: 0.1659 - val_accuracy: 0.9143 - val_precision: 0.9143 - val_recall: 0.9143\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3954 - accuracy: 0.8698 - precision: 0.8696 - recall: 0.8679 - val_loss: 0.1982 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3370 - accuracy: 0.8887 - precision: 0.8956 - recall: 0.8906 - val_loss: 0.1185 - val_accuracy: 0.9429 - val_precision: 0.9706 - val_recall: 0.9429\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3599 - accuracy: 0.8887 - precision: 0.8920 - recall: 0.8887 - val_loss: 0.1470 - val_accuracy: 0.9143 - val_precision: 0.9143 - val_recall: 0.9143\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3843 - accuracy: 0.8774 - precision: 0.8727 - recall: 0.8792 - val_loss: 0.1459 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3486 - accuracy: 0.9000 - precision: 0.8979 - recall: 0.8962 - val_loss: 0.1390 - val_accuracy: 0.9143 - val_precision: 0.9412 - val_recall: 0.9143\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.3638 - accuracy: 0.8887 - precision: 0.8908 - recall: 0.8925 - val_loss: 0.1153 - val_accuracy: 0.9429 - val_precision: 0.9412 - val_recall: 0.9143\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.3255 - accuracy: 0.8981 - precision: 0.8958 - recall: 0.8925 - val_loss: 0.1424 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3460 - accuracy: 0.8887 - precision: 0.8897 - recall: 0.8830 - val_loss: 0.1462 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3676 - accuracy: 0.8925 - precision: 0.8835 - recall: 0.8868 - val_loss: 0.1291 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3484 - accuracy: 0.8830 - precision: 0.8828 - recall: 0.8811 - val_loss: 0.1980 - val_accuracy: 0.9429 - val_precision: 0.9444 - val_recall: 0.9714\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3615 - accuracy: 0.8887 - precision: 0.8874 - recall: 0.8925 - val_loss: 0.1212 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.3328 - accuracy: 0.8868 - precision: 0.8839 - recall: 0.8906 - val_loss: 0.1123 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3472 - accuracy: 0.8906 - precision: 0.8952 - recall: 0.8868 - val_loss: 0.1153 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.3046 - accuracy: 0.9019 - precision: 0.9002 - recall: 0.9019 - val_loss: 0.1014 - val_accuracy: 0.9429 - val_precision: 0.9706 - val_recall: 0.9429\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3992 - accuracy: 0.8887 - precision: 0.8904 - recall: 0.8887 - val_loss: 0.1258 - val_accuracy: 0.9714 - val_precision: 0.9706 - val_recall: 0.9429\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.3129 - accuracy: 0.9075 - precision: 0.9040 - recall: 0.9057 - val_loss: 0.0976 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3541 - accuracy: 0.8962 - precision: 0.8998 - recall: 0.8981 - val_loss: 0.1851 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.3202 - accuracy: 0.8943 - precision: 0.8985 - recall: 0.8849 - val_loss: 0.0729 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2962 - accuracy: 0.9038 - precision: 0.9070 - recall: 0.9019 - val_loss: 0.0800 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3048 - accuracy: 0.9057 - precision: 0.9055 - recall: 0.9038 - val_loss: 0.0753 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3159 - accuracy: 0.9038 - precision: 0.8996 - recall: 0.8962 - val_loss: 0.1341 - val_accuracy: 0.9143 - val_precision: 0.9412 - val_recall: 0.9143\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3316 - accuracy: 0.9094 - precision: 0.9049 - recall: 0.8981 - val_loss: 0.1356 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3342 - accuracy: 0.8830 - precision: 0.8849 - recall: 0.8849 - val_loss: 0.0738 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3251 - accuracy: 0.9094 - precision: 0.9113 - recall: 0.9113 - val_loss: 0.0771 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3303 - accuracy: 0.9019 - precision: 0.9019 - recall: 0.9019 - val_loss: 0.1346 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3174 - accuracy: 0.9057 - precision: 0.9015 - recall: 0.8981 - val_loss: 0.0859 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 5s 525ms/step - loss: 0.3252 - accuracy: 0.8962 - precision: 0.9065 - recall: 0.8962 - val_loss: 0.1269 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 1s 115ms/step - loss: 0.4302 - accuracy: 0.8943 - precision: 0.8860 - recall: 0.8943 - val_loss: 0.1116 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 39ms/step - loss: 0.3160 - accuracy: 0.8830 - precision: 0.8925 - recall: 0.8925 - val_loss: 0.0832 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Train on: [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "Test  on: 5\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 21:13:37.249122: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - ETA: 0s - loss: 0.9824 - accuracy: 0.6208 - precision: 0.6326 - recall: 0.5491"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 21:14:24.631418: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 52s 4s/step - loss: 0.9824 - accuracy: 0.6208 - precision: 0.6326 - recall: 0.5491 - val_loss: 0.6677 - val_accuracy: 0.6286 - val_precision: 0.7000 - val_recall: 0.6000\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.9077 - accuracy: 0.6566 - precision: 0.6634 - recall: 0.6434 - val_loss: 0.5863 - val_accuracy: 0.7714 - val_precision: 0.7714 - val_recall: 0.7714\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 8s 547ms/step - loss: 0.7867 - accuracy: 0.7396 - precision: 0.7402 - recall: 0.7472 - val_loss: 0.2953 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 2s 217ms/step - loss: 0.6978 - accuracy: 0.7830 - precision: 0.7939 - recall: 0.7849 - val_loss: 0.4550 - val_accuracy: 0.7714 - val_precision: 0.7879 - val_recall: 0.7429\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 1s 58ms/step - loss: 0.6631 - accuracy: 0.7906 - precision: 0.7821 - recall: 0.7925 - val_loss: 0.3453 - val_accuracy: 0.8857 - val_precision: 0.8857 - val_recall: 0.8857\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 2s 247ms/step - loss: 0.5786 - accuracy: 0.8358 - precision: 0.8286 - recall: 0.8302 - val_loss: 0.2916 - val_accuracy: 0.9143 - val_precision: 0.9118 - val_recall: 0.8857\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 3s 274ms/step - loss: 0.6596 - accuracy: 0.8057 - precision: 0.7992 - recall: 0.8038 - val_loss: 0.2775 - val_accuracy: 0.9143 - val_precision: 0.9143 - val_recall: 0.9143\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 3s 299ms/step - loss: 0.5623 - accuracy: 0.8547 - precision: 0.8473 - recall: 0.8585 - val_loss: 0.4986 - val_accuracy: 0.7714 - val_precision: 0.7714 - val_recall: 0.7714\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 3s 322ms/step - loss: 0.5872 - accuracy: 0.8321 - precision: 0.8314 - recall: 0.8283 - val_loss: 0.8035 - val_accuracy: 0.4000 - val_precision: 0.4324 - val_recall: 0.4571\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 3s 270ms/step - loss: 0.6244 - accuracy: 0.8170 - precision: 0.8078 - recall: 0.8170 - val_loss: 0.2761 - val_accuracy: 0.9143 - val_precision: 0.9143 - val_recall: 0.9143\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 3s 294ms/step - loss: 0.5276 - accuracy: 0.8321 - precision: 0.8309 - recall: 0.8434 - val_loss: 0.2241 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.5373 - accuracy: 0.8415 - precision: 0.8503 - recall: 0.8358 - val_loss: 0.3685 - val_accuracy: 0.8857 - val_precision: 0.8611 - val_recall: 0.8857\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.5129 - accuracy: 0.8642 - precision: 0.8590 - recall: 0.8623 - val_loss: 0.2069 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 2s 178ms/step - loss: 0.5970 - accuracy: 0.8340 - precision: 0.8311 - recall: 0.8358 - val_loss: 0.3052 - val_accuracy: 0.8857 - val_precision: 0.8857 - val_recall: 0.8857\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 1s 143ms/step - loss: 0.5257 - accuracy: 0.8491 - precision: 0.8493 - recall: 0.8509 - val_loss: 0.3882 - val_accuracy: 0.8571 - val_precision: 0.8571 - val_recall: 0.8571\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 0.4903 - accuracy: 0.8377 - precision: 0.8421 - recall: 0.8453 - val_loss: 0.2951 - val_accuracy: 0.8857 - val_precision: 0.8857 - val_recall: 0.8857\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 1s 73ms/step - loss: 0.5321 - accuracy: 0.8472 - precision: 0.8462 - recall: 0.8509 - val_loss: 0.5384 - val_accuracy: 0.7714 - val_precision: 0.7879 - val_recall: 0.7429\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.4935 - accuracy: 0.8547 - precision: 0.8588 - recall: 0.8491 - val_loss: 0.4322 - val_accuracy: 0.8286 - val_precision: 0.8286 - val_recall: 0.8286\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.5158 - accuracy: 0.8453 - precision: 0.8428 - recall: 0.8396 - val_loss: 0.3614 - val_accuracy: 0.8857 - val_precision: 0.8857 - val_recall: 0.8857\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.4946 - accuracy: 0.8528 - precision: 0.8514 - recall: 0.8434 - val_loss: 0.2967 - val_accuracy: 0.8857 - val_precision: 0.8857 - val_recall: 0.8857\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 0.5123 - accuracy: 0.8491 - precision: 0.8585 - recall: 0.8472 - val_loss: 0.2714 - val_accuracy: 0.8857 - val_precision: 0.8857 - val_recall: 0.8857\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.4630 - accuracy: 0.8792 - precision: 0.8752 - recall: 0.8736 - val_loss: 0.5658 - val_accuracy: 0.6857 - val_precision: 0.7097 - val_recall: 0.6286\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.4782 - accuracy: 0.8604 - precision: 0.8555 - recall: 0.8604 - val_loss: 0.4301 - val_accuracy: 0.8571 - val_precision: 0.8571 - val_recall: 0.8571\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.4942 - accuracy: 0.8491 - precision: 0.8536 - recall: 0.8472 - val_loss: 0.2492 - val_accuracy: 0.8857 - val_precision: 0.8857 - val_recall: 0.8857\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 1s 77ms/step - loss: 0.4568 - accuracy: 0.8623 - precision: 0.8644 - recall: 0.8660 - val_loss: 0.6535 - val_accuracy: 0.5143 - val_precision: 0.5278 - val_recall: 0.5429\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.4719 - accuracy: 0.8453 - precision: 0.8390 - recall: 0.8453 - val_loss: 0.2925 - val_accuracy: 0.8857 - val_precision: 0.8857 - val_recall: 0.8857\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 2s 231ms/step - loss: 0.4864 - accuracy: 0.8679 - precision: 0.8647 - recall: 0.8679 - val_loss: 0.3858 - val_accuracy: 0.8571 - val_precision: 0.8571 - val_recall: 0.8571\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.4606 - accuracy: 0.8792 - precision: 0.8752 - recall: 0.8736 - val_loss: 0.2707 - val_accuracy: 0.8857 - val_precision: 0.8857 - val_recall: 0.8857\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 1s 58ms/step - loss: 0.4544 - accuracy: 0.8566 - precision: 0.8539 - recall: 0.8491 - val_loss: 0.2728 - val_accuracy: 0.8857 - val_precision: 0.8857 - val_recall: 0.8857\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.4286 - accuracy: 0.8774 - precision: 0.8786 - recall: 0.8736 - val_loss: 0.2935 - val_accuracy: 0.8857 - val_precision: 0.8857 - val_recall: 0.8857\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.4374 - accuracy: 0.8868 - precision: 0.8870 - recall: 0.8887 - val_loss: 0.4346 - val_accuracy: 0.8000 - val_precision: 0.8056 - val_recall: 0.8286\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.4449 - accuracy: 0.8811 - precision: 0.8736 - recall: 0.8868 - val_loss: 0.2612 - val_accuracy: 0.8857 - val_precision: 0.8857 - val_recall: 0.8857\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.4450 - accuracy: 0.8755 - precision: 0.8755 - recall: 0.8755 - val_loss: 0.3970 - val_accuracy: 0.8286 - val_precision: 0.8529 - val_recall: 0.8286\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 5s 544ms/step - loss: 0.3826 - accuracy: 0.8792 - precision: 0.8783 - recall: 0.8849 - val_loss: 0.2721 - val_accuracy: 0.8857 - val_precision: 0.8857 - val_recall: 0.8857\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.4177 - accuracy: 0.8736 - precision: 0.8750 - recall: 0.8717 - val_loss: 0.2764 - val_accuracy: 0.8857 - val_precision: 0.8857 - val_recall: 0.8857\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.4130 - accuracy: 0.8811 - precision: 0.8778 - recall: 0.8811 - val_loss: 0.5194 - val_accuracy: 0.6571 - val_precision: 0.6765 - val_recall: 0.6571\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 0.4137 - accuracy: 0.8604 - precision: 0.8561 - recall: 0.8528 - val_loss: 0.3004 - val_accuracy: 0.8857 - val_precision: 0.8611 - val_recall: 0.8857\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.5385 - accuracy: 0.8321 - precision: 0.8240 - recall: 0.8302 - val_loss: 0.6202 - val_accuracy: 0.5714 - val_precision: 0.5938 - val_recall: 0.5429\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3810 - accuracy: 0.8717 - precision: 0.8729 - recall: 0.8679 - val_loss: 0.4810 - val_accuracy: 0.7714 - val_precision: 0.7500 - val_recall: 0.7714\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3821 - accuracy: 0.8943 - precision: 0.8910 - recall: 0.8943 - val_loss: 0.4116 - val_accuracy: 0.8000 - val_precision: 0.8056 - val_recall: 0.8286\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 1s 53ms/step - loss: 0.3537 - accuracy: 0.8887 - precision: 0.8870 - recall: 0.8887 - val_loss: 0.4490 - val_accuracy: 0.8000 - val_precision: 0.7778 - val_recall: 0.8000\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.3831 - accuracy: 0.8717 - precision: 0.8733 - recall: 0.8717 - val_loss: 0.3639 - val_accuracy: 0.8286 - val_precision: 0.8286 - val_recall: 0.8286\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3747 - accuracy: 0.8868 - precision: 0.8843 - recall: 0.8792 - val_loss: 0.6235 - val_accuracy: 0.6000 - val_precision: 0.6000 - val_recall: 0.6000\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3523 - accuracy: 0.8792 - precision: 0.8738 - recall: 0.8755 - val_loss: 0.5126 - val_accuracy: 0.6571 - val_precision: 0.6571 - val_recall: 0.6571\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.3370 - accuracy: 0.8830 - precision: 0.8923 - recall: 0.8755 - val_loss: 0.2746 - val_accuracy: 0.8857 - val_precision: 0.8857 - val_recall: 0.8857\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 1s 86ms/step - loss: 0.4225 - accuracy: 0.8830 - precision: 0.8849 - recall: 0.8849 - val_loss: 0.4402 - val_accuracy: 0.8286 - val_precision: 0.8286 - val_recall: 0.8286\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3815 - accuracy: 0.8792 - precision: 0.8755 - recall: 0.8755 - val_loss: 0.2999 - val_accuracy: 0.8857 - val_precision: 0.8857 - val_recall: 0.8857\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 1s 64ms/step - loss: 0.3623 - accuracy: 0.8925 - precision: 0.8904 - recall: 0.8887 - val_loss: 0.3861 - val_accuracy: 0.8286 - val_precision: 0.8529 - val_recall: 0.8286\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3885 - accuracy: 0.8755 - precision: 0.8703 - recall: 0.8736 - val_loss: 0.5580 - val_accuracy: 0.6286 - val_precision: 0.6286 - val_recall: 0.6286\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3379 - accuracy: 0.8811 - precision: 0.8790 - recall: 0.8774 - val_loss: 0.4175 - val_accuracy: 0.8000 - val_precision: 0.8000 - val_recall: 0.8000\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3334 - accuracy: 0.8962 - precision: 0.8958 - recall: 0.8925 - val_loss: 0.6311 - val_accuracy: 0.6000 - val_precision: 0.5882 - val_recall: 0.5714\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.3330 - accuracy: 0.8868 - precision: 0.8895 - recall: 0.8962 - val_loss: 0.4085 - val_accuracy: 0.8286 - val_precision: 0.8286 - val_recall: 0.8286\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3853 - accuracy: 0.8811 - precision: 0.8826 - recall: 0.8792 - val_loss: 0.3841 - val_accuracy: 0.8286 - val_precision: 0.8333 - val_recall: 0.8571\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3123 - accuracy: 0.8962 - precision: 0.8897 - recall: 0.8981 - val_loss: 0.3571 - val_accuracy: 0.8571 - val_precision: 0.8571 - val_recall: 0.8571\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3415 - accuracy: 0.8943 - precision: 0.8906 - recall: 0.8906 - val_loss: 0.3425 - val_accuracy: 0.8571 - val_precision: 0.8571 - val_recall: 0.8571\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3354 - accuracy: 0.8774 - precision: 0.8792 - recall: 0.8792 - val_loss: 0.4048 - val_accuracy: 0.8000 - val_precision: 0.8485 - val_recall: 0.8000\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.3136 - accuracy: 0.9075 - precision: 0.9024 - recall: 0.9075 - val_loss: 0.4901 - val_accuracy: 0.7714 - val_precision: 0.7714 - val_recall: 0.7714\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3503 - accuracy: 0.8755 - precision: 0.8696 - recall: 0.8811 - val_loss: 0.2914 - val_accuracy: 0.9143 - val_precision: 0.9118 - val_recall: 0.8857\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3281 - accuracy: 0.8925 - precision: 0.8927 - recall: 0.8943 - val_loss: 0.5037 - val_accuracy: 0.7714 - val_precision: 0.7714 - val_recall: 0.7714\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3239 - accuracy: 0.8962 - precision: 0.8968 - recall: 0.9019 - val_loss: 0.4611 - val_accuracy: 0.7714 - val_precision: 0.7941 - val_recall: 0.7714\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2992 - accuracy: 0.8943 - precision: 0.8912 - recall: 0.8962 - val_loss: 0.5241 - val_accuracy: 0.7429 - val_precision: 0.7879 - val_recall: 0.7429\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3430 - accuracy: 0.8830 - precision: 0.8840 - recall: 0.8774 - val_loss: 0.5251 - val_accuracy: 0.6571 - val_precision: 0.6471 - val_recall: 0.6286\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3407 - accuracy: 0.8887 - precision: 0.8891 - recall: 0.8925 - val_loss: 0.3839 - val_accuracy: 0.8571 - val_precision: 0.8788 - val_recall: 0.8286\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.3024 - accuracy: 0.9075 - precision: 0.9134 - recall: 0.9151 - val_loss: 0.5489 - val_accuracy: 0.5143 - val_precision: 0.5294 - val_recall: 0.5143\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3094 - accuracy: 0.8906 - precision: 0.8899 - recall: 0.9000 - val_loss: 0.4112 - val_accuracy: 0.8286 - val_precision: 0.8056 - val_recall: 0.8286\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2780 - accuracy: 0.9132 - precision: 0.9098 - recall: 0.9132 - val_loss: 0.4188 - val_accuracy: 0.8286 - val_precision: 0.8286 - val_recall: 0.8286\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.2646 - accuracy: 0.9113 - precision: 0.9043 - recall: 0.9094 - val_loss: 0.3653 - val_accuracy: 0.9143 - val_precision: 0.9143 - val_recall: 0.9143\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3189 - accuracy: 0.8981 - precision: 0.8939 - recall: 0.9057 - val_loss: 0.4029 - val_accuracy: 0.8286 - val_precision: 0.8286 - val_recall: 0.8286\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3132 - accuracy: 0.8981 - precision: 0.9017 - recall: 0.9000 - val_loss: 0.3728 - val_accuracy: 0.8571 - val_precision: 0.8824 - val_recall: 0.8571\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2709 - accuracy: 0.9208 - precision: 0.9139 - recall: 0.9208 - val_loss: 0.4507 - val_accuracy: 0.8286 - val_precision: 0.8286 - val_recall: 0.8286\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2865 - accuracy: 0.9132 - precision: 0.9103 - recall: 0.9189 - val_loss: 0.4792 - val_accuracy: 0.8000 - val_precision: 0.8000 - val_recall: 0.8000\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.2448 - accuracy: 0.9245 - precision: 0.9182 - recall: 0.9321 - val_loss: 0.7634 - val_accuracy: 0.6286 - val_precision: 0.6216 - val_recall: 0.6571\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2874 - accuracy: 0.9075 - precision: 0.9064 - recall: 0.9132 - val_loss: 0.4679 - val_accuracy: 0.8286 - val_precision: 0.8286 - val_recall: 0.8286\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2784 - accuracy: 0.9151 - precision: 0.9134 - recall: 0.9151 - val_loss: 0.5144 - val_accuracy: 0.8000 - val_precision: 0.7941 - val_recall: 0.7714\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3259 - accuracy: 0.9057 - precision: 0.9070 - recall: 0.9019 - val_loss: 0.3912 - val_accuracy: 0.8571 - val_precision: 0.8571 - val_recall: 0.8571\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.2724 - accuracy: 0.9302 - precision: 0.9215 - recall: 0.9302 - val_loss: 0.4109 - val_accuracy: 0.8286 - val_precision: 0.8529 - val_recall: 0.8286\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2660 - accuracy: 0.9151 - precision: 0.9168 - recall: 0.9151 - val_loss: 0.4006 - val_accuracy: 0.8286 - val_precision: 0.8485 - val_recall: 0.8000\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3073 - accuracy: 0.8925 - precision: 0.8889 - recall: 0.8906 - val_loss: 0.3538 - val_accuracy: 0.8857 - val_precision: 0.8857 - val_recall: 0.8857\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3308 - accuracy: 0.8981 - precision: 0.8918 - recall: 0.9019 - val_loss: 0.4590 - val_accuracy: 0.8286 - val_precision: 0.8235 - val_recall: 0.8000\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3057 - accuracy: 0.9019 - precision: 0.8935 - recall: 0.9019 - val_loss: 0.4893 - val_accuracy: 0.7714 - val_precision: 0.7714 - val_recall: 0.7714\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2423 - accuracy: 0.9170 - precision: 0.9168 - recall: 0.9151 - val_loss: 0.4380 - val_accuracy: 0.8286 - val_precision: 0.8529 - val_recall: 0.8286\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2643 - accuracy: 0.9321 - precision: 0.9271 - recall: 0.9358 - val_loss: 0.5461 - val_accuracy: 0.7429 - val_precision: 0.7429 - val_recall: 0.7429\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2201 - accuracy: 0.9226 - precision: 0.9247 - recall: 0.9264 - val_loss: 0.4536 - val_accuracy: 0.8286 - val_precision: 0.8529 - val_recall: 0.8286\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.2405 - accuracy: 0.9340 - precision: 0.9283 - recall: 0.9283 - val_loss: 0.5633 - val_accuracy: 0.6857 - val_precision: 0.7188 - val_recall: 0.6571\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2418 - accuracy: 0.9283 - precision: 0.9247 - recall: 0.9264 - val_loss: 0.8381 - val_accuracy: 0.5429 - val_precision: 0.5588 - val_recall: 0.5429\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.2897 - accuracy: 0.9189 - precision: 0.9192 - recall: 0.9226 - val_loss: 0.3778 - val_accuracy: 0.8571 - val_precision: 0.8571 - val_recall: 0.8571\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2393 - accuracy: 0.9434 - precision: 0.9375 - recall: 0.9340 - val_loss: 0.4463 - val_accuracy: 0.8286 - val_precision: 0.8529 - val_recall: 0.8286\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.2565 - accuracy: 0.9226 - precision: 0.9195 - recall: 0.9264 - val_loss: 0.6941 - val_accuracy: 0.6857 - val_precision: 0.6970 - val_recall: 0.6571\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2369 - accuracy: 0.9226 - precision: 0.9208 - recall: 0.9208 - val_loss: 0.5118 - val_accuracy: 0.7714 - val_precision: 0.7714 - val_recall: 0.7714\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.2639 - accuracy: 0.9283 - precision: 0.9266 - recall: 0.9283 - val_loss: 0.5610 - val_accuracy: 0.8000 - val_precision: 0.7879 - val_recall: 0.7429\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2204 - accuracy: 0.9302 - precision: 0.9318 - recall: 0.9283 - val_loss: 0.4018 - val_accuracy: 0.8857 - val_precision: 0.8857 - val_recall: 0.8857\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2707 - accuracy: 0.9264 - precision: 0.9232 - recall: 0.9302 - val_loss: 0.4210 - val_accuracy: 0.8286 - val_precision: 0.8286 - val_recall: 0.8286\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2178 - accuracy: 0.9358 - precision: 0.9395 - recall: 0.9377 - val_loss: 0.7120 - val_accuracy: 0.7143 - val_precision: 0.7143 - val_recall: 0.7143\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2716 - accuracy: 0.9358 - precision: 0.9325 - recall: 0.9377 - val_loss: 0.7201 - val_accuracy: 0.6857 - val_precision: 0.6857 - val_recall: 0.6857\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2144 - accuracy: 0.9321 - precision: 0.9272 - recall: 0.9377 - val_loss: 0.5558 - val_accuracy: 0.7714 - val_precision: 0.7714 - val_recall: 0.7714\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2372 - accuracy: 0.9170 - precision: 0.9173 - recall: 0.9208 - val_loss: 0.4801 - val_accuracy: 0.8571 - val_precision: 0.8571 - val_recall: 0.8571\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2641 - accuracy: 0.9170 - precision: 0.9189 - recall: 0.9189 - val_loss: 0.5246 - val_accuracy: 0.7714 - val_precision: 0.7941 - val_recall: 0.7714\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2002 - accuracy: 0.9453 - precision: 0.9486 - recall: 0.9396 - val_loss: 0.5806 - val_accuracy: 0.7714 - val_precision: 0.7647 - val_recall: 0.7429\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2411 - accuracy: 0.9340 - precision: 0.9323 - recall: 0.9358 - val_loss: 0.5590 - val_accuracy: 0.6857 - val_precision: 0.7059 - val_recall: 0.6857\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.2249 - accuracy: 0.9321 - precision: 0.9280 - recall: 0.9245 - val_loss: 0.5227 - val_accuracy: 0.8000 - val_precision: 0.8000 - val_recall: 0.8000\n",
      "Train on: [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "Test  on: 6\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 21:15:51.901211: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - ETA: 0s - loss: 0.9850 - accuracy: 0.6057 - precision: 0.6088 - recall: 0.5755"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 21:16:43.611532: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 56s 4s/step - loss: 0.9850 - accuracy: 0.6057 - precision: 0.6088 - recall: 0.5755 - val_loss: 0.6119 - val_accuracy: 0.9714 - val_precision: 0.8293 - val_recall: 0.9714\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 13s 1s/step - loss: 0.9185 - accuracy: 0.6774 - precision: 0.6839 - recall: 0.6981 - val_loss: 0.4408 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 4s 439ms/step - loss: 0.8015 - accuracy: 0.7264 - precision: 0.7212 - recall: 0.7321 - val_loss: 0.5059 - val_accuracy: 0.9143 - val_precision: 0.8889 - val_recall: 0.9143\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 8s 757ms/step - loss: 0.6491 - accuracy: 0.7830 - precision: 0.7709 - recall: 0.7811 - val_loss: 0.2326 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 6s 461ms/step - loss: 0.6664 - accuracy: 0.8132 - precision: 0.8075 - recall: 0.8151 - val_loss: 0.2840 - val_accuracy: 0.9143 - val_precision: 0.9143 - val_recall: 0.9143\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 4s 339ms/step - loss: 0.6111 - accuracy: 0.8283 - precision: 0.8277 - recall: 0.8340 - val_loss: 0.2265 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 3s 317ms/step - loss: 0.5891 - accuracy: 0.8302 - precision: 0.8246 - recall: 0.8340 - val_loss: 0.2223 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 2s 198ms/step - loss: 0.6168 - accuracy: 0.8245 - precision: 0.8252 - recall: 0.8283 - val_loss: 0.2441 - val_accuracy: 0.9143 - val_precision: 0.9143 - val_recall: 0.9143\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 1s 82ms/step - loss: 0.5410 - accuracy: 0.8377 - precision: 0.8374 - recall: 0.8358 - val_loss: 0.1992 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 3s 247ms/step - loss: 0.5547 - accuracy: 0.8377 - precision: 0.8355 - recall: 0.8434 - val_loss: 0.2004 - val_accuracy: 0.9714 - val_precision: 0.9444 - val_recall: 0.9714\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 46ms/step - loss: 0.5344 - accuracy: 0.8547 - precision: 0.8492 - recall: 0.8604 - val_loss: 0.2034 - val_accuracy: 0.9143 - val_precision: 0.9167 - val_recall: 0.9429\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 2s 237ms/step - loss: 0.5731 - accuracy: 0.8396 - precision: 0.8432 - recall: 0.8321 - val_loss: 0.2176 - val_accuracy: 0.9429 - val_precision: 0.9444 - val_recall: 0.9714\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 1s 133ms/step - loss: 0.5467 - accuracy: 0.8472 - precision: 0.8492 - recall: 0.8396 - val_loss: 0.2148 - val_accuracy: 0.9714 - val_precision: 0.9444 - val_recall: 0.9714\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 1s 97ms/step - loss: 0.5452 - accuracy: 0.8396 - precision: 0.8362 - recall: 0.8377 - val_loss: 0.1910 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 1s 62ms/step - loss: 0.5168 - accuracy: 0.8491 - precision: 0.8473 - recall: 0.8585 - val_loss: 0.1954 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 41ms/step - loss: 0.5951 - accuracy: 0.8396 - precision: 0.8355 - recall: 0.8434 - val_loss: 0.2326 - val_accuracy: 0.9143 - val_precision: 0.9143 - val_recall: 0.9143\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 2s 191ms/step - loss: 0.5376 - accuracy: 0.8396 - precision: 0.8415 - recall: 0.8415 - val_loss: 0.2048 - val_accuracy: 0.9714 - val_precision: 0.9189 - val_recall: 0.9714\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 1s 112ms/step - loss: 0.5303 - accuracy: 0.8547 - precision: 0.8612 - recall: 0.8547 - val_loss: 0.1998 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.5311 - accuracy: 0.8472 - precision: 0.8485 - recall: 0.8453 - val_loss: 0.2612 - val_accuracy: 0.9143 - val_precision: 0.9143 - val_recall: 0.9143\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 1s 82ms/step - loss: 0.5096 - accuracy: 0.8623 - precision: 0.8555 - recall: 0.8604 - val_loss: 0.2140 - val_accuracy: 0.9143 - val_precision: 0.9143 - val_recall: 0.9143\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.4984 - accuracy: 0.8509 - precision: 0.8536 - recall: 0.8472 - val_loss: 0.1893 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.5186 - accuracy: 0.8472 - precision: 0.8449 - recall: 0.8528 - val_loss: 0.2057 - val_accuracy: 0.9143 - val_precision: 0.9143 - val_recall: 0.9143\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.4974 - accuracy: 0.8660 - precision: 0.8614 - recall: 0.8679 - val_loss: 0.1839 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 1s 77ms/step - loss: 0.5344 - accuracy: 0.8472 - precision: 0.8398 - recall: 0.8604 - val_loss: 0.1773 - val_accuracy: 0.9714 - val_precision: 0.9444 - val_recall: 0.9714\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 1s 68ms/step - loss: 0.4734 - accuracy: 0.8642 - precision: 0.8688 - recall: 0.8623 - val_loss: 0.1954 - val_accuracy: 0.9714 - val_precision: 0.9444 - val_recall: 0.9714\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 36ms/step - loss: 0.4572 - accuracy: 0.8698 - precision: 0.8795 - recall: 0.8679 - val_loss: 0.1759 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.4929 - accuracy: 0.8623 - precision: 0.8590 - recall: 0.8623 - val_loss: 0.1949 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.4887 - accuracy: 0.8660 - precision: 0.8682 - recall: 0.8698 - val_loss: 0.1889 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.4701 - accuracy: 0.8679 - precision: 0.8679 - recall: 0.8679 - val_loss: 0.2170 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.4614 - accuracy: 0.8585 - precision: 0.8626 - recall: 0.8528 - val_loss: 0.2428 - val_accuracy: 0.8857 - val_precision: 0.8857 - val_recall: 0.8857\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.4821 - accuracy: 0.8509 - precision: 0.8509 - recall: 0.8509 - val_loss: 0.1885 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.4461 - accuracy: 0.8717 - precision: 0.8779 - recall: 0.8679 - val_loss: 0.1751 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 0.4469 - accuracy: 0.8585 - precision: 0.8588 - recall: 0.8491 - val_loss: 0.1575 - val_accuracy: 0.9429 - val_precision: 0.9444 - val_recall: 0.9714\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.4332 - accuracy: 0.8811 - precision: 0.8745 - recall: 0.8811 - val_loss: 0.1543 - val_accuracy: 0.9714 - val_precision: 0.9444 - val_recall: 0.9714\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.4443 - accuracy: 0.8698 - precision: 0.8701 - recall: 0.8717 - val_loss: 0.1401 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.4561 - accuracy: 0.8585 - precision: 0.8610 - recall: 0.8528 - val_loss: 0.1919 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.4231 - accuracy: 0.8906 - precision: 0.8899 - recall: 0.8849 - val_loss: 0.1777 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 1s 77ms/step - loss: 0.4358 - accuracy: 0.8736 - precision: 0.8743 - recall: 0.8660 - val_loss: 0.1698 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.4252 - accuracy: 0.8698 - precision: 0.8717 - recall: 0.8717 - val_loss: 0.1398 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.4125 - accuracy: 0.8755 - precision: 0.8778 - recall: 0.8811 - val_loss: 0.1455 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.4210 - accuracy: 0.8679 - precision: 0.8672 - recall: 0.8623 - val_loss: 0.1364 - val_accuracy: 0.9714 - val_precision: 0.9459 - val_recall: 1.0000\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.4407 - accuracy: 0.8698 - precision: 0.8641 - recall: 0.8755 - val_loss: 0.1494 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3944 - accuracy: 0.8774 - precision: 0.8717 - recall: 0.8849 - val_loss: 0.1576 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.4229 - accuracy: 0.8509 - precision: 0.8577 - recall: 0.8528 - val_loss: 0.1360 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3782 - accuracy: 0.8906 - precision: 0.8931 - recall: 0.8830 - val_loss: 0.1412 - val_accuracy: 0.9714 - val_precision: 0.9459 - val_recall: 1.0000\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.3883 - accuracy: 0.8736 - precision: 0.8829 - recall: 0.8679 - val_loss: 0.1412 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 4s 422ms/step - loss: 0.6601 - accuracy: 0.8170 - precision: 0.8282 - recall: 0.8189 - val_loss: 0.2459 - val_accuracy: 0.9143 - val_precision: 0.9143 - val_recall: 0.9143\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.3634 - accuracy: 0.8774 - precision: 0.8826 - recall: 0.8792 - val_loss: 0.1385 - val_accuracy: 0.9714 - val_precision: 0.9444 - val_recall: 0.9714\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 3s 308ms/step - loss: 0.3680 - accuracy: 0.8925 - precision: 0.8937 - recall: 0.8887 - val_loss: 0.1487 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.3969 - accuracy: 0.8925 - precision: 0.8827 - recall: 0.8943 - val_loss: 0.1530 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 1s 25ms/step - loss: 0.3696 - accuracy: 0.8830 - precision: 0.8814 - recall: 0.8830 - val_loss: 0.1460 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3627 - accuracy: 0.8962 - precision: 0.8956 - recall: 0.8906 - val_loss: 0.1638 - val_accuracy: 0.9429 - val_precision: 0.9444 - val_recall: 0.9714\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3523 - accuracy: 0.9000 - precision: 0.8960 - recall: 0.8943 - val_loss: 0.1824 - val_accuracy: 0.9429 - val_precision: 0.9697 - val_recall: 0.9143\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 37ms/step - loss: 0.3507 - accuracy: 0.8981 - precision: 0.8918 - recall: 0.9019 - val_loss: 0.1945 - val_accuracy: 0.8571 - val_precision: 0.8571 - val_recall: 0.8571\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 1s 145ms/step - loss: 0.3607 - accuracy: 0.8981 - precision: 0.8902 - recall: 0.8868 - val_loss: 0.1166 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3862 - accuracy: 0.8981 - precision: 0.8975 - recall: 0.8925 - val_loss: 0.1405 - val_accuracy: 0.9714 - val_precision: 0.9706 - val_recall: 0.9429\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 0.3702 - accuracy: 0.8830 - precision: 0.8801 - recall: 0.8868 - val_loss: 0.1069 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3419 - accuracy: 0.8887 - precision: 0.8916 - recall: 0.8849 - val_loss: 0.1245 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.3552 - accuracy: 0.8755 - precision: 0.8859 - recall: 0.8792 - val_loss: 0.1296 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3406 - accuracy: 0.8925 - precision: 0.8937 - recall: 0.8887 - val_loss: 0.1636 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3582 - accuracy: 0.8887 - precision: 0.8859 - recall: 0.8792 - val_loss: 0.1191 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.3352 - accuracy: 0.9019 - precision: 0.9023 - recall: 0.8887 - val_loss: 0.1171 - val_accuracy: 0.9429 - val_precision: 0.9444 - val_recall: 0.9714\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.3736 - accuracy: 0.8830 - precision: 0.8895 - recall: 0.8811 - val_loss: 0.1501 - val_accuracy: 0.9429 - val_precision: 0.9167 - val_recall: 0.9429\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.3598 - accuracy: 0.8717 - precision: 0.8752 - recall: 0.8736 - val_loss: 0.1348 - val_accuracy: 0.9714 - val_precision: 0.9444 - val_recall: 0.9714\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 1s 54ms/step - loss: 0.3049 - accuracy: 0.8906 - precision: 0.8908 - recall: 0.8925 - val_loss: 0.1521 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3204 - accuracy: 0.8792 - precision: 0.8826 - recall: 0.8792 - val_loss: 0.1257 - val_accuracy: 0.9429 - val_precision: 0.9444 - val_recall: 0.9714\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.4129 - accuracy: 0.8887 - precision: 0.8876 - recall: 0.8792 - val_loss: 0.1191 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.3344 - accuracy: 0.8906 - precision: 0.8942 - recall: 0.8774 - val_loss: 0.1384 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.3319 - accuracy: 0.8925 - precision: 0.8985 - recall: 0.8849 - val_loss: 0.1135 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3161 - accuracy: 0.8981 - precision: 0.9000 - recall: 0.9000 - val_loss: 0.1256 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3248 - accuracy: 0.9000 - precision: 0.9049 - recall: 0.8981 - val_loss: 0.1251 - val_accuracy: 0.9714 - val_precision: 0.9706 - val_recall: 0.9429\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3550 - accuracy: 0.8943 - precision: 0.8989 - recall: 0.8887 - val_loss: 0.1297 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3239 - accuracy: 0.8981 - precision: 0.9036 - recall: 0.9019 - val_loss: 0.1335 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3521 - accuracy: 0.8906 - precision: 0.8939 - recall: 0.8906 - val_loss: 0.1216 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2853 - accuracy: 0.9019 - precision: 0.9105 - recall: 0.9019 - val_loss: 0.1094 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 0.3254 - accuracy: 0.8962 - precision: 0.8929 - recall: 0.8962 - val_loss: 0.0964 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2964 - accuracy: 0.8962 - precision: 0.9000 - recall: 0.9000 - val_loss: 0.1218 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3270 - accuracy: 0.9094 - precision: 0.9136 - recall: 0.8981 - val_loss: 0.1576 - val_accuracy: 0.9714 - val_precision: 0.9444 - val_recall: 0.9714\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2877 - accuracy: 0.9038 - precision: 0.9049 - recall: 0.8981 - val_loss: 0.1195 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2822 - accuracy: 0.9170 - precision: 0.9218 - recall: 0.9113 - val_loss: 0.0983 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3131 - accuracy: 0.9000 - precision: 0.8951 - recall: 0.9019 - val_loss: 0.1492 - val_accuracy: 0.9143 - val_precision: 0.9143 - val_recall: 0.9143\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3065 - accuracy: 0.9057 - precision: 0.8976 - recall: 0.9094 - val_loss: 0.1156 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2936 - accuracy: 0.9245 - precision: 0.9171 - recall: 0.9189 - val_loss: 0.1081 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.2973 - accuracy: 0.9000 - precision: 0.9030 - recall: 0.8962 - val_loss: 0.0855 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3459 - accuracy: 0.9094 - precision: 0.9087 - recall: 0.9019 - val_loss: 0.1426 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.2756 - accuracy: 0.9151 - precision: 0.9101 - recall: 0.9170 - val_loss: 0.1127 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2902 - accuracy: 0.9226 - precision: 0.9251 - recall: 0.9094 - val_loss: 0.1272 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3156 - accuracy: 0.9170 - precision: 0.9129 - recall: 0.9094 - val_loss: 0.1092 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3052 - accuracy: 0.9151 - precision: 0.9110 - recall: 0.9075 - val_loss: 0.1098 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3202 - accuracy: 0.9057 - precision: 0.9036 - recall: 0.9019 - val_loss: 0.1089 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2668 - accuracy: 0.9283 - precision: 0.9297 - recall: 0.9226 - val_loss: 0.1291 - val_accuracy: 0.9714 - val_precision: 0.9444 - val_recall: 0.9714\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3274 - accuracy: 0.9151 - precision: 0.9135 - recall: 0.9170 - val_loss: 0.1304 - val_accuracy: 1.0000 - val_precision: 0.9722 - val_recall: 1.0000\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.2783 - accuracy: 0.9189 - precision: 0.9151 - recall: 0.9151 - val_loss: 0.1162 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2402 - accuracy: 0.9358 - precision: 0.9368 - recall: 0.9226 - val_loss: 0.1166 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2789 - accuracy: 0.9283 - precision: 0.9247 - recall: 0.9264 - val_loss: 0.1228 - val_accuracy: 0.9714 - val_precision: 1.0000 - val_recall: 0.9429\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2974 - accuracy: 0.9245 - precision: 0.9254 - recall: 0.9132 - val_loss: 0.1127 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2847 - accuracy: 0.9264 - precision: 0.9260 - recall: 0.9208 - val_loss: 0.0989 - val_accuracy: 0.9714 - val_precision: 0.9722 - val_recall: 1.0000\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2916 - accuracy: 0.9170 - precision: 0.9160 - recall: 0.9057 - val_loss: 0.1019 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2572 - accuracy: 0.9132 - precision: 0.9160 - recall: 0.9057 - val_loss: 0.1679 - val_accuracy: 0.8571 - val_precision: 0.8571 - val_recall: 0.8571\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3032 - accuracy: 0.9302 - precision: 0.9283 - recall: 0.9283 - val_loss: 0.0934 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Train on: [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "Test  on: 7\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 21:18:18.895408: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - ETA: 0s - loss: 0.9714 - accuracy: 0.6151 - precision: 0.6059 - recall: 0.5830"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 21:19:19.710197: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 66s 5s/step - loss: 0.9714 - accuracy: 0.6151 - precision: 0.6059 - recall: 0.5830 - val_loss: 0.7148 - val_accuracy: 0.3429 - val_precision: 0.4103 - val_recall: 0.4571\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 7s 694ms/step - loss: 0.8507 - accuracy: 0.6962 - precision: 0.6951 - recall: 0.6925 - val_loss: 0.4692 - val_accuracy: 0.8571 - val_precision: 0.8571 - val_recall: 0.8571\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 7s 675ms/step - loss: 0.7441 - accuracy: 0.7623 - precision: 0.7590 - recall: 0.7547 - val_loss: 0.3151 - val_accuracy: 0.9429 - val_precision: 0.8919 - val_recall: 0.9429\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 3s 235ms/step - loss: 0.6581 - accuracy: 0.8189 - precision: 0.8090 - recall: 0.8151 - val_loss: 0.2618 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 4s 359ms/step - loss: 0.6455 - accuracy: 0.8226 - precision: 0.8101 - recall: 0.8208 - val_loss: 0.2368 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 2s 188ms/step - loss: 0.6187 - accuracy: 0.8434 - precision: 0.8403 - recall: 0.8340 - val_loss: 0.2686 - val_accuracy: 0.9143 - val_precision: 0.8889 - val_recall: 0.9143\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 2s 201ms/step - loss: 0.5764 - accuracy: 0.8528 - precision: 0.8561 - recall: 0.8528 - val_loss: 0.2314 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 3s 309ms/step - loss: 0.6156 - accuracy: 0.8151 - precision: 0.8192 - recall: 0.8208 - val_loss: 0.2276 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 1s 128ms/step - loss: 0.5941 - accuracy: 0.8358 - precision: 0.8374 - recall: 0.8358 - val_loss: 0.2128 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 4s 357ms/step - loss: 0.5771 - accuracy: 0.8377 - precision: 0.8371 - recall: 0.8434 - val_loss: 0.2416 - val_accuracy: 0.9143 - val_precision: 0.9167 - val_recall: 0.9429\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 1s 53ms/step - loss: 0.5858 - accuracy: 0.8302 - precision: 0.8262 - recall: 0.8340 - val_loss: 0.2215 - val_accuracy: 0.9143 - val_precision: 0.9189 - val_recall: 0.9714\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 1s 61ms/step - loss: 0.5527 - accuracy: 0.8547 - precision: 0.8515 - recall: 0.8547 - val_loss: 0.2219 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 2s 230ms/step - loss: 0.5304 - accuracy: 0.8491 - precision: 0.8485 - recall: 0.8453 - val_loss: 0.1885 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 1s 120ms/step - loss: 0.5909 - accuracy: 0.8358 - precision: 0.8293 - recall: 0.8434 - val_loss: 0.1790 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 6s 612ms/step - loss: 0.5281 - accuracy: 0.8472 - precision: 0.8496 - recall: 0.8528 - val_loss: 0.2400 - val_accuracy: 0.9143 - val_precision: 0.9167 - val_recall: 0.9429\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 1s 85ms/step - loss: 0.5699 - accuracy: 0.8396 - precision: 0.8333 - recall: 0.8491 - val_loss: 0.2535 - val_accuracy: 0.9143 - val_precision: 0.9143 - val_recall: 0.9143\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 1s 93ms/step - loss: 0.5267 - accuracy: 0.8566 - precision: 0.8515 - recall: 0.8547 - val_loss: 0.1994 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.5171 - accuracy: 0.8547 - precision: 0.8547 - recall: 0.8660 - val_loss: 0.2013 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 1s 71ms/step - loss: 0.5061 - accuracy: 0.8623 - precision: 0.8598 - recall: 0.8566 - val_loss: 0.2168 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.5103 - accuracy: 0.8736 - precision: 0.8665 - recall: 0.8698 - val_loss: 0.2366 - val_accuracy: 0.9143 - val_precision: 0.9143 - val_recall: 0.9143\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.4942 - accuracy: 0.8660 - precision: 0.8663 - recall: 0.8679 - val_loss: 0.2299 - val_accuracy: 0.9429 - val_precision: 0.9444 - val_recall: 0.9714\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.5213 - accuracy: 0.8472 - precision: 0.8509 - recall: 0.8509 - val_loss: 0.2086 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 1s 58ms/step - loss: 0.4683 - accuracy: 0.8679 - precision: 0.8698 - recall: 0.8698 - val_loss: 0.1774 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 40ms/step - loss: 0.4524 - accuracy: 0.8623 - precision: 0.8604 - recall: 0.8604 - val_loss: 0.1943 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 45ms/step - loss: 0.5897 - accuracy: 0.8321 - precision: 0.8318 - recall: 0.8302 - val_loss: 0.2901 - val_accuracy: 0.8857 - val_precision: 0.8857 - val_recall: 0.8857\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.4896 - accuracy: 0.8717 - precision: 0.8738 - recall: 0.8755 - val_loss: 0.2342 - val_accuracy: 0.9429 - val_precision: 0.9444 - val_recall: 0.9714\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.4287 - accuracy: 0.8642 - precision: 0.8566 - recall: 0.8679 - val_loss: 0.1980 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.4402 - accuracy: 0.8717 - precision: 0.8663 - recall: 0.8679 - val_loss: 0.2204 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 0.4646 - accuracy: 0.8679 - precision: 0.8679 - recall: 0.8679 - val_loss: 0.1951 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.4500 - accuracy: 0.8660 - precision: 0.8652 - recall: 0.8717 - val_loss: 0.2123 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 37ms/step - loss: 0.4546 - accuracy: 0.8774 - precision: 0.8752 - recall: 0.8736 - val_loss: 0.3157 - val_accuracy: 0.8286 - val_precision: 0.8286 - val_recall: 0.8286\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.5089 - accuracy: 0.8660 - precision: 0.8614 - recall: 0.8679 - val_loss: 0.2013 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.4275 - accuracy: 0.8811 - precision: 0.8780 - recall: 0.8830 - val_loss: 0.1942 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.4256 - accuracy: 0.8660 - precision: 0.8707 - recall: 0.8642 - val_loss: 0.2012 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3971 - accuracy: 0.8792 - precision: 0.8785 - recall: 0.8868 - val_loss: 0.2061 - val_accuracy: 0.9429 - val_precision: 0.9444 - val_recall: 0.9714\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.4187 - accuracy: 0.8755 - precision: 0.8750 - recall: 0.8717 - val_loss: 0.2011 - val_accuracy: 0.9429 - val_precision: 0.9706 - val_recall: 0.9429\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 39ms/step - loss: 0.4270 - accuracy: 0.8566 - precision: 0.8659 - recall: 0.8528 - val_loss: 0.1498 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.4039 - accuracy: 0.8868 - precision: 0.8816 - recall: 0.8849 - val_loss: 0.1691 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3971 - accuracy: 0.8868 - precision: 0.8785 - recall: 0.8868 - val_loss: 0.1621 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.3854 - accuracy: 0.8887 - precision: 0.8856 - recall: 0.8906 - val_loss: 0.1517 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3901 - accuracy: 0.8830 - precision: 0.8822 - recall: 0.8906 - val_loss: 0.1563 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.4427 - accuracy: 0.8679 - precision: 0.8752 - recall: 0.8604 - val_loss: 0.1599 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3886 - accuracy: 0.8717 - precision: 0.8722 - recall: 0.8755 - val_loss: 0.1713 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3786 - accuracy: 0.8962 - precision: 0.8947 - recall: 0.8981 - val_loss: 0.1527 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.3896 - accuracy: 0.8792 - precision: 0.8776 - recall: 0.8792 - val_loss: 0.1258 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3927 - accuracy: 0.8792 - precision: 0.8840 - recall: 0.8774 - val_loss: 0.1390 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.3655 - accuracy: 0.8849 - precision: 0.8839 - recall: 0.8906 - val_loss: 0.1686 - val_accuracy: 0.9429 - val_precision: 0.9444 - val_recall: 0.9714\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.4088 - accuracy: 0.8755 - precision: 0.8759 - recall: 0.8792 - val_loss: 0.1224 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3308 - accuracy: 0.8943 - precision: 0.8937 - recall: 0.8887 - val_loss: 0.1548 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.3962 - accuracy: 0.8887 - precision: 0.8902 - recall: 0.8868 - val_loss: 0.1099 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3497 - accuracy: 0.8981 - precision: 0.8947 - recall: 0.8981 - val_loss: 0.1438 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.3144 - accuracy: 0.8981 - precision: 0.8916 - recall: 0.9000 - val_loss: 0.1083 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3352 - accuracy: 0.9000 - precision: 0.8966 - recall: 0.9000 - val_loss: 0.1360 - val_accuracy: 0.9714 - val_precision: 0.9722 - val_recall: 1.0000\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.3722 - accuracy: 0.8830 - precision: 0.8864 - recall: 0.8830 - val_loss: 0.1467 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3940 - accuracy: 0.8660 - precision: 0.8636 - recall: 0.8717 - val_loss: 0.1287 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3730 - accuracy: 0.8887 - precision: 0.8904 - recall: 0.8887 - val_loss: 0.1090 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.3608 - accuracy: 0.8962 - precision: 0.9017 - recall: 0.9000 - val_loss: 0.0895 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3241 - accuracy: 0.9000 - precision: 0.8996 - recall: 0.8962 - val_loss: 0.1344 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.3593 - accuracy: 0.8887 - precision: 0.8827 - recall: 0.8943 - val_loss: 0.0949 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 37ms/step - loss: 0.3397 - accuracy: 0.8943 - precision: 0.8960 - recall: 0.8943 - val_loss: 0.0691 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.3279 - accuracy: 0.9000 - precision: 0.8996 - recall: 0.8962 - val_loss: 0.1110 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.3280 - accuracy: 0.9000 - precision: 0.8883 - recall: 0.9000 - val_loss: 0.0860 - val_accuracy: 1.0000 - val_precision: 0.9722 - val_recall: 1.0000\n",
      "Train on: [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15]\n",
      "Test  on: 8\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 21:20:27.193662: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - ETA: 0s - loss: 0.9566 - accuracy: 0.6295 - precision: 0.6176 - recall: 0.5955"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 21:21:18.629818: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 56s 3s/step - loss: 0.9566 - accuracy: 0.6295 - precision: 0.6176 - recall: 0.5955 - val_loss: 0.6188 - val_accuracy: 0.8333 - val_precision: 0.8333 - val_recall: 0.8333\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.8936 - accuracy: 0.7127 - precision: 0.6990 - recall: 0.6938 - val_loss: 0.6000 - val_accuracy: 0.7500 - val_precision: 0.7174 - val_recall: 0.9167\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 4s 394ms/step - loss: 0.7605 - accuracy: 0.7467 - precision: 0.7352 - recall: 0.7505 - val_loss: 0.4107 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 6s 571ms/step - loss: 0.6756 - accuracy: 0.7902 - precision: 0.7889 - recall: 0.7769 - val_loss: 0.3049 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 0.6484 - accuracy: 0.8091 - precision: 0.8140 - recall: 0.7940 - val_loss: 0.2618 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 2s 160ms/step - loss: 0.6032 - accuracy: 0.8166 - precision: 0.8151 - recall: 0.8166 - val_loss: 0.2808 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 4s 352ms/step - loss: 0.5985 - accuracy: 0.8204 - precision: 0.8215 - recall: 0.8091 - val_loss: 0.2381 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.5376 - accuracy: 0.8544 - precision: 0.8462 - recall: 0.8526 - val_loss: 0.2783 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.5331 - accuracy: 0.8355 - precision: 0.8438 - recall: 0.8374 - val_loss: 0.2518 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 0.5378 - accuracy: 0.8450 - precision: 0.8444 - recall: 0.8412 - val_loss: 0.2146 - val_accuracy: 0.9722 - val_precision: 0.9706 - val_recall: 0.9167\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 36ms/step - loss: 0.5856 - accuracy: 0.8450 - precision: 0.8440 - recall: 0.8488 - val_loss: 0.2596 - val_accuracy: 0.9167 - val_precision: 0.9429 - val_recall: 0.9167\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 1s 59ms/step - loss: 0.5267 - accuracy: 0.8563 - precision: 0.8588 - recall: 0.8507 - val_loss: 0.2532 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 1s 116ms/step - loss: 0.5875 - accuracy: 0.8299 - precision: 0.8214 - recall: 0.8261 - val_loss: 0.2333 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 3s 258ms/step - loss: 0.5339 - accuracy: 0.8507 - precision: 0.8454 - recall: 0.8582 - val_loss: 0.2536 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 8s 736ms/step - loss: 0.5362 - accuracy: 0.8469 - precision: 0.8425 - recall: 0.8393 - val_loss: 0.2566 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 6s 336ms/step - loss: 0.5226 - accuracy: 0.8507 - precision: 0.8555 - recall: 0.8393 - val_loss: 0.2294 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 1s 78ms/step - loss: 0.4900 - accuracy: 0.8601 - precision: 0.8609 - recall: 0.8658 - val_loss: 0.2147 - val_accuracy: 0.9444 - val_precision: 0.9714 - val_recall: 0.9444\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 1s 65ms/step - loss: 0.5117 - accuracy: 0.8526 - precision: 0.8555 - recall: 0.8507 - val_loss: 0.2639 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.5318 - accuracy: 0.8431 - precision: 0.8479 - recall: 0.8431 - val_loss: 0.2327 - val_accuracy: 0.9722 - val_precision: 0.9706 - val_recall: 0.9167\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 1s 135ms/step - loss: 0.5049 - accuracy: 0.8431 - precision: 0.8500 - recall: 0.8355 - val_loss: 0.2328 - val_accuracy: 0.9722 - val_precision: 0.9714 - val_recall: 0.9444\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 2s 194ms/step - loss: 0.4922 - accuracy: 0.8620 - precision: 0.8566 - recall: 0.8696 - val_loss: 0.2875 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.4898 - accuracy: 0.8733 - precision: 0.8701 - recall: 0.8733 - val_loss: 0.2597 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 1s 93ms/step - loss: 0.4663 - accuracy: 0.8526 - precision: 0.8574 - recall: 0.8526 - val_loss: 0.2596 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 2s 147ms/step - loss: 0.4692 - accuracy: 0.8752 - precision: 0.8769 - recall: 0.8752 - val_loss: 0.2835 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.5267 - accuracy: 0.8488 - precision: 0.8520 - recall: 0.8488 - val_loss: 0.2498 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 40ms/step - loss: 0.4868 - accuracy: 0.8639 - precision: 0.8653 - recall: 0.8620 - val_loss: 0.2685 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.4726 - accuracy: 0.8601 - precision: 0.8629 - recall: 0.8563 - val_loss: 0.2291 - val_accuracy: 0.9444 - val_precision: 0.9706 - val_recall: 0.9167\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.4547 - accuracy: 0.8658 - precision: 0.8700 - recall: 0.8601 - val_loss: 0.2448 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.4273 - accuracy: 0.8696 - precision: 0.8715 - recall: 0.8715 - val_loss: 0.2589 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 36ms/step - loss: 0.4377 - accuracy: 0.8733 - precision: 0.8715 - recall: 0.8715 - val_loss: 0.3094 - val_accuracy: 0.9444 - val_precision: 0.9429 - val_recall: 0.9167\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.4500 - accuracy: 0.8696 - precision: 0.8696 - recall: 0.8696 - val_loss: 0.2858 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.4221 - accuracy: 0.8733 - precision: 0.8736 - recall: 0.8752 - val_loss: 0.2599 - val_accuracy: 0.9444 - val_precision: 0.9714 - val_recall: 0.9444\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.4007 - accuracy: 0.8752 - precision: 0.8710 - recall: 0.8809 - val_loss: 0.2792 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3961 - accuracy: 0.8809 - precision: 0.8802 - recall: 0.8752 - val_loss: 0.2644 - val_accuracy: 0.9444 - val_precision: 0.9444 - val_recall: 0.9444\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.3871 - accuracy: 0.8828 - precision: 0.8868 - recall: 0.8885 - val_loss: 0.2667 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.4032 - accuracy: 0.8790 - precision: 0.8824 - recall: 0.8790 - val_loss: 0.2661 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.4935 - accuracy: 0.8639 - precision: 0.8634 - recall: 0.8601 - val_loss: 0.2992 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.3956 - accuracy: 0.8771 - precision: 0.8736 - recall: 0.8752 - val_loss: 0.3181 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.3995 - accuracy: 0.8715 - precision: 0.8682 - recall: 0.8715 - val_loss: 0.2687 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3942 - accuracy: 0.8771 - precision: 0.8771 - recall: 0.8771 - val_loss: 0.2921 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.3821 - accuracy: 0.8866 - precision: 0.8837 - recall: 0.8904 - val_loss: 0.3050 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.3149 - accuracy: 0.9093 - precision: 0.9084 - recall: 0.8998 - val_loss: 0.2632 - val_accuracy: 0.9722 - val_precision: 0.9459 - val_recall: 0.9722\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.3584 - accuracy: 0.8771 - precision: 0.8738 - recall: 0.8771 - val_loss: 0.2696 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.3457 - accuracy: 0.8790 - precision: 0.8771 - recall: 0.8771 - val_loss: 0.2639 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 41ms/step - loss: 0.3974 - accuracy: 0.8677 - precision: 0.8683 - recall: 0.8601 - val_loss: 0.2903 - val_accuracy: 0.9167 - val_precision: 0.9429 - val_recall: 0.9167\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3373 - accuracy: 0.8809 - precision: 0.8795 - recall: 0.8828 - val_loss: 0.2507 - val_accuracy: 0.9722 - val_precision: 0.9714 - val_recall: 0.9444\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.3087 - accuracy: 0.9036 - precision: 0.9029 - recall: 0.8960 - val_loss: 0.3173 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.3394 - accuracy: 0.8809 - precision: 0.8792 - recall: 0.8809 - val_loss: 0.2837 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3179 - accuracy: 0.8941 - precision: 0.8954 - recall: 0.8904 - val_loss: 0.5122 - val_accuracy: 0.8056 - val_precision: 0.8235 - val_recall: 0.7778\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.6284 - accuracy: 0.8355 - precision: 0.8430 - recall: 0.8223 - val_loss: 0.3027 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.3210 - accuracy: 0.8960 - precision: 0.8994 - recall: 0.8790 - val_loss: 0.2942 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.3377 - accuracy: 0.8847 - precision: 0.9010 - recall: 0.8771 - val_loss: 0.2877 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.3088 - accuracy: 0.8979 - precision: 0.9042 - recall: 0.8922 - val_loss: 0.3575 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.3182 - accuracy: 0.8960 - precision: 0.9038 - recall: 0.9055 - val_loss: 0.3771 - val_accuracy: 0.8333 - val_precision: 0.8529 - val_recall: 0.8056\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.3425 - accuracy: 0.8885 - precision: 0.8944 - recall: 0.8809 - val_loss: 0.2681 - val_accuracy: 0.9444 - val_precision: 0.9444 - val_recall: 0.9444\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3580 - accuracy: 0.8904 - precision: 0.8904 - recall: 0.8904 - val_loss: 0.3539 - val_accuracy: 0.8889 - val_precision: 0.8857 - val_recall: 0.8611\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3002 - accuracy: 0.8960 - precision: 0.8996 - recall: 0.8979 - val_loss: 0.2702 - val_accuracy: 0.9444 - val_precision: 0.9444 - val_recall: 0.9444\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2848 - accuracy: 0.9036 - precision: 0.8985 - recall: 0.9036 - val_loss: 0.3122 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3148 - accuracy: 0.8847 - precision: 0.8859 - recall: 0.8809 - val_loss: 0.2922 - val_accuracy: 0.9167 - val_precision: 0.9429 - val_recall: 0.9167\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2981 - accuracy: 0.9074 - precision: 0.9024 - recall: 0.9093 - val_loss: 0.3208 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3103 - accuracy: 0.8998 - precision: 0.8989 - recall: 0.9074 - val_loss: 0.3362 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3280 - accuracy: 0.8904 - precision: 0.8904 - recall: 0.8904 - val_loss: 0.3493 - val_accuracy: 0.8889 - val_precision: 0.9143 - val_recall: 0.8889\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.3350 - accuracy: 0.8847 - precision: 0.8820 - recall: 0.8904 - val_loss: 0.3919 - val_accuracy: 0.8889 - val_precision: 0.8857 - val_recall: 0.8611\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.2735 - accuracy: 0.9055 - precision: 0.9021 - recall: 0.9055 - val_loss: 0.3183 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2883 - accuracy: 0.8922 - precision: 0.8922 - recall: 0.8922 - val_loss: 0.3244 - val_accuracy: 0.9167 - val_precision: 0.9143 - val_recall: 0.8889\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2985 - accuracy: 0.9112 - precision: 0.9074 - recall: 0.9074 - val_loss: 0.3464 - val_accuracy: 0.8889 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2800 - accuracy: 0.9187 - precision: 0.9254 - recall: 0.9149 - val_loss: 0.3479 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3617 - accuracy: 0.8979 - precision: 0.8866 - recall: 0.8866 - val_loss: 0.3407 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2912 - accuracy: 0.9130 - precision: 0.9231 - recall: 0.9074 - val_loss: 0.3373 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3353 - accuracy: 0.8922 - precision: 0.8935 - recall: 0.8885 - val_loss: 0.3704 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2650 - accuracy: 0.9187 - precision: 0.9189 - recall: 0.8998 - val_loss: 0.3035 - val_accuracy: 0.9167 - val_precision: 0.9429 - val_recall: 0.9167\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.2593 - accuracy: 0.9093 - precision: 0.9089 - recall: 0.9055 - val_loss: 0.3602 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.2573 - accuracy: 0.9225 - precision: 0.9240 - recall: 0.9187 - val_loss: 0.3563 - val_accuracy: 0.9167 - val_precision: 0.9118 - val_recall: 0.8611\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.2649 - accuracy: 0.9206 - precision: 0.9120 - recall: 0.9206 - val_loss: 0.4345 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.2921 - accuracy: 0.9055 - precision: 0.9106 - recall: 0.9055 - val_loss: 0.3954 - val_accuracy: 0.9167 - val_precision: 0.9143 - val_recall: 0.8889\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.2609 - accuracy: 0.9093 - precision: 0.9075 - recall: 0.9093 - val_loss: 0.3346 - val_accuracy: 0.9167 - val_precision: 0.9143 - val_recall: 0.8889\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.2883 - accuracy: 0.9149 - precision: 0.9093 - recall: 0.9282 - val_loss: 0.3338 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.2906 - accuracy: 0.9112 - precision: 0.9065 - recall: 0.8979 - val_loss: 0.3860 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.2850 - accuracy: 0.9187 - precision: 0.9132 - recall: 0.9149 - val_loss: 0.3571 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.2613 - accuracy: 0.9206 - precision: 0.9151 - recall: 0.9168 - val_loss: 0.4201 - val_accuracy: 0.9167 - val_precision: 0.9143 - val_recall: 0.8889\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.2641 - accuracy: 0.9357 - precision: 0.9333 - recall: 0.9263 - val_loss: 0.3712 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.2718 - accuracy: 0.9093 - precision: 0.9055 - recall: 0.9055 - val_loss: 0.4804 - val_accuracy: 0.9167 - val_precision: 0.9143 - val_recall: 0.8889\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.2392 - accuracy: 0.9301 - precision: 0.9251 - recall: 0.9338 - val_loss: 0.4301 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2899 - accuracy: 0.9263 - precision: 0.9244 - recall: 0.9244 - val_loss: 0.4274 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2532 - accuracy: 0.9301 - precision: 0.9237 - recall: 0.9149 - val_loss: 0.3810 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3341 - accuracy: 0.9187 - precision: 0.9144 - recall: 0.9093 - val_loss: 0.3202 - val_accuracy: 0.9444 - val_precision: 0.9444 - val_recall: 0.9444\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2466 - accuracy: 0.9282 - precision: 0.9284 - recall: 0.9319 - val_loss: 0.4116 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2643 - accuracy: 0.9301 - precision: 0.9242 - recall: 0.9225 - val_loss: 0.4979 - val_accuracy: 0.8056 - val_precision: 0.8286 - val_recall: 0.8056\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.2725 - accuracy: 0.9225 - precision: 0.9257 - recall: 0.9187 - val_loss: 0.3980 - val_accuracy: 0.9167 - val_precision: 0.9143 - val_recall: 0.8889\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2986 - accuracy: 0.9112 - precision: 0.9184 - recall: 0.9149 - val_loss: 0.3559 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.2157 - accuracy: 0.9244 - precision: 0.9213 - recall: 0.9301 - val_loss: 0.3689 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2074 - accuracy: 0.9376 - precision: 0.9447 - recall: 0.9357 - val_loss: 0.3795 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2049 - accuracy: 0.9395 - precision: 0.9328 - recall: 0.9452 - val_loss: 0.4871 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2448 - accuracy: 0.9244 - precision: 0.9205 - recall: 0.9187 - val_loss: 0.4742 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.2863 - accuracy: 0.9130 - precision: 0.9162 - recall: 0.9093 - val_loss: 0.4574 - val_accuracy: 0.8889 - val_precision: 0.8857 - val_recall: 0.8611\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2236 - accuracy: 0.9414 - precision: 0.9396 - recall: 0.9414 - val_loss: 0.4042 - val_accuracy: 0.8889 - val_precision: 0.8857 - val_recall: 0.8611\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2204 - accuracy: 0.9357 - precision: 0.9388 - recall: 0.9282 - val_loss: 0.5126 - val_accuracy: 0.8889 - val_precision: 0.8824 - val_recall: 0.8333\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.2250 - accuracy: 0.9376 - precision: 0.9291 - recall: 0.9414 - val_loss: 0.6180 - val_accuracy: 0.8611 - val_precision: 0.8824 - val_recall: 0.8333\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.2574 - accuracy: 0.9395 - precision: 0.9390 - recall: 0.9319 - val_loss: 0.3924 - val_accuracy: 0.8889 - val_precision: 0.8919 - val_recall: 0.9167\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2376 - accuracy: 0.9414 - precision: 0.9343 - recall: 0.9414 - val_loss: 0.4045 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Train on: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15]\n",
      "Test  on: 9\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 21:22:45.416741: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - ETA: 0s - loss: 0.9574 - accuracy: 0.6163 - precision: 0.6119 - recall: 0.5633"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 21:23:34.697334: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 54s 4s/step - loss: 0.9574 - accuracy: 0.6163 - precision: 0.6119 - recall: 0.5633 - val_loss: 0.6367 - val_accuracy: 0.6111 - val_precision: 0.5814 - val_recall: 0.6944\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 9s 902ms/step - loss: 0.8081 - accuracy: 0.7278 - precision: 0.7169 - recall: 0.7372 - val_loss: 0.5231 - val_accuracy: 0.7222 - val_precision: 0.7222 - val_recall: 0.7222\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 7s 415ms/step - loss: 0.7009 - accuracy: 0.7826 - precision: 0.7876 - recall: 0.7921 - val_loss: 0.5057 - val_accuracy: 0.8056 - val_precision: 0.7692 - val_recall: 0.8333\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 4s 336ms/step - loss: 0.6702 - accuracy: 0.7921 - precision: 0.7936 - recall: 0.7921 - val_loss: 0.4757 - val_accuracy: 0.7222 - val_precision: 0.7297 - val_recall: 0.7500\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 2s 175ms/step - loss: 0.6443 - accuracy: 0.8147 - precision: 0.8097 - recall: 0.8204 - val_loss: 0.5489 - val_accuracy: 0.8056 - val_precision: 0.8108 - val_recall: 0.8333\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 3s 341ms/step - loss: 0.5767 - accuracy: 0.8450 - precision: 0.8438 - recall: 0.8374 - val_loss: 0.5199 - val_accuracy: 0.8333 - val_precision: 0.8333 - val_recall: 0.8333\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 1s 138ms/step - loss: 0.5604 - accuracy: 0.8507 - precision: 0.8456 - recall: 0.8488 - val_loss: 0.4826 - val_accuracy: 0.8056 - val_precision: 0.7895 - val_recall: 0.8333\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.5706 - accuracy: 0.8393 - precision: 0.8287 - recall: 0.8412 - val_loss: 0.4511 - val_accuracy: 0.7500 - val_precision: 0.7000 - val_recall: 0.7778\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 3s 269ms/step - loss: 0.5578 - accuracy: 0.8563 - precision: 0.8526 - recall: 0.8526 - val_loss: 0.4673 - val_accuracy: 0.7222 - val_precision: 0.7353 - val_recall: 0.6944\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 1s 97ms/step - loss: 0.5678 - accuracy: 0.8601 - precision: 0.8571 - recall: 0.8620 - val_loss: 0.7451 - val_accuracy: 0.5833 - val_precision: 0.5526 - val_recall: 0.5833\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.5169 - accuracy: 0.8544 - precision: 0.8436 - recall: 0.8563 - val_loss: 0.5627 - val_accuracy: 0.8333 - val_precision: 0.8333 - val_recall: 0.8333\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.5075 - accuracy: 0.8582 - precision: 0.8650 - recall: 0.8601 - val_loss: 0.6599 - val_accuracy: 0.6944 - val_precision: 0.7027 - val_recall: 0.7222\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 2s 153ms/step - loss: 0.5533 - accuracy: 0.8488 - precision: 0.8457 - recall: 0.8601 - val_loss: 0.5826 - val_accuracy: 0.8056 - val_precision: 0.8056 - val_recall: 0.8056\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 1s 145ms/step - loss: 0.4944 - accuracy: 0.8658 - precision: 0.8579 - recall: 0.8677 - val_loss: 0.4701 - val_accuracy: 0.8056 - val_precision: 0.7838 - val_recall: 0.8056\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 1s 97ms/step - loss: 0.4910 - accuracy: 0.8601 - precision: 0.8542 - recall: 0.8639 - val_loss: 0.5211 - val_accuracy: 0.8333 - val_precision: 0.8333 - val_recall: 0.8333\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 1s 60ms/step - loss: 0.5227 - accuracy: 0.8563 - precision: 0.8582 - recall: 0.8582 - val_loss: 0.5088 - val_accuracy: 0.8333 - val_precision: 0.8333 - val_recall: 0.8333\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 5s 488ms/step - loss: 0.4814 - accuracy: 0.8771 - precision: 0.8743 - recall: 0.8809 - val_loss: 0.5195 - val_accuracy: 0.8333 - val_precision: 0.8333 - val_recall: 0.8333\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 1s 29ms/step - loss: 0.4764 - accuracy: 0.8715 - precision: 0.8703 - recall: 0.8752 - val_loss: 0.5520 - val_accuracy: 0.7778 - val_precision: 0.7895 - val_recall: 0.8333\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 39ms/step - loss: 0.4611 - accuracy: 0.8677 - precision: 0.8642 - recall: 0.8658 - val_loss: 0.4618 - val_accuracy: 0.8333 - val_precision: 0.8333 - val_recall: 0.8333\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 1s 90ms/step - loss: 0.4719 - accuracy: 0.8658 - precision: 0.8662 - recall: 0.8563 - val_loss: 0.4713 - val_accuracy: 0.8333 - val_precision: 0.8333 - val_recall: 0.8333\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 3s 249ms/step - loss: 0.5899 - accuracy: 0.8582 - precision: 0.8555 - recall: 0.8620 - val_loss: 0.5853 - val_accuracy: 0.7222 - val_precision: 0.7179 - val_recall: 0.7778\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 38ms/step - loss: 0.4528 - accuracy: 0.8715 - precision: 0.8673 - recall: 0.8771 - val_loss: 0.4192 - val_accuracy: 0.7500 - val_precision: 0.7500 - val_recall: 0.7500\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 2s 187ms/step - loss: 0.4567 - accuracy: 0.8582 - precision: 0.8566 - recall: 0.8582 - val_loss: 0.4235 - val_accuracy: 0.8056 - val_precision: 0.7838 - val_recall: 0.8056\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.4794 - accuracy: 0.8639 - precision: 0.8663 - recall: 0.8696 - val_loss: 0.5251 - val_accuracy: 0.7500 - val_precision: 0.7500 - val_recall: 0.7500\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.4476 - accuracy: 0.8752 - precision: 0.8769 - recall: 0.8752 - val_loss: 0.4619 - val_accuracy: 0.8333 - val_precision: 0.8333 - val_recall: 0.8333\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 44ms/step - loss: 0.4688 - accuracy: 0.8790 - precision: 0.8802 - recall: 0.8752 - val_loss: 0.4138 - val_accuracy: 0.7778 - val_precision: 0.7692 - val_recall: 0.8333\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.4646 - accuracy: 0.8828 - precision: 0.8845 - recall: 0.8828 - val_loss: 0.6045 - val_accuracy: 0.7500 - val_precision: 0.7297 - val_recall: 0.7500\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 1s 76ms/step - loss: 0.4499 - accuracy: 0.8677 - precision: 0.8628 - recall: 0.8677 - val_loss: 0.4377 - val_accuracy: 0.8333 - val_precision: 0.8333 - val_recall: 0.8333\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3946 - accuracy: 0.8847 - precision: 0.8780 - recall: 0.8847 - val_loss: 0.4620 - val_accuracy: 0.8333 - val_precision: 0.8333 - val_recall: 0.8333\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.4374 - accuracy: 0.8828 - precision: 0.8847 - recall: 0.8847 - val_loss: 0.4313 - val_accuracy: 0.7222 - val_precision: 0.7222 - val_recall: 0.7222\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.4501 - accuracy: 0.8696 - precision: 0.8630 - recall: 0.8696 - val_loss: 0.4027 - val_accuracy: 0.7500 - val_precision: 0.7500 - val_recall: 0.7500\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.4184 - accuracy: 0.8979 - precision: 0.9013 - recall: 0.8979 - val_loss: 0.4289 - val_accuracy: 0.8333 - val_precision: 0.8333 - val_recall: 0.8333\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.4281 - accuracy: 0.8752 - precision: 0.8717 - recall: 0.8733 - val_loss: 0.4732 - val_accuracy: 0.8333 - val_precision: 0.8333 - val_recall: 0.8333\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.4086 - accuracy: 0.8809 - precision: 0.8734 - recall: 0.8866 - val_loss: 0.4840 - val_accuracy: 0.8333 - val_precision: 0.7949 - val_recall: 0.8611\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.4239 - accuracy: 0.8677 - precision: 0.8698 - recall: 0.8715 - val_loss: 0.4598 - val_accuracy: 0.8333 - val_precision: 0.8333 - val_recall: 0.8333\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.3868 - accuracy: 0.8904 - precision: 0.8910 - recall: 0.8960 - val_loss: 0.3890 - val_accuracy: 0.8333 - val_precision: 0.8333 - val_recall: 0.8333\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3873 - accuracy: 0.8715 - precision: 0.8691 - recall: 0.8658 - val_loss: 0.5075 - val_accuracy: 0.8056 - val_precision: 0.8056 - val_recall: 0.8056\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 1s 67ms/step - loss: 0.4195 - accuracy: 0.8733 - precision: 0.8764 - recall: 0.8715 - val_loss: 0.3941 - val_accuracy: 0.7778 - val_precision: 0.7778 - val_recall: 0.7778\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.3649 - accuracy: 0.8847 - precision: 0.8885 - recall: 0.8885 - val_loss: 0.4545 - val_accuracy: 0.8056 - val_precision: 0.7895 - val_recall: 0.8333\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.4245 - accuracy: 0.8696 - precision: 0.8684 - recall: 0.8733 - val_loss: 0.4381 - val_accuracy: 0.8333 - val_precision: 0.8378 - val_recall: 0.8611\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 37ms/step - loss: 0.3635 - accuracy: 0.8960 - precision: 0.8895 - recall: 0.8979 - val_loss: 0.3923 - val_accuracy: 0.8333 - val_precision: 0.8333 - val_recall: 0.8333\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.3529 - accuracy: 0.8866 - precision: 0.8897 - recall: 0.8847 - val_loss: 0.4053 - val_accuracy: 0.7222 - val_precision: 0.7297 - val_recall: 0.7500\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3398 - accuracy: 0.8979 - precision: 0.8929 - recall: 0.8979 - val_loss: 0.4687 - val_accuracy: 0.7778 - val_precision: 0.7778 - val_recall: 0.7778\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.4638 - accuracy: 0.8715 - precision: 0.8682 - recall: 0.8715 - val_loss: 0.4161 - val_accuracy: 0.8333 - val_precision: 0.8108 - val_recall: 0.8333\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.3851 - accuracy: 0.8885 - precision: 0.8902 - recall: 0.8885 - val_loss: 0.3653 - val_accuracy: 0.8333 - val_precision: 0.8333 - val_recall: 0.8333\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.3783 - accuracy: 0.8960 - precision: 0.8964 - recall: 0.8998 - val_loss: 0.4448 - val_accuracy: 0.8333 - val_precision: 0.8333 - val_recall: 0.8333\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3743 - accuracy: 0.8979 - precision: 0.8945 - recall: 0.8979 - val_loss: 0.5214 - val_accuracy: 0.7500 - val_precision: 0.7500 - val_recall: 0.7500\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.3500 - accuracy: 0.8885 - precision: 0.8906 - recall: 0.8922 - val_loss: 0.3588 - val_accuracy: 0.8333 - val_precision: 0.8333 - val_recall: 0.8333\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3415 - accuracy: 0.8847 - precision: 0.8797 - recall: 0.8847 - val_loss: 0.4167 - val_accuracy: 0.8056 - val_precision: 0.8056 - val_recall: 0.8056\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3716 - accuracy: 0.8847 - precision: 0.8851 - recall: 0.8885 - val_loss: 0.3943 - val_accuracy: 0.8611 - val_precision: 0.8571 - val_recall: 0.8333\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3481 - accuracy: 0.8998 - precision: 0.8960 - recall: 0.8960 - val_loss: 0.3950 - val_accuracy: 0.8333 - val_precision: 0.8333 - val_recall: 0.8333\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3469 - accuracy: 0.8866 - precision: 0.8895 - recall: 0.8828 - val_loss: 0.3879 - val_accuracy: 0.8333 - val_precision: 0.8333 - val_recall: 0.8333\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3786 - accuracy: 0.8885 - precision: 0.8861 - recall: 0.8828 - val_loss: 0.3634 - val_accuracy: 0.7778 - val_precision: 0.7778 - val_recall: 0.7778\n",
      "Train on: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15]\n",
      "Test  on: 10\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 21:24:39.766652: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - ETA: 0s - loss: 0.9942 - accuracy: 0.5879 - precision: 0.5833 - recall: 0.6087"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 21:25:30.064157: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 55s 4s/step - loss: 0.9942 - accuracy: 0.5879 - precision: 0.5833 - recall: 0.6087 - val_loss: 0.5863 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 14s 1s/step - loss: 0.9013 - accuracy: 0.7202 - precision: 0.7077 - recall: 0.6957 - val_loss: 0.4263 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.9722\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 4s 372ms/step - loss: 0.7601 - accuracy: 0.7788 - precision: 0.7872 - recall: 0.7694 - val_loss: 0.4301 - val_accuracy: 0.8333 - val_precision: 0.8286 - val_recall: 0.8056\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 3s 284ms/step - loss: 0.6984 - accuracy: 0.7769 - precision: 0.7876 - recall: 0.7921 - val_loss: 0.3726 - val_accuracy: 0.8333 - val_precision: 0.8421 - val_recall: 0.8889\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 2s 231ms/step - loss: 0.6686 - accuracy: 0.7958 - precision: 0.8015 - recall: 0.7940 - val_loss: 0.1780 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 3s 279ms/step - loss: 0.6033 - accuracy: 0.8450 - precision: 0.8473 - recall: 0.8393 - val_loss: 0.2172 - val_accuracy: 0.9444 - val_precision: 0.9474 - val_recall: 1.0000\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 2s 160ms/step - loss: 0.6389 - accuracy: 0.8185 - precision: 0.8251 - recall: 0.8204 - val_loss: 0.3476 - val_accuracy: 0.9167 - val_precision: 0.8919 - val_recall: 0.9167\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 2s 156ms/step - loss: 0.5937 - accuracy: 0.8242 - precision: 0.8226 - recall: 0.8242 - val_loss: 0.1738 - val_accuracy: 0.9444 - val_precision: 0.9444 - val_recall: 0.9444\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 3s 262ms/step - loss: 0.6294 - accuracy: 0.8336 - precision: 0.8295 - recall: 0.8185 - val_loss: 0.1350 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 1s 119ms/step - loss: 0.5646 - accuracy: 0.8450 - precision: 0.8383 - recall: 0.8431 - val_loss: 0.1221 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 3s 252ms/step - loss: 0.5652 - accuracy: 0.8393 - precision: 0.8415 - recall: 0.8431 - val_loss: 0.2498 - val_accuracy: 0.9444 - val_precision: 0.9444 - val_recall: 0.9444\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 5s 531ms/step - loss: 0.5430 - accuracy: 0.8223 - precision: 0.8264 - recall: 0.8280 - val_loss: 0.1782 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 1s 77ms/step - loss: 0.5520 - accuracy: 0.8393 - precision: 0.8391 - recall: 0.8280 - val_loss: 0.1267 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.5841 - accuracy: 0.8336 - precision: 0.8286 - recall: 0.8318 - val_loss: 0.2839 - val_accuracy: 0.9444 - val_precision: 0.9444 - val_recall: 0.9444\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 3s 299ms/step - loss: 0.5762 - accuracy: 0.8223 - precision: 0.8257 - recall: 0.8147 - val_loss: 0.1740 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 1s 66ms/step - loss: 0.5374 - accuracy: 0.8544 - precision: 0.8528 - recall: 0.8544 - val_loss: 0.2313 - val_accuracy: 0.9444 - val_precision: 0.9444 - val_recall: 0.9444\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 1s 103ms/step - loss: 0.4862 - accuracy: 0.8677 - precision: 0.8748 - recall: 0.8715 - val_loss: 0.2651 - val_accuracy: 0.9444 - val_precision: 0.9444 - val_recall: 0.9444\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 2s 170ms/step - loss: 0.4958 - accuracy: 0.8431 - precision: 0.8374 - recall: 0.8374 - val_loss: 0.1124 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.5341 - accuracy: 0.8469 - precision: 0.8514 - recall: 0.8450 - val_loss: 0.1737 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 2s 155ms/step - loss: 0.4940 - accuracy: 0.8450 - precision: 0.8415 - recall: 0.8431 - val_loss: 0.1188 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 1s 59ms/step - loss: 0.4896 - accuracy: 0.8412 - precision: 0.8409 - recall: 0.8393 - val_loss: 0.1352 - val_accuracy: 0.9722 - val_precision: 0.9714 - val_recall: 0.9444\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 2s 181ms/step - loss: 0.5175 - accuracy: 0.8450 - precision: 0.8463 - recall: 0.8431 - val_loss: 0.1653 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 0.4736 - accuracy: 0.8507 - precision: 0.8480 - recall: 0.8544 - val_loss: 0.0940 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.9722\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 1s 130ms/step - loss: 0.5206 - accuracy: 0.8620 - precision: 0.8629 - recall: 0.8563 - val_loss: 0.1513 - val_accuracy: 0.9722 - val_precision: 1.0000 - val_recall: 0.9722\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 1s 123ms/step - loss: 0.4882 - accuracy: 0.8677 - precision: 0.8631 - recall: 0.8582 - val_loss: 0.2069 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.9722\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 0.4567 - accuracy: 0.8469 - precision: 0.8517 - recall: 0.8469 - val_loss: 0.1412 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.4839 - accuracy: 0.8582 - precision: 0.8582 - recall: 0.8582 - val_loss: 0.1250 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 2s 161ms/step - loss: 0.4509 - accuracy: 0.8771 - precision: 0.8759 - recall: 0.8809 - val_loss: 0.1822 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.4632 - accuracy: 0.8639 - precision: 0.8596 - recall: 0.8677 - val_loss: 0.1183 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.4447 - accuracy: 0.8639 - precision: 0.8649 - recall: 0.8715 - val_loss: 0.1513 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.4332 - accuracy: 0.8733 - precision: 0.8721 - recall: 0.8639 - val_loss: 0.3149 - val_accuracy: 0.8889 - val_precision: 0.9118 - val_recall: 0.8611\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.4400 - accuracy: 0.8620 - precision: 0.8654 - recall: 0.8507 - val_loss: 0.1610 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 0.4264 - accuracy: 0.8620 - precision: 0.8658 - recall: 0.8658 - val_loss: 0.1881 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.4245 - accuracy: 0.8715 - precision: 0.8710 - recall: 0.8677 - val_loss: 0.1323 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.5114 - accuracy: 0.8450 - precision: 0.8418 - recall: 0.8450 - val_loss: 0.1301 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.4330 - accuracy: 0.8733 - precision: 0.8722 - recall: 0.8771 - val_loss: 0.1599 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.4136 - accuracy: 0.8752 - precision: 0.8705 - recall: 0.8639 - val_loss: 0.1230 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3818 - accuracy: 0.8771 - precision: 0.8776 - recall: 0.8809 - val_loss: 0.1273 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.3936 - accuracy: 0.8960 - precision: 0.8895 - recall: 0.8979 - val_loss: 0.0879 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.4805 - accuracy: 0.8639 - precision: 0.8610 - recall: 0.8544 - val_loss: 0.1331 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.3689 - accuracy: 0.8733 - precision: 0.8698 - recall: 0.8715 - val_loss: 0.0876 - val_accuracy: 0.9722 - val_precision: 1.0000 - val_recall: 0.9722\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3917 - accuracy: 0.8941 - precision: 0.8925 - recall: 0.8941 - val_loss: 0.2383 - val_accuracy: 0.9444 - val_precision: 0.9444 - val_recall: 0.9444\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.3912 - accuracy: 0.8752 - precision: 0.8733 - recall: 0.8733 - val_loss: 0.1283 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3800 - accuracy: 0.8904 - precision: 0.8883 - recall: 0.8866 - val_loss: 0.0997 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.9722\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3861 - accuracy: 0.8752 - precision: 0.8736 - recall: 0.8752 - val_loss: 0.1363 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3946 - accuracy: 0.8790 - precision: 0.8786 - recall: 0.8752 - val_loss: 0.1213 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.4000 - accuracy: 0.8752 - precision: 0.8731 - recall: 0.8582 - val_loss: 0.1100 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3566 - accuracy: 0.8847 - precision: 0.8946 - recall: 0.8828 - val_loss: 0.1114 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3768 - accuracy: 0.8828 - precision: 0.8809 - recall: 0.8809 - val_loss: 0.1267 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3610 - accuracy: 0.8922 - precision: 0.8879 - recall: 0.8979 - val_loss: 0.0985 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3686 - accuracy: 0.8941 - precision: 0.8922 - recall: 0.8922 - val_loss: 0.1118 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3983 - accuracy: 0.8677 - precision: 0.8726 - recall: 0.8677 - val_loss: 0.1296 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3609 - accuracy: 0.8771 - precision: 0.8859 - recall: 0.8809 - val_loss: 0.1252 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3680 - accuracy: 0.8715 - precision: 0.8679 - recall: 0.8696 - val_loss: 0.1419 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.9722\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3710 - accuracy: 0.8904 - precision: 0.8925 - recall: 0.8941 - val_loss: 0.1179 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.3435 - accuracy: 0.8979 - precision: 0.8960 - recall: 0.8960 - val_loss: 0.0842 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3161 - accuracy: 0.8904 - precision: 0.8904 - recall: 0.8904 - val_loss: 0.0867 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.4134 - accuracy: 0.8601 - precision: 0.8629 - recall: 0.8563 - val_loss: 0.1257 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3547 - accuracy: 0.8847 - precision: 0.8897 - recall: 0.8696 - val_loss: 0.1395 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.9444\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.3462 - accuracy: 0.8960 - precision: 0.9038 - recall: 0.8885 - val_loss: 0.1334 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3679 - accuracy: 0.8904 - precision: 0.9072 - recall: 0.8866 - val_loss: 0.1064 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3280 - accuracy: 0.9093 - precision: 0.9013 - recall: 0.8979 - val_loss: 0.0930 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.3271 - accuracy: 0.9149 - precision: 0.9143 - recall: 0.9074 - val_loss: 0.0818 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3087 - accuracy: 0.9074 - precision: 0.9086 - recall: 0.9017 - val_loss: 0.1146 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3333 - accuracy: 0.8922 - precision: 0.8868 - recall: 0.8885 - val_loss: 0.0929 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.3045 - accuracy: 0.9093 - precision: 0.9034 - recall: 0.9017 - val_loss: 0.0758 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.3306 - accuracy: 0.8809 - precision: 0.8874 - recall: 0.8790 - val_loss: 0.1103 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.3659 - accuracy: 0.8733 - precision: 0.8769 - recall: 0.8752 - val_loss: 0.1068 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.3010 - accuracy: 0.9168 - precision: 0.9159 - recall: 0.9055 - val_loss: 0.0409 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.3243 - accuracy: 0.8885 - precision: 0.8908 - recall: 0.8941 - val_loss: 0.0573 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.9722\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.3330 - accuracy: 0.9055 - precision: 0.9040 - recall: 0.8904 - val_loss: 0.0716 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3279 - accuracy: 0.8922 - precision: 0.8920 - recall: 0.8904 - val_loss: 0.0962 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2955 - accuracy: 0.9093 - precision: 0.9159 - recall: 0.9055 - val_loss: 0.0983 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3493 - accuracy: 0.8979 - precision: 0.8990 - recall: 0.8922 - val_loss: 0.0780 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3160 - accuracy: 0.9074 - precision: 0.9195 - recall: 0.9074 - val_loss: 0.0616 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3197 - accuracy: 0.8979 - precision: 0.8981 - recall: 0.8998 - val_loss: 0.1227 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3337 - accuracy: 0.8904 - precision: 0.8908 - recall: 0.8941 - val_loss: 0.1111 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2906 - accuracy: 0.9206 - precision: 0.9113 - recall: 0.9130 - val_loss: 0.1105 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.2982 - accuracy: 0.8979 - precision: 0.8964 - recall: 0.8998 - val_loss: 0.0462 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3202 - accuracy: 0.9149 - precision: 0.9098 - recall: 0.9149 - val_loss: 0.0920 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3686 - accuracy: 0.9017 - precision: 0.9082 - recall: 0.8979 - val_loss: 0.1351 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.2729 - accuracy: 0.9282 - precision: 0.9313 - recall: 0.9225 - val_loss: 0.0821 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2611 - accuracy: 0.9319 - precision: 0.9321 - recall: 0.9338 - val_loss: 0.0643 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3190 - accuracy: 0.8979 - precision: 0.9105 - recall: 0.9036 - val_loss: 0.0709 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3284 - accuracy: 0.9168 - precision: 0.9077 - recall: 0.9112 - val_loss: 0.0780 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3387 - accuracy: 0.8998 - precision: 0.8974 - recall: 0.9093 - val_loss: 0.0775 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 1s 71ms/step - loss: 0.3233 - accuracy: 0.9036 - precision: 0.9086 - recall: 0.9017 - val_loss: 0.1368 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.2747 - accuracy: 0.9055 - precision: 0.9089 - recall: 0.9055 - val_loss: 0.1696 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2844 - accuracy: 0.9225 - precision: 0.9216 - recall: 0.9112 - val_loss: 0.0723 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.2854 - accuracy: 0.9074 - precision: 0.9087 - recall: 0.9036 - val_loss: 0.0744 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3063 - accuracy: 0.9112 - precision: 0.9068 - recall: 0.9017 - val_loss: 0.1109 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2685 - accuracy: 0.9244 - precision: 0.9275 - recall: 0.9187 - val_loss: 0.0480 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3332 - accuracy: 0.9112 - precision: 0.9112 - recall: 0.9112 - val_loss: 0.1163 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Train on: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15]\n",
      "Test  on: 11\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 21:26:55.941137: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - ETA: 0s - loss: 0.9736 - accuracy: 0.6786 - precision: 0.6536 - recall: 0.6597"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 21:27:51.140876: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 60s 4s/step - loss: 0.9736 - accuracy: 0.6786 - precision: 0.6536 - recall: 0.6597 - val_loss: 0.7796 - val_accuracy: 0.0556 - val_precision: 0.0556 - val_recall: 0.0556\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 11s 740ms/step - loss: 0.8597 - accuracy: 0.7202 - precision: 0.7211 - recall: 0.7183 - val_loss: 0.8666 - val_accuracy: 0.2778 - val_precision: 0.2778 - val_recall: 0.2778\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 5s 460ms/step - loss: 0.6715 - accuracy: 0.8110 - precision: 0.8161 - recall: 0.8223 - val_loss: 0.8880 - val_accuracy: 0.4167 - val_precision: 0.4167 - val_recall: 0.4167\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 4s 350ms/step - loss: 0.6099 - accuracy: 0.8318 - precision: 0.8308 - recall: 0.8261 - val_loss: 0.8834 - val_accuracy: 0.4722 - val_precision: 0.4412 - val_recall: 0.4167\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 3s 290ms/step - loss: 0.5886 - accuracy: 0.8412 - precision: 0.8352 - recall: 0.8336 - val_loss: 0.9153 - val_accuracy: 0.4444 - val_precision: 0.4444 - val_recall: 0.4444\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 5s 457ms/step - loss: 0.5463 - accuracy: 0.8526 - precision: 0.8526 - recall: 0.8526 - val_loss: 0.8548 - val_accuracy: 0.5000 - val_precision: 0.4706 - val_recall: 0.4444\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 2s 207ms/step - loss: 0.5389 - accuracy: 0.8582 - precision: 0.8636 - recall: 0.8620 - val_loss: 0.9453 - val_accuracy: 0.4722 - val_precision: 0.4722 - val_recall: 0.4722\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 7s 719ms/step - loss: 0.5175 - accuracy: 0.8563 - precision: 0.8574 - recall: 0.8639 - val_loss: 0.9789 - val_accuracy: 0.5000 - val_precision: 0.4615 - val_recall: 0.5000\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 2s 149ms/step - loss: 0.5011 - accuracy: 0.8696 - precision: 0.8660 - recall: 0.8677 - val_loss: 0.9046 - val_accuracy: 0.4722 - val_precision: 0.4857 - val_recall: 0.4722\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 1s 119ms/step - loss: 0.5071 - accuracy: 0.8677 - precision: 0.8655 - recall: 0.8639 - val_loss: 0.9767 - val_accuracy: 0.3611 - val_precision: 0.3611 - val_recall: 0.3611\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 44ms/step - loss: 0.4875 - accuracy: 0.8601 - precision: 0.8630 - recall: 0.8696 - val_loss: 0.9801 - val_accuracy: 0.4167 - val_precision: 0.4167 - val_recall: 0.4167\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 2s 162ms/step - loss: 0.5175 - accuracy: 0.8677 - precision: 0.8609 - recall: 0.8771 - val_loss: 0.9097 - val_accuracy: 0.4444 - val_precision: 0.4571 - val_recall: 0.4444\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 1s 71ms/step - loss: 0.4565 - accuracy: 0.8752 - precision: 0.8819 - recall: 0.8752 - val_loss: 0.9135 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 41ms/step - loss: 0.5117 - accuracy: 0.8733 - precision: 0.8710 - recall: 0.8677 - val_loss: 0.8370 - val_accuracy: 0.4722 - val_precision: 0.4722 - val_recall: 0.4722\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.4742 - accuracy: 0.8658 - precision: 0.8707 - recall: 0.8658 - val_loss: 0.8018 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 1s 63ms/step - loss: 0.4786 - accuracy: 0.8847 - precision: 0.8847 - recall: 0.8847 - val_loss: 0.8754 - val_accuracy: 0.5278 - val_precision: 0.5294 - val_recall: 0.5000\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 1s 78ms/step - loss: 0.4331 - accuracy: 0.8847 - precision: 0.8944 - recall: 0.8809 - val_loss: 0.8763 - val_accuracy: 0.5000 - val_precision: 0.5143 - val_recall: 0.5000\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.4908 - accuracy: 0.8752 - precision: 0.8738 - recall: 0.8639 - val_loss: 0.8768 - val_accuracy: 0.5556 - val_precision: 0.5152 - val_recall: 0.4722\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 1s 128ms/step - loss: 0.4492 - accuracy: 0.8771 - precision: 0.8776 - recall: 0.8809 - val_loss: 0.9019 - val_accuracy: 0.4444 - val_precision: 0.4324 - val_recall: 0.4444\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.4597 - accuracy: 0.8715 - precision: 0.8717 - recall: 0.8733 - val_loss: 0.9277 - val_accuracy: 0.5000 - val_precision: 0.5135 - val_recall: 0.5278\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 0.4150 - accuracy: 0.8866 - precision: 0.8897 - recall: 0.8847 - val_loss: 0.9675 - val_accuracy: 0.5000 - val_precision: 0.5294 - val_recall: 0.5000\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 2s 195ms/step - loss: 0.4476 - accuracy: 0.8658 - precision: 0.8601 - recall: 0.8601 - val_loss: 0.9211 - val_accuracy: 0.5000 - val_precision: 0.4865 - val_recall: 0.5000\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 1s 86ms/step - loss: 0.4041 - accuracy: 0.8809 - precision: 0.8797 - recall: 0.8847 - val_loss: 0.8599 - val_accuracy: 0.5556 - val_precision: 0.5526 - val_recall: 0.5833\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.4176 - accuracy: 0.8866 - precision: 0.8853 - recall: 0.8904 - val_loss: 0.8286 - val_accuracy: 0.5278 - val_precision: 0.5278 - val_recall: 0.5278\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 1s 99ms/step - loss: 0.4327 - accuracy: 0.8847 - precision: 0.8795 - recall: 0.8828 - val_loss: 0.9165 - val_accuracy: 0.4722 - val_precision: 0.4571 - val_recall: 0.4444\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.4165 - accuracy: 0.8866 - precision: 0.8893 - recall: 0.8809 - val_loss: 0.9290 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 1s 65ms/step - loss: 0.4205 - accuracy: 0.9055 - precision: 0.9017 - recall: 0.9017 - val_loss: 0.9114 - val_accuracy: 0.5278 - val_precision: 0.5278 - val_recall: 0.5278\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 40ms/step - loss: 0.4004 - accuracy: 0.8960 - precision: 0.8979 - recall: 0.8979 - val_loss: 0.8456 - val_accuracy: 0.5278 - val_precision: 0.5278 - val_recall: 0.5278\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 0.4384 - accuracy: 0.8904 - precision: 0.8906 - recall: 0.8922 - val_loss: 0.8085 - val_accuracy: 0.6111 - val_precision: 0.5946 - val_recall: 0.6111\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 1s 67ms/step - loss: 0.3916 - accuracy: 0.8941 - precision: 0.8943 - recall: 0.8960 - val_loss: 0.9312 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.4722\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 38ms/step - loss: 0.3614 - accuracy: 0.9017 - precision: 0.9015 - recall: 0.8998 - val_loss: 1.1173 - val_accuracy: 0.3611 - val_precision: 0.3714 - val_recall: 0.3611\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3584 - accuracy: 0.9017 - precision: 0.9017 - recall: 0.9017 - val_loss: 1.0430 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3672 - accuracy: 0.8960 - precision: 0.8992 - recall: 0.8941 - val_loss: 0.8526 - val_accuracy: 0.5278 - val_precision: 0.5278 - val_recall: 0.5278\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3425 - accuracy: 0.8998 - precision: 0.8962 - recall: 0.8979 - val_loss: 0.8905 - val_accuracy: 0.5556 - val_precision: 0.5429 - val_recall: 0.5278\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.3795 - accuracy: 0.9055 - precision: 0.9048 - recall: 0.8979 - val_loss: 0.9182 - val_accuracy: 0.5278 - val_precision: 0.5135 - val_recall: 0.5278\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 39ms/step - loss: 0.3507 - accuracy: 0.9036 - precision: 0.9017 - recall: 0.9017 - val_loss: 1.1501 - val_accuracy: 0.4167 - val_precision: 0.4167 - val_recall: 0.4167\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3219 - accuracy: 0.9093 - precision: 0.9108 - recall: 0.9074 - val_loss: 1.1486 - val_accuracy: 0.4722 - val_precision: 0.4571 - val_recall: 0.4444\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3235 - accuracy: 0.8979 - precision: 0.8996 - recall: 0.8979 - val_loss: 0.8471 - val_accuracy: 0.6389 - val_precision: 0.6364 - val_recall: 0.5833\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.3612 - accuracy: 0.9036 - precision: 0.9032 - recall: 0.8998 - val_loss: 0.8653 - val_accuracy: 0.5278 - val_precision: 0.5526 - val_recall: 0.5833\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3113 - accuracy: 0.9130 - precision: 0.9143 - recall: 0.9074 - val_loss: 1.0299 - val_accuracy: 0.4722 - val_precision: 0.4722 - val_recall: 0.4722\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.2837 - accuracy: 0.9187 - precision: 0.9163 - recall: 0.9112 - val_loss: 0.9006 - val_accuracy: 0.4722 - val_precision: 0.4722 - val_recall: 0.4722\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3491 - accuracy: 0.9017 - precision: 0.8970 - recall: 0.9055 - val_loss: 1.0325 - val_accuracy: 0.4167 - val_precision: 0.4324 - val_recall: 0.4444\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.3472 - accuracy: 0.9017 - precision: 0.8968 - recall: 0.9036 - val_loss: 1.0353 - val_accuracy: 0.4167 - val_precision: 0.4167 - val_recall: 0.4167\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.3048 - accuracy: 0.9187 - precision: 0.9153 - recall: 0.9187 - val_loss: 1.1335 - val_accuracy: 0.3889 - val_precision: 0.4211 - val_recall: 0.4444\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 1s 143ms/step - loss: 0.2969 - accuracy: 0.8922 - precision: 0.8931 - recall: 0.8998 - val_loss: 1.0074 - val_accuracy: 0.5278 - val_precision: 0.5278 - val_recall: 0.5278\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.3052 - accuracy: 0.9112 - precision: 0.9093 - recall: 0.9093 - val_loss: 1.0299 - val_accuracy: 0.4722 - val_precision: 0.4865 - val_recall: 0.5000\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 5s 518ms/step - loss: 0.2994 - accuracy: 0.9130 - precision: 0.9113 - recall: 0.9130 - val_loss: 1.1403 - val_accuracy: 0.4722 - val_precision: 0.4571 - val_recall: 0.4444\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 1s 28ms/step - loss: 0.2987 - accuracy: 0.9093 - precision: 0.9094 - recall: 0.9112 - val_loss: 1.1291 - val_accuracy: 0.5278 - val_precision: 0.5000 - val_recall: 0.5278\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.2898 - accuracy: 0.9130 - precision: 0.9110 - recall: 0.9093 - val_loss: 1.2728 - val_accuracy: 0.3611 - val_precision: 0.3529 - val_recall: 0.3333\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2948 - accuracy: 0.9112 - precision: 0.9113 - recall: 0.9130 - val_loss: 1.2614 - val_accuracy: 0.5000 - val_precision: 0.4857 - val_recall: 0.4722\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3047 - accuracy: 0.9187 - precision: 0.9170 - recall: 0.9187 - val_loss: 0.9160 - val_accuracy: 0.5556 - val_precision: 0.5625 - val_recall: 0.5000\n",
      "Train on: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15]\n",
      "Test  on: 12\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 21:29:06.471832: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - ETA: 0s - loss: 0.9821 - accuracy: 0.6125 - precision: 0.6011 - recall: 0.6068"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 21:30:01.051816: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 60s 4s/step - loss: 0.9821 - accuracy: 0.6125 - precision: 0.6011 - recall: 0.6068 - val_loss: 0.5894 - val_accuracy: 0.6944 - val_precision: 0.7143 - val_recall: 0.6944\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 11s 997ms/step - loss: 0.8709 - accuracy: 0.7051 - precision: 0.7085 - recall: 0.6938 - val_loss: 0.5296 - val_accuracy: 0.9722 - val_precision: 0.9211 - val_recall: 0.9722\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 4s 349ms/step - loss: 0.7370 - accuracy: 0.7372 - precision: 0.7404 - recall: 0.7278 - val_loss: 0.3323 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 4s 405ms/step - loss: 0.7134 - accuracy: 0.7921 - precision: 0.7891 - recall: 0.7921 - val_loss: 0.2674 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 8s 460ms/step - loss: 0.6639 - accuracy: 0.8053 - precision: 0.8046 - recall: 0.8015 - val_loss: 0.2925 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 2s 186ms/step - loss: 0.6639 - accuracy: 0.8129 - precision: 0.8068 - recall: 0.8129 - val_loss: 0.3152 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 0.6296 - accuracy: 0.8129 - precision: 0.8178 - recall: 0.8147 - val_loss: 0.3448 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 4s 347ms/step - loss: 0.5875 - accuracy: 0.8261 - precision: 0.8277 - recall: 0.8355 - val_loss: 0.2205 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 1s 99ms/step - loss: 0.5933 - accuracy: 0.8393 - precision: 0.8365 - recall: 0.8318 - val_loss: 0.1928 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 2s 201ms/step - loss: 0.5573 - accuracy: 0.8526 - precision: 0.8528 - recall: 0.8431 - val_loss: 0.2208 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 2s 212ms/step - loss: 0.5263 - accuracy: 0.8412 - precision: 0.8506 - recall: 0.8393 - val_loss: 0.1569 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 1s 98ms/step - loss: 0.5794 - accuracy: 0.8280 - precision: 0.8330 - recall: 0.8299 - val_loss: 0.1892 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 1s 74ms/step - loss: 0.5584 - accuracy: 0.8450 - precision: 0.8517 - recall: 0.8469 - val_loss: 0.2115 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 1s 114ms/step - loss: 0.5557 - accuracy: 0.8374 - precision: 0.8399 - recall: 0.8431 - val_loss: 0.2146 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 2s 158ms/step - loss: 0.5649 - accuracy: 0.8526 - precision: 0.8496 - recall: 0.8544 - val_loss: 0.1927 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 1s 93ms/step - loss: 0.5663 - accuracy: 0.8450 - precision: 0.8528 - recall: 0.8431 - val_loss: 0.3848 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 1s 117ms/step - loss: 0.5403 - accuracy: 0.8355 - precision: 0.8343 - recall: 0.8374 - val_loss: 0.1947 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 40ms/step - loss: 0.5403 - accuracy: 0.8488 - precision: 0.8470 - recall: 0.8374 - val_loss: 0.1906 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 2s 183ms/step - loss: 0.4966 - accuracy: 0.8582 - precision: 0.8539 - recall: 0.8620 - val_loss: 0.1660 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.5510 - accuracy: 0.8450 - precision: 0.8450 - recall: 0.8450 - val_loss: 0.2271 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 2s 167ms/step - loss: 0.4924 - accuracy: 0.8507 - precision: 0.8582 - recall: 0.8469 - val_loss: 0.1795 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.4796 - accuracy: 0.8469 - precision: 0.8547 - recall: 0.8450 - val_loss: 0.2103 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.5375 - accuracy: 0.8450 - precision: 0.8418 - recall: 0.8450 - val_loss: 0.2835 - val_accuracy: 0.9444 - val_precision: 0.9444 - val_recall: 0.9444\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.4804 - accuracy: 0.8507 - precision: 0.8509 - recall: 0.8526 - val_loss: 0.1858 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 0.4555 - accuracy: 0.8639 - precision: 0.8574 - recall: 0.8639 - val_loss: 0.1559 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.4828 - accuracy: 0.8582 - precision: 0.8596 - recall: 0.8563 - val_loss: 0.2693 - val_accuracy: 0.9444 - val_precision: 0.9444 - val_recall: 0.9444\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 1s 85ms/step - loss: 0.4642 - accuracy: 0.8488 - precision: 0.8440 - recall: 0.8488 - val_loss: 0.2043 - val_accuracy: 0.9444 - val_precision: 0.9189 - val_recall: 0.9444\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.4643 - accuracy: 0.8601 - precision: 0.8542 - recall: 0.8639 - val_loss: 0.2844 - val_accuracy: 0.9444 - val_precision: 0.9444 - val_recall: 0.9444\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 0.4401 - accuracy: 0.8563 - precision: 0.8596 - recall: 0.8563 - val_loss: 0.2169 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.4184 - accuracy: 0.8715 - precision: 0.8715 - recall: 0.8715 - val_loss: 0.1654 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.4572 - accuracy: 0.8620 - precision: 0.8642 - recall: 0.8658 - val_loss: 0.1849 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 3s 264ms/step - loss: 0.4109 - accuracy: 0.8828 - precision: 0.8831 - recall: 0.8715 - val_loss: 0.1715 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.4303 - accuracy: 0.8733 - precision: 0.8776 - recall: 0.8677 - val_loss: 0.1576 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.4072 - accuracy: 0.8715 - precision: 0.8727 - recall: 0.8809 - val_loss: 0.1367 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.4188 - accuracy: 0.8790 - precision: 0.8792 - recall: 0.8809 - val_loss: 0.1747 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.4096 - accuracy: 0.8752 - precision: 0.8668 - recall: 0.8733 - val_loss: 0.1292 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.4140 - accuracy: 0.8733 - precision: 0.8698 - recall: 0.8715 - val_loss: 0.1282 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.4118 - accuracy: 0.8715 - precision: 0.8698 - recall: 0.8715 - val_loss: 0.1913 - val_accuracy: 0.9444 - val_precision: 0.9444 - val_recall: 0.9444\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.4075 - accuracy: 0.8677 - precision: 0.8625 - recall: 0.8658 - val_loss: 0.1950 - val_accuracy: 0.9444 - val_precision: 0.9444 - val_recall: 0.9444\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3934 - accuracy: 0.8771 - precision: 0.8826 - recall: 0.8809 - val_loss: 0.1906 - val_accuracy: 0.9444 - val_precision: 0.9444 - val_recall: 0.9444\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3689 - accuracy: 0.8809 - precision: 0.8811 - recall: 0.8828 - val_loss: 0.1747 - val_accuracy: 0.9444 - val_precision: 0.9459 - val_recall: 0.9722\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 0.3880 - accuracy: 0.8715 - precision: 0.8736 - recall: 0.8752 - val_loss: 0.2571 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3976 - accuracy: 0.8620 - precision: 0.8590 - recall: 0.8526 - val_loss: 0.3467 - val_accuracy: 0.8611 - val_precision: 0.8857 - val_recall: 0.8611\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.5340 - accuracy: 0.8261 - precision: 0.8220 - recall: 0.8204 - val_loss: 0.1670 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3605 - accuracy: 0.8885 - precision: 0.8780 - recall: 0.8847 - val_loss: 0.1527 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3577 - accuracy: 0.9017 - precision: 0.8868 - recall: 0.9036 - val_loss: 0.1745 - val_accuracy: 0.9444 - val_precision: 0.9444 - val_recall: 0.9444\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.3360 - accuracy: 0.8809 - precision: 0.8759 - recall: 0.8809 - val_loss: 0.1151 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.3520 - accuracy: 0.8752 - precision: 0.8708 - recall: 0.8790 - val_loss: 0.1590 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.3476 - accuracy: 0.8866 - precision: 0.8843 - recall: 0.8960 - val_loss: 0.2744 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.3773 - accuracy: 0.8885 - precision: 0.8885 - recall: 0.8885 - val_loss: 0.1967 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3356 - accuracy: 0.8866 - precision: 0.8825 - recall: 0.8941 - val_loss: 0.1386 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.3544 - accuracy: 0.8885 - precision: 0.8856 - recall: 0.8922 - val_loss: 0.1393 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3362 - accuracy: 0.8790 - precision: 0.8897 - recall: 0.8847 - val_loss: 0.1526 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3610 - accuracy: 0.8904 - precision: 0.8899 - recall: 0.8866 - val_loss: 0.2293 - val_accuracy: 0.9722 - val_precision: 0.9211 - val_recall: 0.9722\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2990 - accuracy: 0.8960 - precision: 0.8854 - recall: 0.9055 - val_loss: 0.1766 - val_accuracy: 0.9444 - val_precision: 0.9444 - val_recall: 0.9444\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.3261 - accuracy: 0.8904 - precision: 0.8857 - recall: 0.8790 - val_loss: 0.1637 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3324 - accuracy: 0.8847 - precision: 0.8808 - recall: 0.8941 - val_loss: 0.1898 - val_accuracy: 0.9722 - val_precision: 0.9459 - val_recall: 0.9722\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3351 - accuracy: 0.9055 - precision: 0.8972 - recall: 0.9074 - val_loss: 0.1386 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.3306 - accuracy: 0.8979 - precision: 0.8970 - recall: 0.9055 - val_loss: 0.1894 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.3327 - accuracy: 0.8828 - precision: 0.8820 - recall: 0.8904 - val_loss: 0.1459 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3454 - accuracy: 0.8922 - precision: 0.8835 - recall: 0.8885 - val_loss: 0.1561 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.2930 - accuracy: 0.9093 - precision: 0.9077 - recall: 0.8922 - val_loss: 0.1929 - val_accuracy: 0.9444 - val_precision: 0.9429 - val_recall: 0.9167\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3318 - accuracy: 0.9036 - precision: 0.8978 - recall: 0.9130 - val_loss: 0.1603 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3120 - accuracy: 0.9130 - precision: 0.9094 - recall: 0.9112 - val_loss: 0.1799 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3264 - accuracy: 0.8998 - precision: 0.9051 - recall: 0.9017 - val_loss: 0.1550 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3251 - accuracy: 0.8960 - precision: 0.8879 - recall: 0.8979 - val_loss: 0.1544 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2620 - accuracy: 0.9225 - precision: 0.9121 - recall: 0.9225 - val_loss: 0.1531 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3399 - accuracy: 0.8998 - precision: 0.8856 - recall: 0.9074 - val_loss: 0.2060 - val_accuracy: 0.9444 - val_precision: 0.9444 - val_recall: 0.9444\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2856 - accuracy: 0.9036 - precision: 0.8980 - recall: 0.9149 - val_loss: 0.1455 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3289 - accuracy: 0.9036 - precision: 0.9004 - recall: 0.9055 - val_loss: 0.1576 - val_accuracy: 0.9722 - val_precision: 0.9459 - val_recall: 0.9722\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2994 - accuracy: 0.9017 - precision: 0.9043 - recall: 0.9112 - val_loss: 0.1578 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2916 - accuracy: 0.9074 - precision: 0.9146 - recall: 0.9112 - val_loss: 0.1402 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2689 - accuracy: 0.9130 - precision: 0.9120 - recall: 0.9206 - val_loss: 0.1154 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3155 - accuracy: 0.9074 - precision: 0.9058 - recall: 0.9093 - val_loss: 0.2029 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2778 - accuracy: 0.9225 - precision: 0.9071 - recall: 0.9225 - val_loss: 0.2350 - val_accuracy: 0.8889 - val_precision: 0.8857 - val_recall: 0.8611\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2825 - accuracy: 0.9244 - precision: 0.9223 - recall: 0.9206 - val_loss: 0.1443 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3076 - accuracy: 0.9168 - precision: 0.9098 - recall: 0.9149 - val_loss: 0.1449 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Train on: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15]\n",
      "Test  on: 13\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 21:31:18.067483: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - ETA: 0s - loss: 0.9666 - accuracy: 0.6427 - precision: 0.6289 - recall: 0.6408"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 21:32:02.515697: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 49s 3s/step - loss: 0.9666 - accuracy: 0.6427 - precision: 0.6289 - recall: 0.6408 - val_loss: 0.7065 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.6667\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 13s 1s/step - loss: 0.9210 - accuracy: 0.7372 - precision: 0.7337 - recall: 0.7448 - val_loss: 0.7101 - val_accuracy: 0.4444 - val_precision: 0.4571 - val_recall: 0.4444\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 4s 362ms/step - loss: 0.7803 - accuracy: 0.7807 - precision: 0.7714 - recall: 0.7656 - val_loss: 0.7615 - val_accuracy: 0.4167 - val_precision: 0.4167 - val_recall: 0.4167\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 3s 292ms/step - loss: 0.6913 - accuracy: 0.7713 - precision: 0.7694 - recall: 0.7694 - val_loss: 0.5653 - val_accuracy: 0.6944 - val_precision: 0.6750 - val_recall: 0.7500\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 4s 441ms/step - loss: 0.6403 - accuracy: 0.8223 - precision: 0.8192 - recall: 0.8053 - val_loss: 0.5339 - val_accuracy: 0.7778 - val_precision: 0.8000 - val_recall: 0.7778\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 4s 397ms/step - loss: 0.6001 - accuracy: 0.8185 - precision: 0.8241 - recall: 0.8147 - val_loss: 0.5168 - val_accuracy: 0.8056 - val_precision: 0.7838 - val_recall: 0.8056\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 2s 223ms/step - loss: 0.6184 - accuracy: 0.8129 - precision: 0.8164 - recall: 0.8072 - val_loss: 0.4527 - val_accuracy: 0.9167 - val_precision: 0.8500 - val_recall: 0.9444\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 6s 569ms/step - loss: 0.6028 - accuracy: 0.8166 - precision: 0.8234 - recall: 0.8110 - val_loss: 0.3939 - val_accuracy: 0.9444 - val_precision: 0.9189 - val_recall: 0.9444\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 2s 158ms/step - loss: 0.5957 - accuracy: 0.8110 - precision: 0.8117 - recall: 0.8147 - val_loss: 0.4178 - val_accuracy: 0.8333 - val_precision: 0.8333 - val_recall: 0.8333\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 2s 182ms/step - loss: 0.5464 - accuracy: 0.8431 - precision: 0.8419 - recall: 0.8355 - val_loss: 0.5003 - val_accuracy: 0.7222 - val_precision: 0.7222 - val_recall: 0.7222\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 1s 84ms/step - loss: 0.5814 - accuracy: 0.8469 - precision: 0.8520 - recall: 0.8488 - val_loss: 0.3887 - val_accuracy: 0.8611 - val_precision: 0.8824 - val_recall: 0.8333\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 2s 234ms/step - loss: 0.5362 - accuracy: 0.8544 - precision: 0.8477 - recall: 0.8526 - val_loss: 0.3385 - val_accuracy: 0.9167 - val_precision: 0.9412 - val_recall: 0.8889\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 1s 142ms/step - loss: 0.5830 - accuracy: 0.8242 - precision: 0.8333 - recall: 0.8223 - val_loss: 0.4633 - val_accuracy: 0.7222 - val_precision: 0.7143 - val_recall: 0.6944\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 1s 86ms/step - loss: 0.5493 - accuracy: 0.8544 - precision: 0.8514 - recall: 0.8450 - val_loss: 0.3819 - val_accuracy: 0.8333 - val_precision: 0.8333 - val_recall: 0.8333\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 3s 288ms/step - loss: 0.5781 - accuracy: 0.8336 - precision: 0.8356 - recall: 0.8261 - val_loss: 0.4099 - val_accuracy: 0.8333 - val_precision: 0.8286 - val_recall: 0.8056\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 1s 94ms/step - loss: 0.5379 - accuracy: 0.8488 - precision: 0.8501 - recall: 0.8469 - val_loss: 0.4384 - val_accuracy: 0.7222 - val_precision: 0.7647 - val_recall: 0.7222\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.5393 - accuracy: 0.8563 - precision: 0.8528 - recall: 0.8431 - val_loss: 0.3897 - val_accuracy: 0.9444 - val_precision: 0.9429 - val_recall: 0.9167\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.5346 - accuracy: 0.8601 - precision: 0.8626 - recall: 0.8544 - val_loss: 0.4560 - val_accuracy: 0.7222 - val_precision: 0.7222 - val_recall: 0.7222\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 1s 77ms/step - loss: 0.5294 - accuracy: 0.8526 - precision: 0.8526 - recall: 0.8526 - val_loss: 0.4262 - val_accuracy: 0.7222 - val_precision: 0.7222 - val_recall: 0.7222\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 1s 62ms/step - loss: 0.5116 - accuracy: 0.8450 - precision: 0.8491 - recall: 0.8507 - val_loss: 0.3344 - val_accuracy: 0.9167 - val_precision: 0.9412 - val_recall: 0.8889\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.5255 - accuracy: 0.8526 - precision: 0.8577 - recall: 0.8544 - val_loss: 0.3942 - val_accuracy: 0.7778 - val_precision: 0.7568 - val_recall: 0.7778\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.5290 - accuracy: 0.8450 - precision: 0.8504 - recall: 0.8488 - val_loss: 0.3667 - val_accuracy: 0.8611 - val_precision: 0.8611 - val_recall: 0.8611\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.5071 - accuracy: 0.8733 - precision: 0.8764 - recall: 0.8715 - val_loss: 0.3123 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 2s 153ms/step - loss: 0.4857 - accuracy: 0.8507 - precision: 0.8479 - recall: 0.8431 - val_loss: 0.4283 - val_accuracy: 0.7222 - val_precision: 0.7222 - val_recall: 0.7222\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.5318 - accuracy: 0.8526 - precision: 0.8547 - recall: 0.8563 - val_loss: 0.4073 - val_accuracy: 0.7500 - val_precision: 0.7368 - val_recall: 0.7778\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.5142 - accuracy: 0.8582 - precision: 0.8617 - recall: 0.8601 - val_loss: 0.3690 - val_accuracy: 0.7778 - val_precision: 0.7778 - val_recall: 0.7778\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 2s 221ms/step - loss: 0.5143 - accuracy: 0.8526 - precision: 0.8542 - recall: 0.8526 - val_loss: 0.3041 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 37ms/step - loss: 0.5067 - accuracy: 0.8526 - precision: 0.8463 - recall: 0.8431 - val_loss: 0.2911 - val_accuracy: 0.9444 - val_precision: 0.9444 - val_recall: 0.9444\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.4777 - accuracy: 0.8715 - precision: 0.8700 - recall: 0.8601 - val_loss: 0.3040 - val_accuracy: 0.8611 - val_precision: 0.8611 - val_recall: 0.8611\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.4618 - accuracy: 0.8752 - precision: 0.8736 - recall: 0.8752 - val_loss: 0.2631 - val_accuracy: 0.9444 - val_precision: 0.9444 - val_recall: 0.9444\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 1s 62ms/step - loss: 0.4630 - accuracy: 0.8696 - precision: 0.8736 - recall: 0.8620 - val_loss: 0.3864 - val_accuracy: 0.7778 - val_precision: 0.7368 - val_recall: 0.7778\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.4940 - accuracy: 0.8507 - precision: 0.8520 - recall: 0.8488 - val_loss: 0.2869 - val_accuracy: 0.8611 - val_precision: 0.8649 - val_recall: 0.8889\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.4458 - accuracy: 0.8715 - precision: 0.8633 - recall: 0.8715 - val_loss: 0.2920 - val_accuracy: 0.8611 - val_precision: 0.8857 - val_recall: 0.8611\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.4537 - accuracy: 0.8771 - precision: 0.8722 - recall: 0.8771 - val_loss: 0.4280 - val_accuracy: 0.7778 - val_precision: 0.7647 - val_recall: 0.7222\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 0.4924 - accuracy: 0.8355 - precision: 0.8358 - recall: 0.8374 - val_loss: 0.3083 - val_accuracy: 0.8333 - val_precision: 0.8333 - val_recall: 0.8333\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.5163 - accuracy: 0.8715 - precision: 0.8696 - recall: 0.8696 - val_loss: 0.1906 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.4351 - accuracy: 0.8677 - precision: 0.8650 - recall: 0.8601 - val_loss: 0.2201 - val_accuracy: 0.9167 - val_precision: 0.9429 - val_recall: 0.9167\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.4539 - accuracy: 0.8563 - precision: 0.8518 - recall: 0.8582 - val_loss: 0.2203 - val_accuracy: 0.9167 - val_precision: 0.9189 - val_recall: 0.9444\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.4608 - accuracy: 0.8733 - precision: 0.8757 - recall: 0.8790 - val_loss: 0.2193 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.4273 - accuracy: 0.8658 - precision: 0.8658 - recall: 0.8658 - val_loss: 0.2751 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 36ms/step - loss: 0.4266 - accuracy: 0.8733 - precision: 0.8707 - recall: 0.8658 - val_loss: 0.2248 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.4318 - accuracy: 0.8658 - precision: 0.8679 - recall: 0.8696 - val_loss: 0.1714 - val_accuracy: 0.9444 - val_precision: 0.9444 - val_recall: 0.9444\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.4246 - accuracy: 0.8828 - precision: 0.8797 - recall: 0.8847 - val_loss: 0.1947 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3778 - accuracy: 0.8847 - precision: 0.8838 - recall: 0.8771 - val_loss: 0.1874 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.3866 - accuracy: 0.8809 - precision: 0.8821 - recall: 0.8771 - val_loss: 0.1775 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.4454 - accuracy: 0.8677 - precision: 0.8631 - recall: 0.8582 - val_loss: 0.1879 - val_accuracy: 0.9444 - val_precision: 0.9714 - val_recall: 0.9444\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.4244 - accuracy: 0.8733 - precision: 0.8752 - recall: 0.8752 - val_loss: 0.1722 - val_accuracy: 0.9444 - val_precision: 0.9189 - val_recall: 0.9444\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3690 - accuracy: 0.8904 - precision: 0.8881 - recall: 0.8998 - val_loss: 0.1953 - val_accuracy: 0.8889 - val_precision: 0.8919 - val_recall: 0.9167\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.4036 - accuracy: 0.8866 - precision: 0.8899 - recall: 0.8866 - val_loss: 0.1635 - val_accuracy: 0.9444 - val_precision: 0.9189 - val_recall: 0.9444\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.4010 - accuracy: 0.8809 - precision: 0.8887 - recall: 0.8752 - val_loss: 0.1367 - val_accuracy: 0.9722 - val_precision: 1.0000 - val_recall: 0.9722\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.3987 - accuracy: 0.8771 - precision: 0.8802 - recall: 0.8752 - val_loss: 0.2571 - val_accuracy: 0.9722 - val_precision: 1.0000 - val_recall: 0.9167\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3967 - accuracy: 0.8847 - precision: 0.8849 - recall: 0.8866 - val_loss: 0.1506 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3966 - accuracy: 0.8904 - precision: 0.8946 - recall: 0.8828 - val_loss: 0.1755 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.3920 - accuracy: 0.8885 - precision: 0.8851 - recall: 0.8885 - val_loss: 0.1205 - val_accuracy: 0.9722 - val_precision: 0.9730 - val_recall: 1.0000\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3728 - accuracy: 0.8771 - precision: 0.8808 - recall: 0.8658 - val_loss: 0.2041 - val_accuracy: 0.9167 - val_precision: 0.8919 - val_recall: 0.9167\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3463 - accuracy: 0.9017 - precision: 0.9070 - recall: 0.9036 - val_loss: 0.1576 - val_accuracy: 0.9444 - val_precision: 0.9412 - val_recall: 0.8889\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.3828 - accuracy: 0.8904 - precision: 0.8929 - recall: 0.8828 - val_loss: 0.1141 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3748 - accuracy: 0.8752 - precision: 0.8736 - recall: 0.8752 - val_loss: 0.1550 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3923 - accuracy: 0.8733 - precision: 0.8757 - recall: 0.8658 - val_loss: 0.1420 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.9722\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3752 - accuracy: 0.8828 - precision: 0.8780 - recall: 0.8847 - val_loss: 0.1312 - val_accuracy: 0.9722 - val_precision: 0.9706 - val_recall: 0.9167\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.3730 - accuracy: 0.8790 - precision: 0.8800 - recall: 0.8733 - val_loss: 0.1976 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3758 - accuracy: 0.8809 - precision: 0.8811 - recall: 0.8828 - val_loss: 0.1277 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3520 - accuracy: 0.8885 - precision: 0.8883 - recall: 0.8866 - val_loss: 0.1246 - val_accuracy: 0.9722 - val_precision: 0.9714 - val_recall: 0.9444\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3449 - accuracy: 0.8922 - precision: 0.8975 - recall: 0.8941 - val_loss: 0.1213 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.4087 - accuracy: 0.8677 - precision: 0.8687 - recall: 0.8752 - val_loss: 0.1504 - val_accuracy: 0.9722 - val_precision: 0.9714 - val_recall: 0.9444\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.3538 - accuracy: 0.8904 - precision: 0.8983 - recall: 0.8847 - val_loss: 0.0903 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3315 - accuracy: 0.9074 - precision: 0.9007 - recall: 0.9093 - val_loss: 0.1197 - val_accuracy: 0.9722 - val_precision: 0.9714 - val_recall: 0.9444\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3394 - accuracy: 0.8904 - precision: 0.8925 - recall: 0.8790 - val_loss: 0.1218 - val_accuracy: 0.9722 - val_precision: 0.9714 - val_recall: 0.9444\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3545 - accuracy: 0.8847 - precision: 0.8853 - recall: 0.8904 - val_loss: 0.1167 - val_accuracy: 0.9444 - val_precision: 0.9444 - val_recall: 0.9444\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.5964 - accuracy: 0.8809 - precision: 0.8811 - recall: 0.8828 - val_loss: 0.2738 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.3553 - accuracy: 0.8904 - precision: 0.8977 - recall: 0.8790 - val_loss: 0.1620 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3348 - accuracy: 0.8922 - precision: 0.9011 - recall: 0.8960 - val_loss: 0.1155 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3324 - accuracy: 0.8904 - precision: 0.8899 - recall: 0.8866 - val_loss: 0.1181 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3312 - accuracy: 0.8960 - precision: 0.8935 - recall: 0.9036 - val_loss: 0.1486 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3308 - accuracy: 0.8941 - precision: 0.8929 - recall: 0.8979 - val_loss: 0.1162 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3472 - accuracy: 0.8979 - precision: 0.8992 - recall: 0.8941 - val_loss: 0.1365 - val_accuracy: 0.9722 - val_precision: 0.9714 - val_recall: 0.9444\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3184 - accuracy: 0.8979 - precision: 0.9030 - recall: 0.8979 - val_loss: 0.1258 - val_accuracy: 0.9444 - val_precision: 0.9714 - val_recall: 0.9444\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3014 - accuracy: 0.9206 - precision: 0.9148 - recall: 0.9130 - val_loss: 0.1279 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3312 - accuracy: 0.9093 - precision: 0.9093 - recall: 0.9093 - val_loss: 0.1147 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3021 - accuracy: 0.9036 - precision: 0.9040 - recall: 0.9074 - val_loss: 0.1000 - val_accuracy: 0.9444 - val_precision: 0.9444 - val_recall: 0.9444\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3432 - accuracy: 0.8960 - precision: 0.8989 - recall: 0.8904 - val_loss: 0.1213 - val_accuracy: 0.9444 - val_precision: 0.9444 - val_recall: 0.9444\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.3067 - accuracy: 0.9187 - precision: 0.9189 - recall: 0.9206 - val_loss: 0.0885 - val_accuracy: 0.9444 - val_precision: 0.9444 - val_recall: 0.9444\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.3778 - accuracy: 0.8960 - precision: 0.8912 - recall: 0.8979 - val_loss: 0.1268 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3185 - accuracy: 0.9168 - precision: 0.9184 - recall: 0.9149 - val_loss: 0.1321 - val_accuracy: 0.9444 - val_precision: 0.9444 - val_recall: 0.9444\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3444 - accuracy: 0.9017 - precision: 0.8960 - recall: 0.8960 - val_loss: 0.1138 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.2884 - accuracy: 0.9112 - precision: 0.9082 - recall: 0.9168 - val_loss: 0.1539 - val_accuracy: 0.9722 - val_precision: 0.9714 - val_recall: 0.9444\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3021 - accuracy: 0.9206 - precision: 0.9189 - recall: 0.9206 - val_loss: 0.1781 - val_accuracy: 0.9167 - val_precision: 0.8919 - val_recall: 0.9167\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2831 - accuracy: 0.9149 - precision: 0.9148 - recall: 0.9130 - val_loss: 0.1259 - val_accuracy: 0.9444 - val_precision: 0.9444 - val_recall: 0.9444\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 8s 757ms/step - loss: 0.2767 - accuracy: 0.9225 - precision: 0.9221 - recall: 0.9168 - val_loss: 0.1169 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 1s 111ms/step - loss: 0.3543 - accuracy: 0.9036 - precision: 0.8994 - recall: 0.8960 - val_loss: 0.1540 - val_accuracy: 0.9444 - val_precision: 0.9444 - val_recall: 0.9444\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3109 - accuracy: 0.9093 - precision: 0.9074 - recall: 0.9074 - val_loss: 0.1137 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2797 - accuracy: 0.9263 - precision: 0.9209 - recall: 0.9244 - val_loss: 0.0960 - val_accuracy: 0.9444 - val_precision: 0.9459 - val_recall: 0.9722\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 1s 53ms/step - loss: 0.2949 - accuracy: 0.9149 - precision: 0.9167 - recall: 0.9149 - val_loss: 0.0896 - val_accuracy: 0.9444 - val_precision: 0.9444 - val_recall: 0.9444\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.2946 - accuracy: 0.9206 - precision: 0.9099 - recall: 0.9168 - val_loss: 0.1088 - val_accuracy: 0.9444 - val_precision: 0.9714 - val_recall: 0.9444\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.2993 - accuracy: 0.9130 - precision: 0.9148 - recall: 0.9130 - val_loss: 0.1033 - val_accuracy: 0.9444 - val_precision: 0.9444 - val_recall: 0.9444\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.3141 - accuracy: 0.9017 - precision: 0.9053 - recall: 0.9036 - val_loss: 0.1227 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3165 - accuracy: 0.9130 - precision: 0.9096 - recall: 0.9130 - val_loss: 0.1050 - val_accuracy: 0.9444 - val_precision: 0.9444 - val_recall: 0.9444\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.2704 - accuracy: 0.9225 - precision: 0.9184 - recall: 0.9149 - val_loss: 0.1228 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.3338 - accuracy: 0.9036 - precision: 0.9042 - recall: 0.8922 - val_loss: 0.0983 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 1s 89ms/step - loss: 0.2908 - accuracy: 0.9282 - precision: 0.9195 - recall: 0.9282 - val_loss: 0.0887 - val_accuracy: 0.9444 - val_precision: 0.9444 - val_recall: 0.9444\n",
      "Train on: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15]\n",
      "Test  on: 14\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 21:33:37.131992: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - ETA: 0s - loss: 0.9973 - accuracy: 0.6163 - precision: 0.6160 - recall: 0.5520"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 21:34:26.491474: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 54s 3s/step - loss: 0.9973 - accuracy: 0.6163 - precision: 0.6160 - recall: 0.5520 - val_loss: 0.6384 - val_accuracy: 0.6944 - val_precision: 0.6757 - val_recall: 0.6944\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 14s 1s/step - loss: 0.8892 - accuracy: 0.7127 - precision: 0.6971 - recall: 0.6919 - val_loss: 0.5521 - val_accuracy: 0.6944 - val_precision: 0.6944 - val_recall: 0.6944\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 3s 332ms/step - loss: 0.7986 - accuracy: 0.7505 - precision: 0.7457 - recall: 0.7429 - val_loss: 0.6089 - val_accuracy: 0.6111 - val_precision: 0.6216 - val_recall: 0.6389\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 6s 517ms/step - loss: 0.6284 - accuracy: 0.8204 - precision: 0.8209 - recall: 0.8318 - val_loss: 0.6123 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.6667\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 3s 278ms/step - loss: 0.5549 - accuracy: 0.8204 - precision: 0.8208 - recall: 0.8223 - val_loss: 0.7828 - val_accuracy: 0.4722 - val_precision: 0.4865 - val_recall: 0.5000\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 3s 337ms/step - loss: 0.5808 - accuracy: 0.8544 - precision: 0.8462 - recall: 0.8526 - val_loss: 0.7785 - val_accuracy: 0.4722 - val_precision: 0.4722 - val_recall: 0.4722\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 2s 151ms/step - loss: 0.5788 - accuracy: 0.8620 - precision: 0.8579 - recall: 0.8677 - val_loss: 0.7693 - val_accuracy: 0.4722 - val_precision: 0.4722 - val_recall: 0.4722\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 2s 155ms/step - loss: 0.5413 - accuracy: 0.8639 - precision: 0.8615 - recall: 0.8582 - val_loss: 0.8344 - val_accuracy: 0.5000 - val_precision: 0.5135 - val_recall: 0.5278\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 5s 511ms/step - loss: 0.4885 - accuracy: 0.8601 - precision: 0.8497 - recall: 0.8658 - val_loss: 0.7447 - val_accuracy: 0.5556 - val_precision: 0.5556 - val_recall: 0.5556\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 1s 115ms/step - loss: 0.5362 - accuracy: 0.8658 - precision: 0.8630 - recall: 0.8696 - val_loss: 0.7589 - val_accuracy: 0.4722 - val_precision: 0.4722 - val_recall: 0.4722\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 2s 199ms/step - loss: 0.4950 - accuracy: 0.8752 - precision: 0.8731 - recall: 0.8847 - val_loss: 0.7386 - val_accuracy: 0.5278 - val_precision: 0.5405 - val_recall: 0.5556\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.4907 - accuracy: 0.8715 - precision: 0.8682 - recall: 0.8715 - val_loss: 0.7923 - val_accuracy: 0.5000 - val_precision: 0.5135 - val_recall: 0.5278\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.4690 - accuracy: 0.8866 - precision: 0.8832 - recall: 0.8866 - val_loss: 0.8021 - val_accuracy: 0.6111 - val_precision: 0.6216 - val_recall: 0.6389\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 36ms/step - loss: 0.4863 - accuracy: 0.8696 - precision: 0.8625 - recall: 0.8658 - val_loss: 0.7915 - val_accuracy: 0.5000 - val_precision: 0.5135 - val_recall: 0.5278\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 1s 142ms/step - loss: 0.4974 - accuracy: 0.8752 - precision: 0.8752 - recall: 0.8752 - val_loss: 0.7703 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 3s 259ms/step - loss: 0.4736 - accuracy: 0.8639 - precision: 0.8731 - recall: 0.8715 - val_loss: 0.6790 - val_accuracy: 0.5556 - val_precision: 0.5526 - val_recall: 0.5833\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.4444 - accuracy: 0.8733 - precision: 0.8745 - recall: 0.8828 - val_loss: 0.7819 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 0.4613 - accuracy: 0.8752 - precision: 0.8745 - recall: 0.8696 - val_loss: 0.6886 - val_accuracy: 0.6389 - val_precision: 0.6286 - val_recall: 0.6111\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.4378 - accuracy: 0.8809 - precision: 0.8764 - recall: 0.8847 - val_loss: 0.6893 - val_accuracy: 0.5833 - val_precision: 0.5588 - val_recall: 0.5278\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 3s 266ms/step - loss: 0.4379 - accuracy: 0.8828 - precision: 0.8797 - recall: 0.8847 - val_loss: 0.8299 - val_accuracy: 0.4722 - val_precision: 0.4865 - val_recall: 0.5000\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 38ms/step - loss: 0.4113 - accuracy: 0.8941 - precision: 0.8918 - recall: 0.8885 - val_loss: 0.7976 - val_accuracy: 0.5556 - val_precision: 0.5405 - val_recall: 0.5556\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.4153 - accuracy: 0.8790 - precision: 0.8774 - recall: 0.8790 - val_loss: 0.7400 - val_accuracy: 0.6111 - val_precision: 0.6111 - val_recall: 0.6111\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 2s 214ms/step - loss: 0.4345 - accuracy: 0.8847 - precision: 0.8847 - recall: 0.8847 - val_loss: 0.6928 - val_accuracy: 0.5833 - val_precision: 0.6053 - val_recall: 0.6389\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 38ms/step - loss: 0.3846 - accuracy: 0.8752 - precision: 0.8769 - recall: 0.8752 - val_loss: 0.8661 - val_accuracy: 0.4167 - val_precision: 0.4062 - val_recall: 0.3611\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.4069 - accuracy: 0.8733 - precision: 0.8752 - recall: 0.8752 - val_loss: 0.9183 - val_accuracy: 0.5556 - val_precision: 0.5556 - val_recall: 0.5556\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 0.4362 - accuracy: 0.8696 - precision: 0.8642 - recall: 0.8658 - val_loss: 0.7499 - val_accuracy: 0.6111 - val_precision: 0.6000 - val_recall: 0.5833\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.4123 - accuracy: 0.8828 - precision: 0.8814 - recall: 0.8847 - val_loss: 0.7752 - val_accuracy: 0.5833 - val_precision: 0.5789 - val_recall: 0.6111\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.4102 - accuracy: 0.8866 - precision: 0.8811 - recall: 0.8828 - val_loss: 0.6901 - val_accuracy: 0.5556 - val_precision: 0.5556 - val_recall: 0.5556\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 1s 103ms/step - loss: 0.3846 - accuracy: 0.8696 - precision: 0.8701 - recall: 0.8733 - val_loss: 0.6781 - val_accuracy: 0.6111 - val_precision: 0.5946 - val_recall: 0.6111\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.3580 - accuracy: 0.8904 - precision: 0.8874 - recall: 0.8941 - val_loss: 0.5890 - val_accuracy: 0.7222 - val_precision: 0.7297 - val_recall: 0.7500\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.3854 - accuracy: 0.8904 - precision: 0.8933 - recall: 0.8866 - val_loss: 0.7350 - val_accuracy: 0.6389 - val_precision: 0.6389 - val_recall: 0.6389\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.4237 - accuracy: 0.8696 - precision: 0.8696 - recall: 0.8696 - val_loss: 0.6270 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.6667\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 1s 62ms/step - loss: 0.3866 - accuracy: 0.8922 - precision: 0.8891 - recall: 0.8941 - val_loss: 0.7995 - val_accuracy: 0.6111 - val_precision: 0.6111 - val_recall: 0.6111\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3962 - accuracy: 0.8771 - precision: 0.8738 - recall: 0.8771 - val_loss: 0.7251 - val_accuracy: 0.5278 - val_precision: 0.5263 - val_recall: 0.5556\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.4348 - accuracy: 0.8696 - precision: 0.8686 - recall: 0.8620 - val_loss: 0.6875 - val_accuracy: 0.6389 - val_precision: 0.6389 - val_recall: 0.6389\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3537 - accuracy: 0.8904 - precision: 0.8933 - recall: 0.8866 - val_loss: 0.7571 - val_accuracy: 0.6111 - val_precision: 0.6111 - val_recall: 0.6111\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3400 - accuracy: 0.8941 - precision: 0.8964 - recall: 0.8828 - val_loss: 0.6900 - val_accuracy: 0.6111 - val_precision: 0.6111 - val_recall: 0.6111\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.3559 - accuracy: 0.8828 - precision: 0.8799 - recall: 0.8866 - val_loss: 0.7765 - val_accuracy: 0.6389 - val_precision: 0.6389 - val_recall: 0.6389\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3713 - accuracy: 0.8885 - precision: 0.8891 - recall: 0.8941 - val_loss: 0.7980 - val_accuracy: 0.6389 - val_precision: 0.6389 - val_recall: 0.6389\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3272 - accuracy: 0.8998 - precision: 0.8998 - recall: 0.8998 - val_loss: 0.7590 - val_accuracy: 0.6389 - val_precision: 0.6389 - val_recall: 0.6389\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3587 - accuracy: 0.8828 - precision: 0.8807 - recall: 0.8790 - val_loss: 0.6442 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.7222\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3432 - accuracy: 0.8696 - precision: 0.8710 - recall: 0.8809 - val_loss: 0.7759 - val_accuracy: 0.6389 - val_precision: 0.6486 - val_recall: 0.6667\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 44ms/step - loss: 0.3537 - accuracy: 0.8885 - precision: 0.8906 - recall: 0.8922 - val_loss: 0.7752 - val_accuracy: 0.6667 - val_precision: 0.6486 - val_recall: 0.6667\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3361 - accuracy: 0.9017 - precision: 0.8989 - recall: 0.8904 - val_loss: 0.6929 - val_accuracy: 0.6389 - val_precision: 0.6316 - val_recall: 0.6667\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.3650 - accuracy: 0.8904 - precision: 0.8870 - recall: 0.8904 - val_loss: 0.6187 - val_accuracy: 0.6667 - val_precision: 0.6757 - val_recall: 0.6944\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.2942 - accuracy: 0.9055 - precision: 0.9086 - recall: 0.9017 - val_loss: 0.6209 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.6667\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.3401 - accuracy: 0.8904 - precision: 0.8902 - recall: 0.8885 - val_loss: 0.6098 - val_accuracy: 0.6667 - val_precision: 0.6944 - val_recall: 0.6944\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.3195 - accuracy: 0.9112 - precision: 0.9110 - recall: 0.9093 - val_loss: 0.6658 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.6667\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3035 - accuracy: 0.8979 - precision: 0.8927 - recall: 0.8960 - val_loss: 1.0313 - val_accuracy: 0.5833 - val_precision: 0.5833 - val_recall: 0.5833\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3588 - accuracy: 0.8866 - precision: 0.8866 - recall: 0.8866 - val_loss: 0.8039 - val_accuracy: 0.6111 - val_precision: 0.6111 - val_recall: 0.6111\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.2913 - accuracy: 0.9093 - precision: 0.9159 - recall: 0.9055 - val_loss: 0.7144 - val_accuracy: 0.7222 - val_precision: 0.7222 - val_recall: 0.7222\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.3709 - accuracy: 0.8790 - precision: 0.8870 - recall: 0.8752 - val_loss: 0.6610 - val_accuracy: 0.6944 - val_precision: 0.6944 - val_recall: 0.6944\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2959 - accuracy: 0.9017 - precision: 0.9015 - recall: 0.8998 - val_loss: 0.6807 - val_accuracy: 0.6667 - val_precision: 0.6486 - val_recall: 0.6667\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.3145 - accuracy: 0.8904 - precision: 0.8958 - recall: 0.8941 - val_loss: 0.7137 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.6667\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3002 - accuracy: 0.9017 - precision: 0.8983 - recall: 0.9017 - val_loss: 0.7524 - val_accuracy: 0.6944 - val_precision: 0.6944 - val_recall: 0.6944\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.2843 - accuracy: 0.9130 - precision: 0.9178 - recall: 0.9074 - val_loss: 0.7986 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.6667\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2782 - accuracy: 0.9168 - precision: 0.9135 - recall: 0.9187 - val_loss: 0.6552 - val_accuracy: 0.7222 - val_precision: 0.7222 - val_recall: 0.7222\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3176 - accuracy: 0.8960 - precision: 0.8967 - recall: 0.8866 - val_loss: 0.6129 - val_accuracy: 0.6944 - val_precision: 0.7143 - val_recall: 0.6944\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.2914 - accuracy: 0.9093 - precision: 0.9124 - recall: 0.9055 - val_loss: 0.6550 - val_accuracy: 0.6944 - val_precision: 0.6944 - val_recall: 0.6944\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.2569 - accuracy: 0.9149 - precision: 0.9067 - recall: 0.9187 - val_loss: 0.6432 - val_accuracy: 0.6667 - val_precision: 0.6757 - val_recall: 0.6944\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3156 - accuracy: 0.8922 - precision: 0.8929 - recall: 0.8979 - val_loss: 0.6767 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.6667\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.2927 - accuracy: 0.9017 - precision: 0.9021 - recall: 0.9055 - val_loss: 0.5020 - val_accuracy: 0.7500 - val_precision: 0.7368 - val_recall: 0.7778\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2935 - accuracy: 0.9112 - precision: 0.9045 - recall: 0.9130 - val_loss: 0.5509 - val_accuracy: 0.7500 - val_precision: 0.7500 - val_recall: 0.7500\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3015 - accuracy: 0.9168 - precision: 0.9118 - recall: 0.9187 - val_loss: 0.5439 - val_accuracy: 0.6944 - val_precision: 0.7027 - val_recall: 0.7222\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.2676 - accuracy: 0.9130 - precision: 0.9084 - recall: 0.9187 - val_loss: 0.8333 - val_accuracy: 0.6667 - val_precision: 0.6757 - val_recall: 0.6944\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2796 - accuracy: 0.9263 - precision: 0.9159 - recall: 0.9263 - val_loss: 0.7581 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.6667\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2806 - accuracy: 0.9093 - precision: 0.9106 - recall: 0.9055 - val_loss: 0.7396 - val_accuracy: 0.6944 - val_precision: 0.7027 - val_recall: 0.7222\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2847 - accuracy: 0.9112 - precision: 0.9112 - recall: 0.9112 - val_loss: 0.6697 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.6667\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2596 - accuracy: 0.9187 - precision: 0.9153 - recall: 0.9187 - val_loss: 0.7888 - val_accuracy: 0.6944 - val_precision: 0.6757 - val_recall: 0.6944\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.2780 - accuracy: 0.9074 - precision: 0.9072 - recall: 0.9055 - val_loss: 0.9991 - val_accuracy: 0.6389 - val_precision: 0.6286 - val_recall: 0.6111\n",
      "Train on: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "Test  on: 15\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 21:35:43.042954: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - ETA: 0s - loss: 0.9429 - accuracy: 0.6208 - precision: 0.6257 - recall: 0.6151"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 21:36:26.323265: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 48s 3s/step - loss: 0.9429 - accuracy: 0.6208 - precision: 0.6257 - recall: 0.6151 - val_loss: 0.8062 - val_accuracy: 0.4286 - val_precision: 0.3902 - val_recall: 0.4571\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 13s 1s/step - loss: 0.8238 - accuracy: 0.7057 - precision: 0.6990 - recall: 0.6925 - val_loss: 0.6412 - val_accuracy: 0.6286 - val_precision: 0.6286 - val_recall: 0.6286\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 8s 802ms/step - loss: 0.6790 - accuracy: 0.7906 - precision: 0.7917 - recall: 0.7887 - val_loss: 0.8060 - val_accuracy: 0.6286 - val_precision: 0.6286 - val_recall: 0.6286\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 7s 720ms/step - loss: 0.5709 - accuracy: 0.8283 - precision: 0.8299 - recall: 0.8283 - val_loss: 1.2030 - val_accuracy: 0.5714 - val_precision: 0.5556 - val_recall: 0.5714\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 2s 180ms/step - loss: 0.5440 - accuracy: 0.8377 - precision: 0.8453 - recall: 0.8453 - val_loss: 1.3489 - val_accuracy: 0.5429 - val_precision: 0.5278 - val_recall: 0.5429\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 3s 284ms/step - loss: 0.5153 - accuracy: 0.8509 - precision: 0.8531 - recall: 0.8547 - val_loss: 1.5254 - val_accuracy: 0.4857 - val_precision: 0.4857 - val_recall: 0.4857\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 0.5108 - accuracy: 0.8509 - precision: 0.8528 - recall: 0.8528 - val_loss: 1.3193 - val_accuracy: 0.5714 - val_precision: 0.5714 - val_recall: 0.5714\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 3s 257ms/step - loss: 0.5184 - accuracy: 0.8491 - precision: 0.8469 - recall: 0.8453 - val_loss: 1.2344 - val_accuracy: 0.6000 - val_precision: 0.5833 - val_recall: 0.6000\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 2s 175ms/step - loss: 0.4744 - accuracy: 0.8604 - precision: 0.8620 - recall: 0.8604 - val_loss: 1.1459 - val_accuracy: 0.6286 - val_precision: 0.6286 - val_recall: 0.6286\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 1s 57ms/step - loss: 0.4710 - accuracy: 0.8736 - precision: 0.8692 - recall: 0.8774 - val_loss: 1.4583 - val_accuracy: 0.5143 - val_precision: 0.5278 - val_recall: 0.5429\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 0.4689 - accuracy: 0.8792 - precision: 0.8843 - recall: 0.8792 - val_loss: 1.1395 - val_accuracy: 0.6000 - val_precision: 0.6111 - val_recall: 0.6286\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 1s 95ms/step - loss: 0.4511 - accuracy: 0.8868 - precision: 0.8920 - recall: 0.8887 - val_loss: 1.2045 - val_accuracy: 0.5429 - val_precision: 0.5429 - val_recall: 0.5429\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.4417 - accuracy: 0.8698 - precision: 0.8670 - recall: 0.8736 - val_loss: 1.0954 - val_accuracy: 0.6000 - val_precision: 0.6111 - val_recall: 0.6286\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 3s 275ms/step - loss: 0.4441 - accuracy: 0.8811 - precision: 0.8807 - recall: 0.8774 - val_loss: 1.2210 - val_accuracy: 0.5429 - val_precision: 0.5429 - val_recall: 0.5429\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.4280 - accuracy: 0.8830 - precision: 0.8845 - recall: 0.8811 - val_loss: 1.2666 - val_accuracy: 0.4857 - val_precision: 0.4857 - val_recall: 0.4857\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 1s 108ms/step - loss: 0.4218 - accuracy: 0.8811 - precision: 0.8868 - recall: 0.8868 - val_loss: 1.2520 - val_accuracy: 0.5143 - val_precision: 0.5278 - val_recall: 0.5429\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.4096 - accuracy: 0.8925 - precision: 0.8881 - recall: 0.8981 - val_loss: 1.3890 - val_accuracy: 0.4857 - val_precision: 0.4857 - val_recall: 0.4857\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 2s 220ms/step - loss: 0.4389 - accuracy: 0.8868 - precision: 0.8870 - recall: 0.8887 - val_loss: 1.2845 - val_accuracy: 0.5143 - val_precision: 0.5294 - val_recall: 0.5143\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 1s 137ms/step - loss: 0.3898 - accuracy: 0.9057 - precision: 0.9055 - recall: 0.9038 - val_loss: 1.8021 - val_accuracy: 0.4000 - val_precision: 0.4000 - val_recall: 0.4000\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 1s 63ms/step - loss: 0.4018 - accuracy: 0.8679 - precision: 0.8710 - recall: 0.8660 - val_loss: 1.4247 - val_accuracy: 0.4857 - val_precision: 0.5000 - val_recall: 0.5143\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 1s 55ms/step - loss: 0.3656 - accuracy: 0.8906 - precision: 0.8939 - recall: 0.8906 - val_loss: 1.3549 - val_accuracy: 0.5429 - val_precision: 0.5429 - val_recall: 0.5429\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.4369 - accuracy: 0.8849 - precision: 0.8799 - recall: 0.8849 - val_loss: 1.4484 - val_accuracy: 0.5143 - val_precision: 0.5143 - val_recall: 0.5143\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.3779 - accuracy: 0.8943 - precision: 0.8895 - recall: 0.8962 - val_loss: 1.5654 - val_accuracy: 0.4857 - val_precision: 0.4857 - val_recall: 0.4857\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3612 - accuracy: 0.9075 - precision: 0.9106 - recall: 0.9038 - val_loss: 1.5306 - val_accuracy: 0.4857 - val_precision: 0.4857 - val_recall: 0.4857\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 1s 115ms/step - loss: 0.3352 - accuracy: 0.8981 - precision: 0.9026 - recall: 0.9094 - val_loss: 1.8196 - val_accuracy: 0.4857 - val_precision: 0.5000 - val_recall: 0.5143\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.3565 - accuracy: 0.8925 - precision: 0.8962 - recall: 0.8962 - val_loss: 1.5281 - val_accuracy: 0.4857 - val_precision: 0.4857 - val_recall: 0.4857\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 4s 423ms/step - loss: 0.3695 - accuracy: 0.9019 - precision: 0.8955 - recall: 0.9057 - val_loss: 1.5132 - val_accuracy: 0.4857 - val_precision: 0.4857 - val_recall: 0.4857\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 2s 62ms/step - loss: 0.3806 - accuracy: 0.8943 - precision: 0.8933 - recall: 0.8849 - val_loss: 1.4246 - val_accuracy: 0.5143 - val_precision: 0.5143 - val_recall: 0.5143\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3564 - accuracy: 0.9075 - precision: 0.9023 - recall: 0.9057 - val_loss: 1.3651 - val_accuracy: 0.5429 - val_precision: 0.5278 - val_recall: 0.5429\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 1s 137ms/step - loss: 0.3726 - accuracy: 0.8887 - precision: 0.8809 - recall: 0.8792 - val_loss: 1.5732 - val_accuracy: 0.4571 - val_precision: 0.4571 - val_recall: 0.4571\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3846 - accuracy: 0.8981 - precision: 0.8971 - recall: 0.8887 - val_loss: 1.4474 - val_accuracy: 0.5143 - val_precision: 0.5143 - val_recall: 0.5143\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 1s 145ms/step - loss: 0.3091 - accuracy: 0.9019 - precision: 0.9053 - recall: 0.9019 - val_loss: 1.8105 - val_accuracy: 0.4286 - val_precision: 0.4444 - val_recall: 0.4571\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.3493 - accuracy: 0.9000 - precision: 0.8933 - recall: 0.9000 - val_loss: 1.8929 - val_accuracy: 0.4286 - val_precision: 0.4286 - val_recall: 0.4286\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 1s 76ms/step - loss: 0.3460 - accuracy: 0.9132 - precision: 0.9079 - recall: 0.9113 - val_loss: 1.4899 - val_accuracy: 0.4857 - val_precision: 0.5000 - val_recall: 0.5143\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 1s 73ms/step - loss: 0.3139 - accuracy: 0.8981 - precision: 0.8972 - recall: 0.9057 - val_loss: 1.3826 - val_accuracy: 0.5429 - val_precision: 0.5405 - val_recall: 0.5714\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3149 - accuracy: 0.9094 - precision: 0.9091 - recall: 0.9057 - val_loss: 2.3431 - val_accuracy: 0.3429 - val_precision: 0.3611 - val_recall: 0.3714\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 36ms/step - loss: 0.3155 - accuracy: 0.9094 - precision: 0.9112 - recall: 0.9094 - val_loss: 1.4070 - val_accuracy: 0.5143 - val_precision: 0.5143 - val_recall: 0.5143\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3336 - accuracy: 0.9132 - precision: 0.9041 - recall: 0.9075 - val_loss: 2.2439 - val_accuracy: 0.3143 - val_precision: 0.3143 - val_recall: 0.3143\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 1s 62ms/step - loss: 0.3429 - accuracy: 0.8981 - precision: 0.8937 - recall: 0.9038 - val_loss: 1.5586 - val_accuracy: 0.5143 - val_precision: 0.5143 - val_recall: 0.5143\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3035 - accuracy: 0.9151 - precision: 0.9117 - recall: 0.9151 - val_loss: 1.5583 - val_accuracy: 0.5143 - val_precision: 0.5143 - val_recall: 0.5143\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3117 - accuracy: 0.9075 - precision: 0.9060 - recall: 0.9094 - val_loss: 1.8108 - val_accuracy: 0.4571 - val_precision: 0.4571 - val_recall: 0.4571\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2921 - accuracy: 0.9170 - precision: 0.9167 - recall: 0.9132 - val_loss: 1.4779 - val_accuracy: 0.5714 - val_precision: 0.5714 - val_recall: 0.5714\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.3184 - accuracy: 0.9075 - precision: 0.9075 - recall: 0.9075 - val_loss: 1.4132 - val_accuracy: 0.5714 - val_precision: 0.5714 - val_recall: 0.5714\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.3615 - accuracy: 0.8962 - precision: 0.9000 - recall: 0.9000 - val_loss: 1.5196 - val_accuracy: 0.5714 - val_precision: 0.5556 - val_recall: 0.5714\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 2s 165ms/step - loss: 0.2768 - accuracy: 0.9208 - precision: 0.9241 - recall: 0.9189 - val_loss: 1.5359 - val_accuracy: 0.5429 - val_precision: 0.5294 - val_recall: 0.5143\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.3048 - accuracy: 0.9283 - precision: 0.9215 - recall: 0.9302 - val_loss: 1.7034 - val_accuracy: 0.5143 - val_precision: 0.5278 - val_recall: 0.5429\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.2845 - accuracy: 0.9132 - precision: 0.9122 - recall: 0.9019 - val_loss: 1.6164 - val_accuracy: 0.5714 - val_precision: 0.5714 - val_recall: 0.5714\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2836 - accuracy: 0.9226 - precision: 0.9231 - recall: 0.9283 - val_loss: 1.8827 - val_accuracy: 0.4857 - val_precision: 0.4857 - val_recall: 0.4857\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2534 - accuracy: 0.9302 - precision: 0.9295 - recall: 0.9208 - val_loss: 1.9068 - val_accuracy: 0.5143 - val_precision: 0.5000 - val_recall: 0.5143\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.2936 - accuracy: 0.9264 - precision: 0.9229 - recall: 0.9264 - val_loss: 2.1073 - val_accuracy: 0.4286 - val_precision: 0.4286 - val_recall: 0.4286\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3113 - accuracy: 0.9057 - precision: 0.9009 - recall: 0.9094 - val_loss: 1.6506 - val_accuracy: 0.5143 - val_precision: 0.5000 - val_recall: 0.5143\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2961 - accuracy: 0.9302 - precision: 0.9279 - recall: 0.9226 - val_loss: 1.9836 - val_accuracy: 0.4571 - val_precision: 0.4571 - val_recall: 0.4571\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2524 - accuracy: 0.9189 - precision: 0.9208 - recall: 0.9208 - val_loss: 1.5728 - val_accuracy: 0.5143 - val_precision: 0.5278 - val_recall: 0.5429\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2825 - accuracy: 0.9075 - precision: 0.9168 - recall: 0.9151 - val_loss: 1.8622 - val_accuracy: 0.5143 - val_precision: 0.5143 - val_recall: 0.5143\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.2755 - accuracy: 0.9208 - precision: 0.9212 - recall: 0.9264 - val_loss: 1.5184 - val_accuracy: 0.5714 - val_precision: 0.5714 - val_recall: 0.5714\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2883 - accuracy: 0.9170 - precision: 0.9221 - recall: 0.9151 - val_loss: 2.1504 - val_accuracy: 0.4571 - val_precision: 0.4571 - val_recall: 0.4571\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2537 - accuracy: 0.9302 - precision: 0.9297 - recall: 0.9226 - val_loss: 1.7257 - val_accuracy: 0.5429 - val_precision: 0.5429 - val_recall: 0.5429\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.3223 - accuracy: 0.9151 - precision: 0.9091 - recall: 0.9057 - val_loss: 2.0204 - val_accuracy: 0.4571 - val_precision: 0.4571 - val_recall: 0.4571\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.2444 - accuracy: 0.9340 - precision: 0.9291 - recall: 0.9396 - val_loss: 2.2821 - val_accuracy: 0.4857 - val_precision: 0.4857 - val_recall: 0.4857\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.2934 - accuracy: 0.9113 - precision: 0.9110 - recall: 0.9075 - val_loss: 1.9897 - val_accuracy: 0.4857 - val_precision: 0.4857 - val_recall: 0.4857\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2177 - accuracy: 0.9377 - precision: 0.9358 - recall: 0.9358 - val_loss: 1.9662 - val_accuracy: 0.5429 - val_precision: 0.5294 - val_recall: 0.5143\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2918 - accuracy: 0.9170 - precision: 0.9173 - recall: 0.9208 - val_loss: 2.1670 - val_accuracy: 0.4857 - val_precision: 0.4857 - val_recall: 0.4857\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.2336 - accuracy: 0.9321 - precision: 0.9284 - recall: 0.9302 - val_loss: 2.6506 - val_accuracy: 0.4000 - val_precision: 0.4000 - val_recall: 0.4000\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.2564 - accuracy: 0.9208 - precision: 0.9212 - recall: 0.9264 - val_loss: 1.9068 - val_accuracy: 0.4857 - val_precision: 0.4857 - val_recall: 0.4857\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.2822 - accuracy: 0.9189 - precision: 0.9209 - recall: 0.9226 - val_loss: 2.2117 - val_accuracy: 0.4571 - val_precision: 0.4571 - val_recall: 0.4571\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2668 - accuracy: 0.9189 - precision: 0.9196 - recall: 0.9283 - val_loss: 2.2292 - val_accuracy: 0.4571 - val_precision: 0.4571 - val_recall: 0.4571\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2622 - accuracy: 0.9132 - precision: 0.9146 - recall: 0.9094 - val_loss: 1.4343 - val_accuracy: 0.5714 - val_precision: 0.5714 - val_recall: 0.5714\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2608 - accuracy: 0.9189 - precision: 0.9226 - recall: 0.9226 - val_loss: 1.7996 - val_accuracy: 0.5714 - val_precision: 0.5714 - val_recall: 0.5714\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2664 - accuracy: 0.9226 - precision: 0.9260 - recall: 0.9208 - val_loss: 1.9324 - val_accuracy: 0.5714 - val_precision: 0.5714 - val_recall: 0.5714\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.2287 - accuracy: 0.9396 - precision: 0.9361 - recall: 0.9396 - val_loss: 2.5549 - val_accuracy: 0.4286 - val_precision: 0.4286 - val_recall: 0.4286\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2236 - accuracy: 0.9358 - precision: 0.9342 - recall: 0.9377 - val_loss: 2.3778 - val_accuracy: 0.5143 - val_precision: 0.5143 - val_recall: 0.5143\n"
     ]
    }
   ],
   "source": [
    "# for smart_os, signals in SMARTWATCH_OS.items():\n",
    "train(\"E4\", SIGNALS, all_subjects_X, all_subjects_y, DataType.CGAN, num_epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_4_'></a>[Evaluation](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating every models on the corresponding test dataset not seen during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(os_scores_acc, os_scores_f1, smart_os, signals, all_subjects_X, all_subjects_y, data_type: DataType, num_epochs: int):\n",
    "\n",
    "    # all_subjects_X_os = filter_for_smartwatch_os(os, all_subjects_X)\n",
    "    subject_ids = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17]\n",
    "    \n",
    "    all_subjects_X_os =  all_subjects_X \n",
    "    all_accuracies = []\n",
    "    all_precisions = []\n",
    "    all_recalls = []\n",
    "    all_f1s = []\n",
    "\n",
    "    for i, subject_id in enumerate(subject_ids):\n",
    "        X_test = all_subjects_X_os[i]\n",
    "        y_test = all_subjects_y[i]\n",
    "        X_test = np.asarray(X_test)\n",
    "        y_test = np.asarray(y_test)\n",
    "        \n",
    "        y_test = tf.keras.utils.to_categorical(y_test, num_output_class)\n",
    "        \n",
    "        if data_type == DataType.REAL:\n",
    "            model_path = f\"models/stress_detector/real/{num_epochs}/wesad_s{subject_id}.h5\"  # Path to save the model file\n",
    "        if data_type == DataType.DGAN:\n",
    "            model_path = f\"models/stress_detector/syn/dgan_30000/{num_epochs}/wesad_s{subject_id}.h5\"\n",
    "        if data_type == DataType.CGAN:\n",
    "            model_path = f\"models/stress_detector/syn/cgan/{num_epochs}/wesad_s{subject_id}.h5\"\n",
    "\n",
    "        model = tf.keras.models.load_model(model_path)\n",
    "        accuracy = model.evaluate(X_test, y_test, verbose=0, )[1]\n",
    "        precision = model.evaluate(X_test, y_test, verbose=0, )[2]\n",
    "        recall = model.evaluate(X_test, y_test, verbose=0, )[3]\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "        all_accuracies.append(accuracy)\n",
    "        all_precisions.append(precision)\n",
    "        all_recalls.append(recall)\n",
    "        all_f1s.append(f1)\n",
    "\n",
    "    print(f'Smartwatch OS: {smart_os}')\n",
    "    print(f'Evaluation of CNN model trained on {num_epochs} epochs\\n')\n",
    "    print(f'Subject\\t\\t Accuracy\\tPrecision\\tRecall\\t\\tF1-Score')\n",
    "    print(\"************************************************************************\")\n",
    "    for i in range(len(all_accuracies)):\n",
    "        print(f'S{subject_ids[i]}\\t\\t {round(all_accuracies[i], 5):.5f}\\t{round(all_precisions[i], 5):.5f}\\t\\t{round(all_recalls[i], 5):.5f}\\t\\t{round(all_f1s[i], 5):.5f}')\n",
    "\n",
    "    print(\"************************************************************************\")\n",
    "    print(f'Average\\t\\t {round(np.mean(all_accuracies), 5):.5f}\\t{round(np.mean(all_precisions), 5):.5f}\\t\\t{round(np.mean(all_recalls), 5):.5f}\\t\\t{round(np.mean(all_f1s), 5):.5f}\\n\\n\\n')\n",
    "\n",
    "    os_scores_acc[smart_os] = all_accuracies\n",
    "    os_scores_f1[smart_os] = all_f1s\n",
    "\n",
    "    return os_scores_acc, os_scores_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 21:40:04.600036: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 21:40:16.749786: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 21:40:26.252977: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 21:40:37.419181: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 21:40:49.903360: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 21:41:02.152385: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 21:41:14.123757: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 21:41:25.994831: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 21:41:39.138128: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 21:41:50.823365: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 21:42:02.271221: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 21:42:11.861606: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 21:42:23.549609: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 21:42:36.380309: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 21:42:47.789767: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smartwatch OS: E4\n",
      "Evaluation of CNN model trained on 100 epochs\n",
      "\n",
      "Subject\t\t Accuracy\tPrecision\tRecall\t\tF1-Score\n",
      "************************************************************************\n",
      "S2\t\t 0.97059\t0.97059\t\t0.97059\t\t0.97059\n",
      "S3\t\t 0.82353\t0.81818\t\t0.79412\t\t0.80597\n",
      "S4\t\t 0.97143\t0.97143\t\t0.97143\t\t0.97143\n",
      "S5\t\t 1.00000\t1.00000\t\t1.00000\t\t1.00000\n",
      "S6\t\t 0.94286\t0.94286\t\t0.94286\t\t0.94286\n",
      "S7\t\t 0.94286\t0.94286\t\t0.94286\t\t0.94286\n",
      "S8\t\t 0.94286\t0.97059\t\t0.94286\t\t0.95652\n",
      "S9\t\t 1.00000\t1.00000\t\t1.00000\t\t1.00000\n",
      "S10\t\t 0.97222\t0.97143\t\t0.94444\t\t0.95775\n",
      "S11\t\t 0.80556\t0.80000\t\t0.77778\t\t0.78873\n",
      "S13\t\t 0.97222\t0.97222\t\t0.97222\t\t0.97222\n",
      "S14\t\t 0.27778\t0.27778\t\t0.27778\t\t0.27778\n",
      "S15\t\t 0.97222\t0.97222\t\t0.97222\t\t0.97222\n",
      "S16\t\t 1.00000\t1.00000\t\t1.00000\t\t1.00000\n",
      "S17\t\t 0.66667\t0.66667\t\t0.66667\t\t0.66667\n",
      "************************************************************************\n",
      "Average\t\t 0.88405\t0.88512\t\t0.87839\t\t0.88171\n",
      "\n",
      "\n",
      "\n",
      "E4_DGAN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 21:42:59.262457: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 21:43:10.219932: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 21:43:19.538938: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 21:43:30.110236: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 21:43:41.188673: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 21:43:54.449773: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 21:44:06.003341: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 21:44:17.178304: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 21:44:29.324538: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 21:44:40.387677: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 21:44:52.147906: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 21:45:05.373498: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 21:45:18.142706: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 21:45:30.096985: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 21:45:43.385455: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smartwatch OS: E4_DGAN\n",
      "Evaluation of CNN model trained on 100 epochs\n",
      "\n",
      "Subject\t\t Accuracy\tPrecision\tRecall\t\tF1-Score\n",
      "************************************************************************\n",
      "S2\t\t 0.97059\t0.97059\t\t0.97059\t\t0.97059\n",
      "S3\t\t 0.79412\t0.81818\t\t0.79412\t\t0.80597\n",
      "S4\t\t 0.97143\t0.97143\t\t0.97143\t\t0.97143\n",
      "S5\t\t 1.00000\t1.00000\t\t1.00000\t\t1.00000\n",
      "S6\t\t 0.97143\t0.97143\t\t0.97143\t\t0.97143\n",
      "S7\t\t 0.94286\t0.94286\t\t0.94286\t\t0.94286\n",
      "S8\t\t 1.00000\t1.00000\t\t0.94286\t\t0.97059\n",
      "S9\t\t 1.00000\t1.00000\t\t1.00000\t\t1.00000\n",
      "S10\t\t 0.97222\t0.97222\t\t0.97222\t\t0.97222\n",
      "S11\t\t 0.83333\t0.81081\t\t0.83333\t\t0.82192\n",
      "S13\t\t 1.00000\t1.00000\t\t1.00000\t\t1.00000\n",
      "S14\t\t 0.66667\t0.66667\t\t0.66667\t\t0.66667\n",
      "S15\t\t 0.97222\t0.97222\t\t0.97222\t\t0.97222\n",
      "S16\t\t 0.97222\t0.97222\t\t0.97222\t\t0.97222\n",
      "S17\t\t 0.63889\t0.64865\t\t0.66667\t\t0.65753\n",
      "************************************************************************\n",
      "Average\t\t 0.91373\t0.91449\t\t0.91177\t\t0.91304\n",
      "\n",
      "\n",
      "\n",
      "E4_CGAN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 21:46:00.195444: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 21:46:13.159648: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 21:46:25.054651: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 21:46:35.761664: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 21:46:47.975016: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 21:46:58.548035: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 21:47:11.503751: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 21:47:22.989322: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 21:47:36.063313: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 21:47:47.502864: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 21:47:59.812566: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 21:48:14.014498: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 21:48:27.296708: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 21:48:38.051988: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 21:48:49.734993: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smartwatch OS: E4_CGAN\n",
      "Evaluation of CNN model trained on 100 epochs\n",
      "\n",
      "Subject\t\t Accuracy\tPrecision\tRecall\t\tF1-Score\n",
      "************************************************************************\n",
      "S2\t\t 0.88235\t0.88235\t\t0.88235\t\t0.88235\n",
      "S3\t\t 0.85294\t0.85294\t\t0.85294\t\t0.85294\n",
      "S4\t\t 1.00000\t1.00000\t\t1.00000\t\t1.00000\n",
      "S5\t\t 1.00000\t1.00000\t\t0.97143\t\t0.98551\n",
      "S6\t\t 0.94286\t0.94286\t\t0.94286\t\t0.94286\n",
      "S7\t\t 0.94286\t0.94286\t\t0.94286\t\t0.94286\n",
      "S8\t\t 1.00000\t1.00000\t\t1.00000\t\t1.00000\n",
      "S9\t\t 0.97143\t0.97143\t\t0.97143\t\t0.97143\n",
      "S10\t\t 0.97222\t0.97059\t\t0.91667\t\t0.94286\n",
      "S11\t\t 0.83333\t0.83333\t\t0.83333\t\t0.83333\n",
      "S13\t\t 1.00000\t1.00000\t\t1.00000\t\t1.00000\n",
      "S14\t\t 0.05556\t0.05556\t\t0.05556\t\t0.05556\n",
      "S15\t\t 0.97222\t0.97222\t\t0.97222\t\t0.97222\n",
      "S16\t\t 0.94444\t0.94444\t\t0.94444\t\t0.94444\n",
      "S17\t\t 0.75000\t0.73684\t\t0.77778\t\t0.75676\n",
      "************************************************************************\n",
      "Average\t\t 0.87468\t0.87369\t\t0.87092\t\t0.87221\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "# Evaluating every models on the corresponding test dataset not seen during training.\n",
    "os_scores_acc = {}\n",
    "os_scores_f1 = {}\n",
    "\n",
    "for smart_os, signals in SMARTWATCH_OS.items():\n",
    "    \n",
    "    if  smart_os == \"E4_CGAN\":\n",
    "        print(smart_os)\n",
    "        evaluate(os_scores_acc, os_scores_f1, smart_os, signals, all_subjects_X, all_subjects_y, DataType.CGAN, num_epochs=num_epochs)\n",
    "    if  smart_os == \"E4_DGAN\":\n",
    "        print(smart_os)\n",
    "        evaluate(os_scores_acc, os_scores_f1, smart_os, signals, all_subjects_X, all_subjects_y, DataType.DGAN, num_epochs=num_epochs)\n",
    "    if smart_os == \"E4\":\n",
    "        print(\"E4\")\n",
    "        evaluate(os_scores_acc, os_scores_f1, smart_os, signals, all_subjects_X, all_subjects_y, DataType.REAL, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_os_scores_acc = pd.DataFrame(os_scores_acc)\n",
    "replacements = {l1:f'S{l2}' for l1, l2 in zip(groups_set, subject_ids)}\n",
    "df_os_scores_acc = df_os_scores_acc.rename(replacements)\n",
    "df_os_scores_acc.to_csv('os_scores_acc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_os_scores_f1 = pd.DataFrame(os_scores_f1)\n",
    "replacements = {l1:f'S{l2}' for l1, l2 in zip(groups_set, subject_ids)}\n",
    "df_os_scores_f1 = df_os_scores_f1.rename(replacements)\n",
    "df_os_scores_f1.to_csv('os_scores_f1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: title={'center': 'Accuracy of different os models on each subject'}>"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_os_scores_acc.plot.bar(figsize=(20,10), title='Accuracy of different os models on each subject')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: title={'center': 'F1-Score of different os models on each subject'}>"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABkEAAANOCAYAAACm/KtOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAABlRklEQVR4nOz9e5zXc/74/9+nmkPpqNLJqJUUyikr7EEpIrRFTnnT4bs2S07ZRWvJLnJYu8S2rEOptMtqtcqZZK11SO91iPVejEYRUVQOTaWevz/8ms+OmWqmhpkertfL5Xm5eD1fj+fz+Xi9nq8Jc+v5euZkWZYFAAAAAABAYurU9AQAAAAAAAC+DiIIAAAAAACQJBEEAAAAAABIkggCAAAAAAAkSQQBAAAAAACSJIIAAAAAAABJEkEAAAAAAIAkiSAAAAAAAECSRBAAAAAAACBJIggAQOI+/PDDeP/992t6GluViy++OLbffvsoKCiIXXbZJdatW1el7XNycmLo0KGbHLdgwYLo169fNGnSJJo2bRoXXXTRRtdTO/Xs2TM6dOhQ5e2GDh0aOTk51T+hBDzxxBORk5MTt99+e01PZbPPLwAAtYMIAgCwFbnkkksiJyenwmXu3Lml45566qkYOXJkdO3aNVq1ahUPPfTQZh8zy7IYP358dO3aNerXrx/NmzeP/fbbL6ZNm1YdL6nW+etf/xqXXnppnHLKKfHYY4/Fz372sy3eZ3FxceTk5MQll1xSZv3pp58ec+fOjT//+c8xbdq0+P73v7/R9UDtVtkACgDAN6deTU8AAICqmzx5cuyyyy5l1u26666l/zxz5sz46KOPonfv3vHqq69u0bEuv/zyuOiii+Lss8+O8ePHx5IlS2LWrFmxcOHCLdpvbfXUU09FRMT5558fBQUF1RIg2rZtG88//3y0bdu23LH69u0b/fr1q9T62uTee++NiRMnxh//+Mdo1apVTU8HaoXnn38+WrRoUe37ffrpp+O3v/1tXHzxxbHHHntU+/4BAFImggAAbIV22WWX2GeffTb4/FVXXRURX36lzPXXX79Fx7rpppuiR48ece2115auO/roo7don1W1cuXKqF+//jdyrI8//jgiIgoKCqptn3l5eRWer2XLllV4nA2t3xyff/55NGjQoFr29d9eeOGFuPfee+O6666r9n3D1mpjfy5viddffz3uueeeOOOMM76W/QMApMzXYQEAsFGrVq2KBQsWxIoVKzY6rqioKE488cRo1apV5ObmRsuWLeO0004rfT7Lsrjhhhtit912i/z8/GjZsmUMHjw4iouLy+xn/Vd+/etf/4rjjz8+GjVqFHfddVfp81OmTIldd9016tevH127do3JkydX6nW8//77MXz48GjVqlXk5+dH586d44orroi1a9eWjunQoUNMmjQpIqL0a8a+Or+vuuGGG6Jjx45RUFAQ++yzTzz++OPlxnz167DW3+8gImLSpEmRk5MTPXv23OD69V5//fU44ogjYptttol27drFT37yk3LnZf3X8dx1113RuXPn6NatW+lz7733XgwePDiaNGkSLVu2jGOPPbbc/WI6dOgQPXv2LD1Wo0aNon379jFlypTSMUOHDo1f/epXERHxne98J3JycuKmm27a6PtUmfc/ImLevHlx8MEHR5MmTWKbbbaJrl27bvKz99/v7/Tp02P33XeP+vXrxwEHHBBvvfVWvP3223HkkUdGw4YNo0OHDmU+T+v9+c9/ju7du0f9+vWjadOm0b9//3j55ZfLjZs1a1bss88+UVBQEDvuuGPccMMNFc5pzZo18Ytf/CLatWsXjRo1ih/84Afx/PPPb/R1RHx5P5iBAwdG8+bNo6CgIDp37hz/+c9/NrndJ598EmeffXYUFhZGXl5edOjQIc4777z4/PPPy4xbf3+L9957L0488cRo2rRptG7dOq6++upNHiOicp+hm2++OX74wx9GixYtolGjRnHggQfGK6+8Um5fN910U+y1115Rv379aNCgQXTu3DleeumlcuMmT54cu+22WzRo0CAOPPDAKCoq2uQ8P/744xg6dGi0atUq8vLyYscdd4wnnnii9PkN3XNkY/dpefXVV+Oggw6KbbbZJlq3bh2/+MUvyn1+K/o6rMq8Z2vWrImxY8fGLrvsEvn5+dGwYcPo1q1bLF68OC655JIYNmxYRET06tUrcnJy4oILLtjkewAAwJdEEAAANur000+P9957L3r06BF///vfKxxTVFQU++67b8yYMSPOP//8ePzxx+Pmm2+O7373u6VjRo0aFWeddVb069cvHnzwwbj22mvj2Wefjf322y8WLVpUbp8nnXRStG3bNu67777o3bt3RHz5y9Wf/vSnceaZZ8YjjzwSAwcOjCFDhsSDDz640dfw8ccfxwEHHBAPP/xwXHnllfHQQw/FcccdFxdffHGZX1jOnDkzjjjiiIj48mttKvoKq//229/+Ns4888w49NBD48EHH4yf/vSnZcLPhnTv3r30F+JHHHFEPP/88/HHP/5xg+sjIhYtWhTf//73o3nz5nH//ffH7373u7j//vvjlFNOKbf/Z599Nn71q1/FpZdeWhqJPv300+jZs2csW7Ys7rnnnpgwYUK88sorMXDgwHLbv/POO9GrV6/o0aNH3HfffdGlS5cYPnx4zJ8/PyK+DFXrjztjxox4/vnnN3p1UGXf/yzL4vDDD49Vq1bF9OnTY8aMGTFkyJCoW7fuJt/TiIgHHnggzj///Ljwwgvj9ttvj7lz58bgwYPj4IMPju7du8d9990Xbdq0iWHDhpVe8RMRMW7cuBg8eHDsscceMWPGjLjtttvinXfeiQMOOKBMCHn22WfjsMMOiyZNmsQ999wTv/vd7+Kvf/1rPP300+XmMnTo0Jg2bVpcf/31MWPGjGjevHn07t07Pvjgg42+hhNPPDFef/31mDp1ajz88MMxcuTITV7Js3r16ujTp09MnDgxzjvvvHjkkUfijDPOiD/84Q9x+OGHl/tF/aeffho//OEPo1WrVvG3v/0tDjnkkDj//PPjH//4x0aPU9nP0IIFC+LHP/5xTJ8+PaZOnRpvvvlm/OQnPykz5uyzz46f/vSn0apVq7jrrrvigQceiDPPPDO22WabMuNuvPHGuOKKK+Kiiy6KO++8M1588cVy+6rI+j8j/vjHP8asWbNi9OjRse22225yuw355JNP4phjjokBAwbE/fffH8cee2xcccUVm4xHlX3PjjnmmLjwwgtj7733jnvvvTf+9re/xdChQyM3Nzd+8pOfxJgxYyLiy3D0/PPPuyIEAKAqMgAAthpjxozJIqLccuONN1Y4fvbs2VlEZBMnTtyi41522WVZXl5eFhHZwIEDs4ULF5Z5fvDgwVlEZPfdd1+F27/xxhtZTk5ONnz48DLrX3nllSwnJyf76U9/Wu41XnLJJWXGlpSUZM2bN88uuOCCMut33XXX7Mgjj9zo/C+66KIsIrInn3yyzPrzzjsvi4jsueeeK103ZMiQrDL/mfzZZ59ljRs3zg466KAy65cvX55FRDZkyJDSdfPnz88iIhszZkyZsV8dt7H1p59+eta2bdts7dq1peuuvvrqLCKyJUuWlNl2u+22yxYvXlxm+9/85jdZbm5utmLFitJ1f/nLX7KIyP73f/+3dF379u2zOnXqZA888EDpunvvvTeLiOyuu+4qXbf+PM2fP7/c/L+qsu//hx9+mEVEdsUVV2xyn/9t/fvbqVOn7MMPPyxd36NHj6xOnTrZ9OnTS9fddNNNWURkTz/9dJZlX56vbbbZptx5/PDDD7MGDRpkhx12WOm63r17Z40bN84+/fTT0nXr1q3LunfvnrVv37503dy5c7OIyB566KHSdR988EEWEdlvf/vb0nUVfda22WabbMSIEVV6/bfddlsWEdnkyZPLrP/DH/5Q7rwdeOCBWURkN910U+m6l156KYuI7KqrrtrocSr7Gfqqk08+OSsoKCh9/J///CfLycnJ9t1332zdunUVbrP+z64uXbpkH3/8cen6gQMHZvXr19/oPLMsy3bbbbesb9++G3x+Q382VnRODjzwwKxhw4bZG2+8UWb93nvvnW277bZlXsNXf3Yr85498sgjWURkgwYN2uB8J06cmEVENnv27A2OAQCgYq4EAQDYCk2dOjVeeOGF0uWYY46p8j6yLIsvvviiwuWrf3P8wgsvjHnz5sWRRx4Z06dPj912263MV8s89thj0a5duzj88MMrPNasWbMiy7Lo379/mfW77bZb7LjjjvHoo4+W22bIkCFlHr/wwguxdOnSuPLKK0u/qionJyf+/e9/b/LrcR599NFo2rRp/OAHPyiz/sgjjyx9vqqee+65WLFiRemVI+s1bty4yvuqjMceeywWLVoUdevWLX3t5513XkREvPXWW2XGHnbYYbHddtuV237NmjXRuHHj0u2PPfbYiIhy79/3vve9OOyww0ofr39NX/1qpcqq7PvfokWLOOCAA2LMmDFx9tlnl155UlmDBw8uc1PqgoKCKCwsjAEDBpSuy8/Pj4gvv+YtIuKZZ56Jzz77rNxns0WLFrH//vvH448/HuvWrYtVq1bFk08+GT179ixztUJOTk40bNiw3OuNiDj00ENL3+v152NTn9Uf/ehHcfPNN8fQoUNj3rx5lXrd64/31dewoc93YWFhjBgxovRxZc9vZT9DxcXFMWLEiNhxxx0jPz8/Jk+eHCUlJaXPr//z4JRTTtngV0+t9/Of/zyaNm1aZq4rV67c6DYRX76PDz/8cPzoRz+Kf/7zn5scvynNmzePnXbaqcy6/fffPz766KMKr2RbrzLv2WOPPRYRUeacAABQfdwYHQBgK7TzzjvHnnvuuUX7mDRpUun3zH9V+/bty90LY+edd44ZM2bE9OnT43/+53/i2GOPjeLi4mjQoEF89NFH0b179w0ea8mSJRER0bJly3LPtWzZMv7v//5vk/NdunRpRERcdNFFcdRRR5V5Li8vb6PbLlmyZIPH/u/5VcV7770XERGtWrWq8rabY+nSpbHHHnuUu4dBRJT75eyGtm/ZsmU88sgj5Z7bYYcdyjyuU6d6/65UVd7/+++/P84777y48cYbY/z48XHKKafEtddeWxovqtumPpurVq2KTz75JD777LNYs2ZNpc73+s/qvffeW+693dRXMk2YMCEKCwtj/PjxMXny5Bg0aFDcfPPNZUJARa8hNzc3mjRpUm7+//0a19vc81uZz9DChQtjn332ibp168YFF1wQ3/3ud+Pqq6+OmTNnlo796KOPIiJi++233+QxN3eul112WTRt2jSuuuqq+P73vx8HHXRQTJo0qVLHrKxGjRpFxJfvS7t27SocU5n3rCrvBwAAVSeCAAB8S/Xv3z9eeOGFCp/bWFQYOHBgjBgxIq699tr497//Hfvss0+0bt063nnnnQ1us/5v51cUGz744IMKfwH9Vet/+bxkyZIqB6AWLVpUeHPp9fdnqMzxv2r9L7M//fTTKm+7OVq1ahVvvfVWdO3aNerVq/p/xrdq1Srmzp0bbdu2LXeVyNetKu9/06ZN4+abb47LL788xowZEzfeeGM0b948Lr300q9tbhEb/mwWFBREo0aNSn8mKnO+139WS0pKqvxZzc/PjyuvvDIuvPDCuPbaa2PMmDGRn59f5sb0Fb2GNWvWxIoVK8pcibQln++KVOYzdMstt8TSpUvjqaeeiu9973sREXHrrbeWGdO6deuI+DKYfF1ycnLi5z//eZxxxhkxYcKEGDVqVJxwwgmbvO/Jf1+xsimLFy+OiNjofYMq85799/vRpUuXSh8fAIDK8XVYAADfUttuu23sueeeFS677rprRHz5lVlZlpXbdv3X0az/BXL//v3j3XffLfO3vf/bQQcdFDk5OeWenzdvXrz11lvRp0+fTc53r732isLCwrjjjjtKf/lYWX369ImPP/643Nfi3HvvvaXPV9Wuu+4aderUKXdT7Oeee67K+6qM/v37xyeffBI333zzZm8fEXHNNddUy3wKCgoiImLFihWbHLs573/Lli3jD3/4QzRr1ixeeumlaphxxfbff//YZpttyn02P/zww3jmmWeiV69eUadOnahfv3507Ngxnn322TI/Ex9++GG5ryM74ogjIicnJ6699tpYt27dZs2rUaNGcfHFF8eee+65yde//v376mvYks93RSrzGVp/VUO3bt1K162/Cf369+LQQw+N3NzcuPnmmzf7/amsgoKCOO200+Kwww4r8z6uv9n8+qt2IiLuu+++mDZtWoX7WbVqVaxevbr08dq1a+ORRx6JPffcs8xXsH1VZd6z9V9bdtNNN230dURU7ucNAICyXAkCAJCg4uLiWLJkSenfvi8uLo65c+dGo0aNonPnzpXez/Lly2P33XePE044IXr06BEtWrSIv//973HLLbfE4MGDo0OHDhERcfHFF8eMGTPihBNOiDFjxkSPHj1i8eLF8X//939x0UUXRadOnWLkyJExfvz4aN68efTt2zfefffduOiii2K77baLCy+8cJNzqVu3btx4440xYMCAOOCAA+Liiy+OHXfcMd5888146aWX4rrrrtvgtuecc05MmTIljjvuuBg7dmwUFhbGrFmz4rrrrovBgwfHvvvuW+n3ZL0ddtghjj322Jg6dWrssssusf/++8cTTzwRM2bMqPK+KuP888+P6dOnx9lnnx2LFi2Kgw46KD777LOYNWtWnHLKKbHbbrttdPthw4bF1KlT45prronPPvssfvSjH8W6deviH//4R/Tu3TsOOuigKs1nn332iYgvz/2oUaNip5122uDfiK/s+//qq6/GL3/5yzjqqKOiQ4cO8cgjj8THH39c5v4k1a1x48bx61//Os4999w45ZRT4rjjjotly5bFZZddFjk5OTF27NjSsT//+c/j1FNPjeHDh8eQIUOiqKgorrnmmnJf2dSlS5e44IIL4oorroi+ffvGaaedFk2bNo0XXngh8vLyYuTIkRXOZfny5XH00UfH8ccfHzvvvHO88MILMW/evDj33HM3+hpOOumkuPHGG+P000+PFStWxK677hrPP/98jBkzJn7wgx/E0UcfveVvVFTuM3TggQfG+PHj45xzzomTTz45Jk2aFM8880xEfHlFyEknnRTt2rWLSy65JC688MLo27dvjBw5Mho1ahRz586NAw88MHr06LHFc+3bt28ceeSR0bVr13j77bfjsccei379+pU+v8suu0STJk3i97//feTn58crr7wS06dPj/333z+eeuqpcvtbunRp7L///nH++edHs2bNYvz48fHee++Vu8plc96zfffdN0455ZS45ZZb4vjjj4+hQ4dGnTp14p///GcMGTIkdtxxx9h7772jTp06ceWVV0bjxo1jhx12iB133HGL3ycAgG+FmrwrOwAAVTNmzJgsIrLnn39+o+OGDBmSRUS55cADD6zS8VauXJkNGTIk23XXXbNtttkma9KkSda9e/fsxhtvzNasWVNm7MKFC7PBgwdnzZo1ywoKCrJOnTpl559/funz69aty373u99lnTt3znJzc7PmzZtnxx9/fPbWW29V+Brnz59f4Zyeeuqp7JBDDskaNWqUNWjQINt1112zX/ziF5t8Le+++2528sknZy1atMhyc3OznXfeObv88svLvY71711lLF++PBsyZEjWpEmTrGHDhtmAAQOyhQsXZhGRDRkypHTc/Pnzs4jIxowZU2b7r47b1PqlS5dmI0eOzNq1a5fl5uZmbdu2zfr375+9/fbbm9w2y7Ls888/zy688MJsxx13zHJzc7PtttsuO+SQQ7J//etfpWPat29f7nMye/bsLCKyiRMnllk/ZsyYbLvttsuaNWuWzZw5s8JjrleZ9/+9997LBg0alG2//fZZfn5+tvPOO2fXXnvtRvebZRt+fw888MCsffv2ZdZNnDgxi4hs9uzZZdZPnjw522OPPbK8vLysSZMm2RFHHJG98MILZcasW7cuu+yyy7J27dpl+fn5WY8ePbInn3yywuOsP9Zee+2V5efnZ02aNMl69OiR/elPfyp9/quftZKSkux//ud/sg4dOmT5+flZ+/bts1/+8pfZ6tWrN/keLFu2LBs5cmTWpk2brF69eln79u2zn/3sZ9mnn366yfdkQ+9fRSrzGbrwwguzFi1aZK1bt85++ctfZosXL866du2aNWnSJJs3b17puAkTJmS77bZb6Z8HBx54YPbiiy9mWbbhz1xlfz7POOOMbOedd84KCgqytm3bZqeffnq2fPnyMmMeeOCBbOedd87q16+f9enTJ/v3v/9d4f4PPPDA7Ic//GH25z//OevcuXOWl5eX7bbbbtn06dPLjFu3bl0WEdnw4cOr/J6tXbs2u/rqq7OOHTtmubm5WatWrbK+fftmCxcuLB1z0003ZYWFhVmjRo2ym266aZPvAQAAX8rJsgq+3wAAAACotGXLlkWzZs3iwgsvjMsuu6ympwMAwP+fr8MCAACAzfDxxx/H7bffHj169Ij77rsvIr78Ki4AAGoPV4IAAADAZlh/z5qXX345WrVqFWeddVacffbZNT0tAAD+iwgCAAAAAAAkqU5NTwAAAAAAAODrIIIAAAAAAABJEkEAAAAAAIAk1avpCVTGunXrYtGiRdGoUaPIycmp6ekAAAAAAAA1KMuy+OSTT6Jt27ZRp86Gr/fYKiLIokWLorCwsKanAQAAAAAA1CILFy6M7bfffoPPbxURpFGjRhHx5Ytp3LhxDc8GAAAAAACoSStWrIjCwsLSfrAhW0UEWf8VWI0bNxZBAAAAAACAiIhN3kLDjdEBAAAAAIAkiSAAAAAAAECSRBAAAAAAACBJW8U9QQAAAAAAYHOsXbs21qxZU9PToIpyc3Ojbt26W7wfEQQAAAAAgORkWRbvv/9+LFu2rKanwmZq2rRptG7depM3P98YEQQAAAAAgOSsDyDbbbddNGjQYIt+kc43K8uy+Pzzz+ODDz6IiIg2bdps9r5EEAAAAAAAkrJ27drSANK8efOang6boX79+hER8cEHH8R222232V+N5cboAAAAAAAkZf09QBo0aFDDM2FLrD9/W3JPFxEEAAAAAIAk+QqsrVt1nD8RBAAAAAAASJIIAgAAAAAAtUTPnj0jJyenzNKlS5dy48466yxXulSCG6MDAAAAAPCt0eGC+7+xYxVfefhmbde/f/+YNGlS6eOv3hR8zpw5MX78+C2a27eFK0EAAAAAAKAWyc3NjaZNm5YujRo1Kn3uiy++iFNOOSWGDx9egzPceoggAAAAAACwlbjmmmsiJycnzjvvvJqeylbB12EBAAAAAMBWoKioKMaOHRuzZ8+OevX8er8yXAkCAAAAAAC1yIwZM8p8HdZrr70WERGnnnpqnHrqqdG9e/canuHWQyoCAAAAAIBapE+fPvGHP/yh9HG7du1i8uTJUVxcHDNmzKjBmW19RBAAAAAAAKhFGjRoEB06dCizbuLEiVFUVFTmJukREfXq1YsJEybEySef/A3OcOshggAAAAAAQC03YcKE+Oyzz0ofP//88zF8+PB48cUXY/vtt6/BmdVuIggAAAAAANQia9asiWXLlpVZ1759+6hT5//d5nvJkiUREdG1a9dvcmpbHREEAAAAAABqkRkzZkSzZs3KrHvjjTdip512qqEZbb1EEAAAAAAAvjWKrzy8pqewUU888USlxvXs2TOyLPt6J5OAOpseAgAAAAAAsPURQQAAAAAAgCSJIAAAAAAAQJJEEAAAAAAAIEkiCAAAAAAAkCQRBAAAAAAASJIIAgAAAAAAJKnKEaSoqCj++Mc/xnHHHRc33HDDJsfPnz8/+vTpE/Xr14+uXbvGrFmzNmuiAAAAAAAAVVHlCHL00UfHww8/HDNnzoylS5dudOwXX3wRhx56aOy8885RVFQUo0aNih/96EdRVFS02RMGAAAAAACojCpHkBdeeCHuueeeaNCgwSbH3nvvvbF06dK47rrrom3btjF8+PDo1atXpa4gAQAAAACAb5uePXtGTk5OmaVLly7lxp111lmRk5NT6f3efvvtZfbZoEGD6Ny5c1xwwQXxySeflBv/6quvxvHHHx+tW7eOvLy8aNGiRey3334xceLEcmPnzJkTOTk5ce6555Z77oknnoicnJy4+uqryz3XoUOHuP322yv9GjZHvapuUJU3ddq0aXHAAQdEXl5e6bqePXvG7373u7juuuuqemgAAAAAANgylzT5Bo+1fLM269+/f0yaNKn0cd26dcs8P2fOnBg/fvxm7fudd96J/Pz8+Oijj+Lxxx+PCy+8MGbPnh1PPvlk5OfnR0TEU089FX379o1DDjkk7rvvvth+++1jwYIF8fjjj8fHH39cbp9TpkyJiIg777wzfvOb30SdOuWvv7jsssvi5JNPjtatW2/WvDdXlSNIVSxYsCD23HPPMusKCwvjvffeizVr1kRubm6F261atSpWrVpV+njFihVf5zQBAAAAAKDWyM3NjaZNm1b43BdffBGnnHJKDB8+PG655ZYq77tJkybRsGHDaNGiRey8886x0047xcEHHxzjx4+PUaNGxbp162Lo0KGx++67x1//+tfSoNG6devYd999y+1vzZo1ceedd0afPn3isccei9mzZ0fv3r0rfE0XXHDB137lx1d9rRFkyZIlUVBQUGZdQUFBZFkWS5cu3WDxueKKK+JXv/rV1zk1IFHdJnXb4n3MGzKvGmZSe3S44P4t3kdxweAtn8hm/s0HgNrKv3PK8+8cgApUw9827vadHaphIun9eweoumr577UrD6+GmbAlrrnmmsjJyYnzzjtvsyLIV/Xp0ye6d+8ed955Z4waNSqeeuqpKCoqimuuuabCKzq+6qGHHoply5bFhAkTYrfddos77rijwgjy61//Os4444w47bTTKowpX5cq3xOkKlq2bBklJSVl1q1cuTJycnKiefPmG9xu9OjRsXz58tJl4cKFX+c0AQAAAACg1isqKoqxY8fGbbfdFvXqVd81DnvuuWe89tprERHx4osvRkTE3nvvXalt77jjjjj44IOjsLAwBg4cGPfcc0+5LhARceqpp0bXrl3jjDPOiCzLqm3um/K1RpD27dvHO++8U2bdggULok2bNhv8KqyIiPz8/GjcuHGZBQAAAAAAvg1mzJgRTZs2LV3WB4pTTz01Tj311OjevXu1Hq9Fixalt6hYf3uKVq1abXK75cuXx4wZM+KEE06IiIgTTjghVqxYETNnziw3tm7dujFu3LiYM2dOmfudfN2+1ggyaNCg+Oc//xmrV68uXff444/HoEGDvs7DAgAAAADAVqtPnz7x4osvli477bRTTJ48OYqLi7+WW0m899570aJFi4iIaNSoUUREvP/+++XGDRs2LC699NLSx9OmTYucnJwYOHBg6bxbtGgRU6dOrfA4vXr1ikGDBsXo0aPjk08+qe6XUaEqR5AVK1bEsmXLIsuyKCkpiWXLlpVe2nLyySeX+a6vI488Mlq0aBHnnntuvPfee3HLLbfEk08+GWeccUb1vQIAAAAAAEhIgwYNokOHDqVLbm5uTJw4MYqKiqJRo0ZRr1692GmnnSIiol69ejF58uQtOt6//vWv+O53vxsREd26fXn/w7lz55YbN2/evCgqKip9PGXKlCgpKYkWLVpEQUFBNGzYMJYuXRoPPvhgfPTRRxUe65prronly5eXiSlfpypHkN133z2aNWsWH330UVx11VXRrFmzuPLKKyPiy6+6+u83oF69evHAAw/EK6+8Et/5znfi+uuvj3vvvbf05AAAAAAAAJs2YcKEePnll0uvDll/U/QXX3wx+vfvv9n7ffjhh+OVV16J/+//+/8iIuKHP/xhbL/99nH55ZfH2rVrN7jdggUL4sknn4yJEyeWuWplxowZsXr16rj77rsr3K59+/bx85//PMaNGxdLly7d7HlXVpXvnFJcXLzB55544oly63bccceYPXt2VQ8DAAAAAADfSmvWrIlly5aVWde+ffuoU+f/XdewZMmSiIjo2rVrlfa9fPny+OKLL2LFihXx2GOPxfnnnx/Dhg0rDSn16tWLW2+9Nfr37x+HHnpoXHzxxdGlS5f48MMPY/ny5aX7mTp1amy//fZx0kknlZlXly5dolu3bjF16tQYMWJEhXM4//zzY+LEibFw4cIqzX1zVN/t4wEAAAAAoLa7ZPmmx9SwGTNmRLNmzcqse+ONN6rlW5a23377iPjyK7d22223uPzyy+OUU04pM6Zv377x9NNPx9ixY+Ooo46K5cuXx7bbbhu77rpr9O3bNyIi7rjjjhg2bFiZALLesGHD4txzz4233367wjk0aNAgfvOb38Txxx+/xa9nU0QQAAAAAACoJSr6xqWK9OzZM7Isq/R+hw4dGkOHDq30+O7du8df//rXDT7/6quvbvC5c845J84555yI+PIKlormedxxx8Vxxx1X6flsrirfEwQAAAAAAKhdTjvttGjatGmFy5/+9Keanl6NcSUIAN+IbpO6bfE+5g2ZVw0zAQAAAEjPr3/96zjvvPMqfK5Fixbf8GxqDxEEAAAAAAC2ci1atPhWx44N8XVYAAAAAABAkkQQAAAAAAAgSSIIAAAAAACQJBEEAAAAAABIkggCAAAAAAAkSQQBAAAAAACSJIIAAAAAAEAt0bNnz8jJySmzdOnSpdy4s846K3Jycqq8/0mTJsUBBxwQjRs3jvr160f79u3jiCOOiDfeeKN0zNKlS2PUqFHRsWPHyM/Pj6ZNm0bXrl1j1KhR5fa3atWqaNasWXTv3r3C4+Xk5ES/fv3KrR86dGgMHTq0yvOvqnpf+xEAAAAAAKCW6Dap2zd2rHlD5m3Wdv37949JkyaVPq5bt26Z5+fMmRPjx4+v8n7POuusuPnmm2Ps2LHxpz/9KSIi/v3vf8f9998fn376aUREfPjhh7H//vtHQUFBjB8/Pvbaa6/44IMP4rnnnou5c+eW2+d9990Xy5Yti3/961/xf//3fxUGmwcffDDuv//+OPzww6s85y0lggAAALBplzSppv0sr579wDegwwX3b/E+iguqYSKwlamen53BW7yPbt/ZYYv3sbm/wE5adfw3gf8e2KTc3Nxo2rRphc998cUXccopp8Tw4cPjlltuqfQ+//73v8f1118fN910U4wYMaJ0fYcOHcpcqXHeeefF4sWLo6ioKLbbbruIiGjVqlV069YtfvzjH5fb75QpU6Jnz57xj3/8I6ZOnRqXXnppuTHbbrttnHPOOXHwwQdHXl5epedcHUSQr6gtf0j7g4CtSa35uYmIqIb/wIGtiv/4hM1THT87/p1Ta1XX3+zzSw8AAGqja665JnJycuK8886rUgSZNGlStGzZMoYNG7bBMatWrYo777wzRowYURpANuajjz6KBx54IP7yl79Ebm7uBiPImDFjYtSoUTFu3Lj4+c9/Xuk5Vwf3BAEAAAAAgK1AUVFRjB07Nm677baoV69q1zi8+OKLsdtuu230Soz//Oc/UVJSEnvvvXel9nnXXXfFNttsE/369YsTTjgh5s+fH08//XS5cbvvvnv85Cc/iUsvvTTef//9Ks17S4kgAAAAAABQi8yYMSOaNm1aurz22msREXHqqafGqaeeusGbkG/MihUronXr1pscE/Hl119VxpQpU+Koo46KvLy8OOqooyI/Pz+mTp1a4dhLL700cnNz44ILLqjaxLeQCAIAAAAAALVInz594sUXXyxddtppp5g8eXIUFxfHr371q83aZ+PGjTd5FUajRo0iIiocd8MNN8TAgQNLH7/55pvxzDPPxODBX37NfZMmTeKwww6Lv/zlL/HFF1+U27558+bx61//OiZPnhxz5szZrNewOUQQAAAAAACoRRo0aBAdOnQoXXJzc2PixIlRVFQUjRo1inr16sVOO+0UERH16tWLyZMnb3Kfu+++e7zyyitRUlKywTGdO3eOvLy8mDt3brnn3n777XjhhRdKH99xxx0REXH44YdHQUFBFBQUxMyZM2PJkiXx0EMPVbj/U089Nbp27RpnnHFGZFm2yTlXBxEEAAAAAABquQkTJsTLL79cenXI+puiv/jii9G/f/9Nbn/iiSfGkiVL4ve///0GxxQUFMRRRx0Vt912W7z77rsb3d/UqVPjtNNOK3PFyssvvxzNmzff4Fdi1a1bN8aNGxdz5syJ++67b5Nzrg5Vu3MKAAAAAADwtVqzZk0sW7aszLr27dtHnTr/77qGJUuWRERE165dK7XPgw8+OIYPHx6jR4+Ozz77LAYPHhz169ePV199NW6//fYYOXJkfO9734vf/OY38Y9//CN69uwZV1xxRXzve9+L1atXx9tvv126r2eeeSbefPPNeOCBB6JTp05ljjN48OC47bbb4tNPP42GDRuWm0evXr3i6KOPjr/+9a+VfTu2iAgCAAAAAMC3xrwh82p6Cps0Y8aMaNasWZl1b7zxRulXYG2uW2+9Nfbdd9+49dZb4+qrr466detG+/bt4/DDD48uXbpERMT2228fzz//fFx22WXxs5/9LBYtWhQNGzaMjh07xsknnxwRX94Q/Yc//GG5ABIRMWzYsLjhhhvinnvuKR3/Vddcc03cf//9W/RaKksEAQAAAACAWuKJJ56o1LiePXtW+b4aOTk5MWLEiBgxYsRGx7Vp0ybGjx8f48ePr/D5P/zhDxvcdq+99iozr4rm2KFDh1i5cmUlZ71l3BMEAAAAAAC2cqeddlo0bdq0wuVPf/pTTU+vxrgSBAAAIHEdLtjyrxooLqiGiQAA8LX59a9/Heedd16Fz7Vo0eIbnk3tIYIAALBV8ctcAACA8lq0aPGtjh0b4uuwAAAAAACAJIkgAAAAAAAkqao3Dqd2qY7zJ4IAAAAAAJCU3NzciIj4/PPPa3gmbIn152/9+dwc7gkCAAAAAEBS6tatG02bNo0PPvggIiIaNGgQOTk5NTwrKivLsvj888/jgw8+iKZNm0bdunU3e18iCAAAAAAAyWndunVERGkIYevTtGnT0vO4uUQQAAAAAACSk5OTE23atIntttsu1qxZU9PToYpyc3O36AqQ9UQQAAAAAACSVbdu3Wr5ZTpbJxEEAAAAAIBvTLdJ3aplP/OGzKuW/ZC2OjU9AQAAAAAAgK+DK0EAoIZ0uOD+Ld5HccGWz8PfwCmves7N4GqYSUS37+ywxftI6dwAW7/q+PeOP9cAAKgsV4IAAAAAAABJEkEAAAAAAIAkiSAAAAAAAECSRBAAAAAAACBJIggAAAAAAJAkEQQAAAAAAEiSCAIAAAAAACRJBAEAAAAAAJIkggAAAAAAAEkSQQAAAAAAgCSJIAAAAAAAQJJEEAAAAAAAIEkiCAAAAAAAkCQRBAAAAAAASJIIAgAAAAAAJEkEAQAAAAAAkiSCAAAAAAAASRJBAAAAAACAJIkgAAAAAABAkkQQAAAAAAAgSSIIAAAAAACQJBEEAAAAAABIkggCAAAAAAAkSQQBAAAAAACSJIIAAAAAAABJEkEAAAAAAIAkiSAAAAAAAECSRBAAAAAAACBJIggAAAAAAJAkEQQAAAAAAEiSCAIAAAAAACRJBAEAAAAAAJIkggAAAAAAAEkSQQAAAAAAgCSJIAAAAAAAQJJEEAAAAAAAIEkiCAAAAAAAkCQRBAAAAAAASJIIAgAAAAAAJEkEAQAAAAAAkiSCAAAAAAAASRJBAAAAAACAJIkgAAAAAABAkurV9ASoWLdJ3bZ4H/OGzKuGmQAAAAAAwNbJlSAAAAAAAECSRBAAAAAAACBJIggAAAAAAJAkEQQAAAAAAEiSCAIAAAAAACRJBAEAAAAAAJIkggAAAAAAAEkSQQAAAAAAgCSJIAAAAAAAQJJEEAAAAAAAIEkiCAAAAAAAkCQRBAAAAAAASJIIAgAAAAAAJEkEAQAAAAAAkiSCAAAAAAAASRJBAAAAAACAJIkgAAAAAABAkkQQAAAAAAAgSSIIAAAAAACQJBEEAAAAAABIkggCAAAAAAAkqV5NTwC2Nt0mdauW/cwbMq9a9gMAAAAAQMVcCQIAAAAAACRJBAEAAAAAAJIkggAAAAAAAEkSQQAAAAAAgCSJIAAAAAAAQJJEEAAAAAAAIEkiCAAAAAAAkCQRBAAAAAAASJIIAgAAAAAAJEkEAQAAAAAAkiSCAAAAAAAASRJBAAAAAACAJIkgAAAAAABAkurV9AQAAACAmtdtUrct3se8IfOqYSYAANXHlSAAAAAAAECSRBAAAAAAACBJIggAAAAAAJAkEQQAAAAAAEiSCAIAAAAAACRJBAEAAAAAAJIkggAAAAAAAEmqV9MTAAAAALbQJU22fB/f2WHL9wEAUMu4EgQAAAAAAEiSCAIAAAAAACRJBAEAAAAAAJIkggAAAAAAAEkSQQAAAAAAgCSJIAAAAAAAQJJEEAAAAAAAIEkiCAAAAAAAkCQRBAAAAAAASJIIAgAAAAAAJGmzIsijjz4aXbt2jfr160efPn2iuLh4o+MXLlwYRx99dGy77bbRsmXLGD58eHz22Webc2gAAAAAAIBKqVfVDV5//fUYMGBA/P73v4++ffvGpZdeGv369Yt58+ZF3bp1K9zmqKOOij333DNeeumlWLRoUZxwwgkxZsyYuOaaa7b4BfDt0eGC+7d4H8UFg7d8It/ZYcv3AQAAAADA167KV4LccMMNcdBBB8WwYcOibdu2MW7cuFi8eHHMnDmzwvEfffRRzJ07N84666woLCyMHj16xNFHHx2vv/76Fk8eAAAAAABgQ6ocQaZNmxa9evUqfZyXlxcHHHBA3H333RWOb9SoUbRs2TLGjx8fWZbF2rVrY/bs2XHMMcds/qwBAAAAAAA2oUpfh7V69epYvHhxFBYWlllfWFgYL7/8coXb5ObmxqRJk+Koo46K+fPnR+PGjePwww+Pk046aYPHWbVqVaxatar08YoVK6oyTQAAAAAAgKpdCbJ06dLIsiwKCgrKrC8oKIglS5ZsdNt27dpFSUlJ3HPPPfHpp5/GF198scGxV1xxRTRp0qR0+Wp0AQAAAAAA2JQqRZDmzZtHTk5OlJSUlFm/cuXKaNmyZYXb/Oc//4ljjjkm7rrrrnjiiSdi3Lhxcf3118dpp522weOMHj06li9fXrosXLiwKtMEAAAAAACo2tdh5eXlRZs2beKdd94ps37BggWxww47VLjNpEmTokuXLtG9e/eIiDj99NPj448/jjFjxsS1114b22yzTblt8vPzIz8/vypTAwAAAAAAKKPKN0YfNGhQzJ49u/RxSUlJPP300zFo0KAKx69atSo+/vjjMuvat28fOTk5kZOTU9XDAwAAAAAAVEqVI8jIkSNj1qxZMWXKlFi0aFGceeaZ0bp16+jfv39ERPTu3TtOPvnk0vEDBgyI4uLiGD16dCxcuDCeeeaZuPzyy+OYY46JBg0aVN8rAQAAAAAA+C9VjiCdOnWK6dOnx9ixY6Njx44xf/78ePDBB6Nu3boREVFUVBQLFiwoHf+DH/wgpk2bFo888kh06dIljj/++DjyyCPj1ltvrb5XAQAAAAAA8BVVuifIeocccki89tprFT5XXFxcbt3AgQNj4MCBm3MoAAAAAACAzVLlK0EAAAAAAAC2BiIIAAAAAACQpM36OiwAAACgenS44P4t3kdxQTVMBAAgQa4EAQAAAAAAkiSCAAAAAAAASRJBAAAAAACAJIkgAAAAAABAkkQQAAAAAAAgSSIIAAAAAACQJBEEAAAAAABIkggCAAAAAAAkSQQBAAAAAACSJIIAAAAAAABJEkEAAAAAAIAkiSAAAAAAAECSRBAAAAAAACBJIggAAAAAAJAkEQQAAAAAAEiSCAIAAAAAACRJBAEAAAAAAJIkggAAAAAAAEkSQQAAAAAAgCSJIAAAAAAAQJJEEAAAAAAAIEkiCAAAAAAAkKR6NT0BAAAAAACgdug2qdsW72PekHnVMJPq4UoQAAAAAAAgSSIIAAAAAACQJBEEAAAAAABIkggCAAAAAAAkSQQBAAAAAACSJIIAAAAAAABJEkEAAAAAAIAkiSAAAAAAAECSRBAAAAAAACBJIggAAAAAAJAkEQQAAAAAAEiSCAIAAAAAACRJBAEAAAAAAJIkggAAAAAAAEkSQQAAAAAAgCSJIAAAAAAAQJJEEAAAAAAAIEkiCAAAAAAAkCQRBAAAAAAASJIIAgAAAAAAJEkEAQAAAAAAkiSCAAAAAAAASRJBAAAAAACAJIkgAAAAAABAkkQQAAAAAAAgSSIIAAAAAACQJBEEAAAAAABIkggCAAAAAAAkSQQBAAAAAACSJIIAAAAAAABJEkEAAAAAAIAkiSAAAAAAAECSRBAAAAAAACBJIggAAAAAAJAkEQQAAAAAAEiSCAIAAAAAACRJBAEAAAAAAJIkggAAAAAAAEkSQQAAAAAAgCSJIAAAAAAAQJJEEAAAAAAAIEkiCAAAAAAAkCQRBAAAAAAASJIIAgAAAAAAJEkEAQAAAAAAkiSCAAAAAAAASRJBAAAAAACAJIkgAAAAAABAkkQQAAAAAAAgSSIIAAAAAACQJBEEAAAAAABIkggCAAAAAAAkSQQBAAAAAACSJIIAAAAAAABJEkEAAAAAAIAkiSAAAAAAAECSRBAAAAAAACBJIggAAAAAAJAkEQQAAAAAAEiSCAIAAAAAACRJBAEAAAAAAJIkggAAAAAAAEkSQQAAAAAAgCSJIAAAAAAAQJJEEAAAAAAAIEn1anoCAAAAAPCNu6RJNe1nefXsB/hW63DB/Vu8j+IrD6+GmaTHlSAAAAAAAECSRBAAAAAAACBJIggAAAAAAJAkEQQAAAAAAEiSCAIAAAAAACRJBAEAAAAAAJJUr6YnAAAAAAAAbKFLmlTPfr6zQ/Xsp5ZwJQgAAAAAAJAkEQQAAAAAAEiSCAIAAAAAACRJBAEAAAAAAJIkggAAAAAAAEkSQQAAAAAAgCSJIAAAAAAAQJJEEAAAAAAAIEkiCAAAAAAAkCQRBAAAAAAASJIIAgAAAAAAJEkEAQAAAAAAkiSCAAAAAAAASRJBAAAAAACAJIkgAAAAAABAkkQQAAAAAAAgSSIIAAAAAACQJBEEAAAAAABIkggCAAAAAAAkSQQBAAAAAACSJIIAAAAAAABJEkEAAAAAAIAkiSAAAAAAAECSRBAAAAAAACBJIggAAAAAAJAkEQQAAAAAAEiSCAIAAAAAACRJBAEAAAAAAJIkggAAAAAAAEkSQQAAAAAAgCSJIAAAAAAAQJJEEAAAAAAAIEkiCAAAAAAAkCQRBAAAAAAASJIIAgAAAAAAJEkEAQAAAAAAkrRZEeTRRx+Nrl27Rv369aNPnz5RXFy80fHvvfdenHjiibHttttGw4YN47vf/W48//zzm3NoAAAAAACASqlyBHn99ddjwIABce6550ZRUVF06tQp+vXrF2vXrq1w/Oeffx69evWKLMtizpw58fLLL8eZZ54Z9erV2+LJAwAAAAAAbEiVS8QNN9wQBx10UAwbNiwiIsaNGxdt2rSJmTNnxoABA8qN/+Mf/xifffZZTJo0KXJzcyMiYscdd9yyWQMAAAAAAGxCla8EmTZtWvTq1av0cV5eXhxwwAFx9913Vzh++vTp0a9fv9IAAgAAAAAA8E2oUgRZvXp1LF68OAoLC8usLywsjLfffrvCbf7973/H9ttvH+eee24UFhbGnnvuGTfffPNGj7Nq1apYsWJFmQUAAAAAAKAqqhRBli5dGlmWRUFBQZn1BQUFsWTJkgq3WbZsWVx//fXRrl27ePDBB+PEE0+MESNGxNSpUzd4nCuuuCKaNGlSunw1ugAAAAAAAGxKlSJI8+bNIycnJ0pKSsqsX7lyZbRs2bLCbfLy8qJ///4xatSo6Nq1a/z85z+PXr16xa233rrB44wePTqWL19euixcuLAq0wQAAAAAAKjajdHz8vKiTZs28c4775RZv2DBgthhhx0q3KZ9+/bRunXrMut23XXX+Pvf/77B4+Tn50d+fn5VpgYAAAAAAFBGlW+MPmjQoJg9e3bp45KSknj66adj0KBBFY7v3bt3PPPMM2XWzZ8/P3bZZZeqHhoAAAAAAKDSqhxBRo4cGbNmzYopU6bEokWL4swzz4zWrVtH//79I+LL6HHyySeXjj/nnHPiueeeiyuuuCIWLFgQEyZMiEceeSTOP//86nsVAAAAAAAAX1HlCNKpU6eYPn16jB07Njp27Bjz58+PBx98MOrWrRsREUVFRbFgwYLS8R07dowHHngg/vKXv0SnTp3i6quvjr/85S/RvXv36nsVAAAAAAAAX1Gle4Ksd8ghh8Rrr71W4XPFxcXl1h144IHxwgsvbM6hAAAAAAAANkuVrwQBAAAAAADYGoggAAAAAABAkkQQAAAAAAAgSSIIAAAAAACQJBEEAAAAAABIkggCAAAAAAAkSQQBAAAAAACSJIIAAAAAAABJEkEAAAAAAIAkiSAAAAAAAECSRBAAAAAAACBJIggAAAAAAJAkEQQAAAAAAEiSCAIAAAAAACRJBAEAAAAAAJIkggAAAAAAAEkSQQAAAAAAgCSJIAAAAAAAQJJEEAAAAAAAIEkiCAAAAAAAkCQRBAAAAAAASJIIAgAAAAAAJEkEAQAAAAAAkiSCAAAAAAAASRJBAAAAAACAJIkgAAAAAABAkkQQAAAAAAAgSSIIAAAAAACQJBEEAAAAAABIkggCAAAAAAAkSQQBAAAAAACSJIIAAAAAAABJEkEAAAAAAIAkiSAAAAAAAECSRBAAAAAAACBJIggAAAAAAJAkEQQAAAAAAEiSCAIAAAAAACRJBAEAAAAAAJIkggAAAAAAAEkSQQAAAAAAgCSJIAAAAAAAQJJEEAAAAAAAIEkiCAAAAAAAkCQRBAAAAAAASJIIAgAAAAAAJEkEAQAAAAAAkiSCAAAAAAAASRJBAAAAAACAJIkgAAAAAABAkkQQAAAAAAAgSSIIAAAAAACQJBEEAAAAAABIkggCAAAAAAAkSQQBAAAAAACSJIIAAAAAAABJEkEAAAAAAIAkiSAAAAAAAECSRBAAAAAAACBJIggAAAAAAJAkEQQAAAAAAEiSCAIAAAAAACRJBAEAAAAAAJIkggAAAAAAAEkSQQAAAAAAgCSJIAAAAAAAQJJEEAAAAAAAIEkiCAAAAAAAkCQRBAAAAAAASJIIAgAAAAAAJEkEAQAAAAAAkiSCAAAAAAAASRJBAAAAAACAJIkgAAAAAABAkkQQAAAAAAAgSSIIAAAAAACQJBEEAAAAAABIkggCAAAAAAAkSQQBAAAAAACSJIIAAAAAAABJEkEAAAAAAIAkiSAAAAAAAECSRBAAAAAAACBJIggAAAAAAJAkEQQAAAAAAEiSCAIAAAAAACRJBAEAAAAAAJIkggAAAAAAAEkSQQAAAAAAgCSJIAAAAAAAQJJEEAAAAAAAIEkiCAAAAAAAkCQRBAAAAAAASJIIAgAAAAAAJEkEAQAAAAAAkiSCAAAAAAAASRJBAAAAAACAJIkgAAAAAABAkkQQAAAAAAAgSSIIAAAAAACQJBEEAAAAAABIkggCAAAAAAAkSQQBAAAAAACSJIIAAAAAAABJEkEAAAAAAIAkiSAAAAAAAECSRBAAAAAAACBJIggAAAAAAJAkEQQAAAAAAEiSCAIAAAAAACRJBAEAAAAAAJIkggAAAAAAAEkSQQAAAAAAgCSJIAAAAAAAQJJEEAAAAAAAIEkiCAAAAAAAkCQRBAAAAAAASJIIAgAAAAAAJEkEAQAAAAAAkiSCAAAAAAAASRJBAAAAAACAJIkgAAAAAABAkkQQAAAAAAAgSSIIAAAAAACQJBEEAAAAAABIkggCAAAAAAAkSQQBAAAAAACSJIIAAAAAAABJEkEAAAAAAIAkiSAAAAAAAECSRBAAAAAAACBJIggAAAAAAJAkEQQAAAAAAEiSCAIAAAAAACRJBAEAAAAAAJK0WRHk0Ucfja5du0b9+vWjT58+UVxcXKntPvnkkygsLIyhQ4duzmEBAAAAAAAqrcoR5PXXX48BAwbEueeeG0VFRdGpU6fo169frF27dpPbjh49Ot59993NmigAAAAAAEBVVDmC3HDDDXHQQQfFsGHDom3btjFu3LhYvHhxzJw5c6PbPfvss3H77bfH4MGDN3uyAAAAAAAAlVXlCDJt2rTo1atX6eO8vLw44IAD4u67797gNmvWrImf/OQnMWbMmNhpp502b6YAAAAAAABVUKUIsnr16li8eHEUFhaWWV9YWBhvv/32Brf7zW9+E3l5eTFq1KhKHWfVqlWxYsWKMgsAAAAAAEBVVCmCLF26NLIsi4KCgjLrCwoKYsmSJRVu8+abb8aVV14Zt912W9StW7dSx7niiiuiSZMmpctXowsAAAAAAMCmVCmCNG/ePHJycqKkpKTM+pUrV0bLli0r3GbEiBFxxhlnxB577FHp44wePTqWL19euixcuLAq0wQAAAAAAIh6VRmcl5cXbdq0iXfeeafM+gULFsQOO+xQbvzbb78djz/+ePz973+Pq666KiIi1q1bFxERd9xxR3zxxRcVHic/Pz/y8/OrMjUAAAAAAIAyqnxj9EGDBsXs2bNLH5eUlMTTTz8dgwYNKje2bdu2MW/evHjxxRdLl/79+0f//v3jxRdf3KKJAwAAAAAAbEyVrgSJiBg5cmTsueeeMWXKlOjdu3dccskl0bp16+jfv39ERPTu3TvatWsXkydPjtzc3OjatWuZ7Zs2bRoRUW49AAAAAABAdarylSCdOnWK6dOnx9ixY6Njx44xf/78ePDBB0tvel5UVBQLFiyo9okCAAAAAABURZWvBImIOOSQQ+K1116r8Lni4uKNbnv77bdvziEBAAAAAACqpMpXggAAAAAAAGwNRBAAAAAAACBJIggAAAAAAJAkEQQAAAAAAEiSCAIAAAAAACRJBAEAAAAAAJIkggAAAAAAAEkSQQAAAAAAgCSJIAAAAAAAQJJEEAAAAAAAIEkiCAAAAAAAkCQRBAAAAAAASJIIAgAAAAAAJEkEAQAAAAAAkiSCAAAAAAAASRJBAAAAAACAJIkgAAAAAABAkkQQAAAAAAAgSSIIAAAAAACQJBEEAAAAAABIkggCAAAAAAAkSQQBAAAAAACSJIIAAAAAAABJEkEAAAAAAIAkiSAAAAAAAECSRBAAAAAAACBJIggAAAAAAJAkEQQAAAAAAEiSCAIAAAAAACRJBAEAAAAAAJIkggAAAAAAAEkSQQAAAAAAgCSJIAAAAAAAQJJEEAAAAAAAIEkiCAAAAAAAkCQRBAAAAAAASJIIAgAAAAAAJEkEAQAAAAAAkiSCAAAAAAAASRJBAAAAAACAJIkgAAAAAABAkkQQAAAAAAAgSSIIAAAAAACQJBEEAAAAAABIkggCAAAAAAAkSQQBAAAAAACSJIIAAAAAAABJEkEAAAAAAIAkiSAAAAAAAECSRBAAAAAAACBJIggAAAAAAJAkEQQAAAAAAEiSCAIAAAAAACRJBAEAAAAAAJIkggAAAAAAAEkSQQAAAAAAgCSJIAAAAAAAQJJEEAAAAAAAIEkiCAAAAAAAkCQRBAAAAAAASJIIAgAAAAAAJEkEAQAAAAAAkiSCAAAAAAAASRJBAAAAAACAJIkgAAAAAABAkkQQAAAAAAAgSSIIAAAAAACQJBEEAAAAAABIkggCAAAAAAAkSQQBAAAAAACSJIIAAAAAAABJEkEAAAAAAIAkiSAAAAAAAECSRBAAAAAAACBJIggAAAAAAJAkEQQAAAAAAEiSCAIAAAAAACRJBAEAAAAAAJIkggAAAAAAAEkSQQAAAAAAgCSJIAAAAAAAQJJEEAAAAAAAIEn1anoCAAAAAFAVHS64f4v3UVxQDRMBoNZzJQgAAAAAAJAkEQQAAAAAAEiSCAIAAAAAACRJBAEAAAAAAJIkggAAAAAAAEkSQQAAAAAAgCSJIAAAAAAAQJJEEAAAAAAAIEkiCAAAAAAAkCQRBAAAAAAASJIIAgAAAAAAJEkEAQAAAAAAkiSCAAAAAAAASRJBAAAAAACAJIkgAAAAAABAkkQQAAAAAAAgSSIIAAAAAACQJBEEAAAAAABIkggCAAAAAAAkSQQBAAAAAACSJIIAAAAAAABJEkEAAAAAAIAkiSAAAAAAAECSRBAAAAAAACBJIggAAAAAAJAkEQQAAAAAAEiSCAIAAAAAACRJBAEAAAAAAJIkggAAAAAAAEkSQQAAAAAAgCSJIAAAAAAAQJJEEAAAAAAAIEkiCAAAAAAAkCQRBAAAAAAASJIIAgAAAAAAJEkEAQAAAAAAkiSCAAAAAAAASRJBAAAAAACAJIkgAAAAAABAkkQQAAAAAAAgSSIIAAAAAACQJBEEAAAAAABIkggCAAAAAAAkSQQBAAAAAACSJIIAAAAAAABJEkEAAAAAAIAkiSAAAAAAAECSRBAAAAAAACBJIggAAAAAAJAkEQQAAAAAAEiSCAIAAAAAACRpsyLIo48+Gl27do369etHnz59ori4eINj58yZE0cccURst9120bRp0/jRj34Ub7/99ubOFwAAAAAAoFKqHEFef/31GDBgQJx77rlRVFQUnTp1in79+sXatWsrHD937tzo1atXPPXUU/HUU0/F4sWLo3///hscDwAAAAAAUB3qVXWDG264IQ466KAYNmxYRESMGzcu2rRpEzNnzowBAwaUG3/aaaeVeXz55ZdHnz594o033oguXbps3qwBAAAAAAA2ocpXgkybNi169epV+jgvLy8OOOCAuPvuuyu1fX5+fkRErFy5sqqHBgAAAAAAqLQqXQmyevXqWLx4cRQWFpZZX1hYGC+//HKl9nHnnXdG27Zto1u3bhscs2rVqli1alXp4xUrVlRlmgAAAAAAAFW7EmTp0qWRZVkUFBSUWV9QUBBLlizZ5PaPPPJI3HrrrXHbbbdFvXob7i9XXHFFNGnSpHT5anQBAAAAAADYlCpFkObNm0dOTk6UlJSUWb9y5cpo2bLlRrd94okn4thjj43JkyfHoYceutGxo0ePjuXLl5cuCxcurMo0AQAAAAAAqvZ1WHl5edGmTZt45513yqxfsGBB7LDDDhvc7n//939jwIABcdttt8XRRx+9yePk5+eX3jsEAAAAAABgc1T5xuiDBg2K2bNnlz4uKSmJp59+OgYNGlTh+BUrVsRRRx0VZ511VqUCCAAAAAAAQHWocgQZOXJkzJo1K6ZMmRKLFi2KM888M1q3bh39+/ePiIjevXvHySefXDr+8ssvjw8++CBGjBgRy5YtK12++OKL6nsVAAAAAAAAX1HlCNKpU6eYPn16jB07Njp27Bjz58+PBx98MOrWrRsREUVFRbFgwYLS8c8991yUlJREu3btolmzZqXLU089VX2vAgAAAAAA4CuqdE+Q9Q455JB47bXXKnyuuLi4zOMnnnhicw4BAAAAAACwRap8JQgAAAAAAMDWQAQBAAAAAACSJIIAAAAAAABJEkEAAAAAAIAkiSAAAAAAAECSRBAAAAAAACBJIggAAAAAAJAkEQQAAAAAAEiSCAIAAAAAACRJBAEAAAAAAJIkggAAAAAAAEkSQQAAAAAAgCSJIAAAAAAAQJJEEAAAAAAAIEkiCAAAAAAAkCQRBAAAAAAASJIIAgAAAAAAJEkEAQAAAAAAkiSCAAAAAAAASRJBAAAAAACAJIkgAAAAAABAkkQQAAAAAAAgSSIIAAAAAACQJBEEAAAAAABIkggCAAAAAAAkSQQBAAAAAACSJIIAAAAAAABJEkEAAAAAAIAkiSAAAAAAAECSRBAAAAAAACBJIggAAAAAAJAkEQQAAAAAAEiSCAIAAAAAACRJBAEAAAAAAJIkggAAAAAAAEkSQQAAAAAAgCSJIAAAAAAAQJJEEAAAAAAAIEkiCAAAAAAAkCQRBAAAAAAASJIIAgAAAAAAJEkEAQAAAAAAkiSCAAAAAAAASRJBAAAAAACAJIkgAAAAAABAkkQQAAAAAAAgSSIIAAAAAACQJBEEAAAAAABIkggCAAAAAAAkSQQBAAAAAACSJIIAAAAAAABJEkEAAAAAAIAkiSAAAAAAAECSRBAAAAAAACBJIggAAAAAAJAkEQQAAAAAAEiSCAIAAAAAACRJBAEAAAAAAJIkggAAAAAAAEkSQQAAAAAAgCSJIAAAAAAAQJJEEAAAAAAAIEkiCAAAAAAAkCQRBAAAAAAASJIIAgAAAAAAJEkEAQAAAAAAkiSCAAAAAAAASRJBAAAAAACAJIkgAAAAAABAkkQQAAAAAAAgSSIIAAAAAACQJBEEAAAAAABIkggCAAAAAAAkSQQBAAAAAACSJIIAAAAAAABJEkEAAAAAAIAkiSAAAAAAAECSRBAAAAAAACBJIggAAAAAAJAkEQQAAAAAAEiSCAIAAAAAACRJBAEAAAAAAJIkggAAAAAAAEkSQQAAAAAAgCSJIAAAAAAAQJJEEAAAAAAAIEkiCAAAAAAAkCQRBAAAAAAASJIIAgAAAAAAJEkEAQAAAAAAkiSCAAAAAAAASRJBAAAAAACAJIkgAAAAAABAkkQQAAAAAAAgSSIIAAAAAACQJBEEAAAAAABIkggCAAAAAAAkSQQBAAAAAACSJIIAAAAAAABJqlfTEwAAAACArVW3Sd22eB/zhsyrhpkAUBFXggAAAAAAAEkSQQAAAAAAgCSJIAAAAAAAQJJEEAAAAAAAIEkiCAAAAAAAkCQRBAAAAAAASJIIAgAAAAAAJEkEAQAAAAAAkiSCAAAAAAAASRJBAAAAAACAJIkgAAAAAABAkkQQAAAAAAAgSSIIAAAAAACQJBEEAAAAAABIkggCAAAAAAAkSQQBAAAAAACSJIIAAAAAAABJEkEAAAAAAIAkiSAAAAAAAECSRBAAAAAAACBJIggAAAAAAJAkEQQAAAAAAEiSCAIAAAAAACRJBAEAAAAAAJIkggAAAAAAAEkSQQAAAAAAgCSJIAAAAAAAQJJEEAAAAAAAIEkiCAAAAAAAkCQRBAAAAAAASJIIAgAAAAAAJEkEAQAAAAAAkiSCAAAAAAAASRJBAAAAAACAJIkgAAAAAABAkjYrgjz66KPRtWvXqF+/fvTp0yeKi4s3Ov6FF16IHj16RP369aNHjx7x4osvbs5hAQAAAAAAKq3KEeT111+PAQMGxLnnnhtFRUXRqVOn6NevX6xdu7bC8R999FEccsgh0b9//3jrrbfiyCOPjL59+8ayZcu2dO4AAAAAAAAbVOUIcsMNN8RBBx0Uw4YNi7Zt28a4ceNi8eLFMXPmzArHT5w4Mdq0aRMXXnhhtGnTJn75y1/GdtttF7fffvuWzh0AAAAAAGCDqhxBpk2bFr169Sp9nJeXFwcccEDcfffdGxzfs2fPMut69uy5wfEAAAAAAADVoV5VBq9evToWL14chYWFZdYXFhbGyy+/XOE2CxYsiKOOOqrc+OnTp2/wOKtWrYpVq1aVPl6+fHlERKxYsaIq090s61Z9vsX7WJGTbfE+1q6s+OvFqjSPb+D9+ialdG4i0jo/teXcRPjZqUhtOT/OTXkpnZuItM5PbTk3EX52KlJbzo9zU15K5yYirfNTW85NhJ+ditSW8+PclJfSuYlI6/zUlnMT4WenIrXl/Dg35aV0biLSOj+15dxEbD0/O+uPkWWbeN1ZFSxatCiLiGzGjBll1p9zzjlZ586dK9wmLy8vu/7668usGzduXJafn7/B44wZMyaLCIvFYrFYLBaLxWKxWCwWi8VisVgslg0uCxcu3GjXqNKVIM2bN4+cnJwoKSkps37lypXRsmXLCrdp2bJllcZHRIwePTpGjRpV+njdunXx0UcflR5/a7ZixYooLCyMhQsXRuPGjWt6OnyF81N7OTe1l3NTuzk/tZdzU3s5N7Wb81N7OTe1l3NTuzk/tZdzU3s5N7Wb81N7pXZusiyLTz75JNq2bbvRcVWKIHl5edGmTZt45513yqxfsGBB7LDDDhVu0759+yqNj4jIz8+P/Pz8MuuaNm1alanWeo0bN07ig5Yq56f2cm5qL+emdnN+ai/npvZybmo356f2cm5qL+emdnN+ai/npvZybmo356f2SuncNGnSZJNjqnxj9EGDBsXs2bNLH5eUlMTTTz8dgwYNqtT4iIjZs2dvcDwAAAAAAEB1qHIEGTlyZMyaNSumTJkSixYtijPPPDNat24d/fv3j4iI3r17x8knn1w6fujQofH+++/HVVddFe+//35ccsklsWTJkhg6dGi1vQgAAAAAAICvqnIE6dSpU0yfPj3Gjh0bHTt2jPnz58eDDz4YdevWjYiIoqKiWLBgQen4Zs2axUMPPRR33313dOjQIR566KF4+OGHo1mzZtX3KrYi+fn5MWbMmHJf90Xt4PzUXs5N7eXc1G7OT+3l3NRezk3t5vzUXs5N7eXc1G7OT+3l3NRezk3t5vzUXt/Wc5OTZVlW05MAAAAAAACoblW+EgQAAAAAAGBrIIIAAAAAAABJEkEAAAAAAIAkiSAAAAAAAECSRBAAAAAAACBJIgiw1bjjjjtixYoVNT0N2GosXLgwXnjhhfj0009reirfapMnT44333yzpqfBRixbtqzc45tvvjluvfXWeP/992tmUpR68803Y/bs2TFr1qx46aWXYvXq1TU9Jf7L6tWr46233oo5c+bE/PnznR8gOf/4xz9i5cqVNT0N2GqsW7cuPv7445qexrfek08+We7/c77NRJCv0dy5c+MXv/hFnHPOOfHwww+Xe37lypUxfPjwGpjZt9u6devitttui6uuuio++OCDiPjyf65//OMfR8+ePWPIkCHx7LPP1vAsqcjw4cPj3XffrelpfGtdf/31sWbNmjLrVqxYEdddd12cdtppcdVVV8XChQtraHbfbldeeWXccccdpY+XLVsWhx56aHTo0CH22Wef2HbbbWPUqFHlzh/fjKFDh8Yee+wRo0aN8j8DtcycOXOiVatW0bx58zj44INjyZIl8cYbb8Ruu+0WP/3pT+OMM86I3XffPV555ZWanuq30i233BLt27ePzp07R+/eveOQQw6JvffeO5o1axZDhgzx75wa9vTTT8dRRx0VDRs2jE6dOsV+++0XO+20UzRs2DAGDhwYTz/9dE1PkQ345JNPYscdd6zpaXwrzZo1K+66664oKSmJiIiPPvooLrvsshg6dGiMGTMmiouLa3aCVKh3797OTQ2aMWNGrF27tsy6devWxd/+9re4+uqr46677opPPvmkhmb37Xb77bfHjBkzSh+XlJTEiBEjokGDBtGiRYto3bp1XH/99TU4w2+3nj17xk477RTXX399fPHFFzU9nRqXk2VZVtOTSNE999wTxx57bLRt2zby8/OjqKgoTjrppJg4cWLUqfNle1q+fHlsu+225f4w5+v1s5/9LK699tpo0qRJNG/ePB577LHYb7/9omHDhrHXXnvF66+/Hq+88krMnDkzDjvssJqe7rdOnTp1Iicnp8Lnsiwr85yfnW9W3bp14+OPP47GjRtHxJe/aN97771j0aJFseOOO8Z7770XERFPPPFE7LHHHjU51W+djh07xoQJE+LAAw+MiIgf//jH8dhjj8Wll14au+66a7z11ltx8cUXx6GHHhrXXnttDc/226dOnToxZ86cuOqqq2L27Nnxs5/9LE4//fRo1KhRTU/tW+973/tedOnSJc4999x45JFH4m9/+1usWrUqli1bFo888ki0adMmTj/99Fi4cGE88MADNT3db5Vrrrkmrr766hgzZkx8//vfj88++yx+8YtfxKBBg6J169YxefLkeO655+LJJ5+Mzp071/R0v3XuvPPOOOWUU2LYsGHRs2fPKCwsjIKCgli5cmUsWLAgZs2aFVOmTIkJEybEscceW9PT5Sv8f2jNuOqqq2L06NEREfHd7343Hnroodhvv/3i/fffj86dO0dxcXF8/vnnMWvWrOjRo0cNz/bbZ2NhsLi4ONq1axe5ubkREfHWW299U9Miyv9/aElJSfTs2TPmzJkT9evXj5UrV0aHDh3i8ccfjw4dOtTsZL9ldtlll7juuuuib9++EfHl79smTpwYZ599dun/h/7ud7+LkSNHxoUXXljDs/32qVOnzv+vvfuPqar+4zj+ulzkR9AtwBhkgBRIgtcfMAjQIUoWJkE5IIYp/eG4ZRsOMDV1iViW+k+TVrIZIi5A0SRyLcgNWowSZeiUy0AdiFcIxwzcvKIQn+8f1vl+r4iz7cs9nzivx8Yf9/D54709d/V+OPecgxMnTmDXrl0YHBzEjh078NZbb034N7cpT9CkMBqNoqCgQHl95swZYTQaRVpamhgbGxNCCDE4OCgcHBzUGlGz/P39xeHDh4UQQuzcuVOEhYWJFStWiJGREWVNXl6eiIqKUmtETcvJyRGOjo7CZDKJy5cvi+7ubtHd3S26urqEo6OjOHjwoGhoaBANDQ1qj6o5Op1ODA0NKa83bdok5s2bJ37//XchhBDDw8MiKytLrFixQq0RNcvZ2VnpIIQQM2fOFKdOnbJZ09LSIry8vOw9Ggnb987p06fFkiVLhIeHh9i2bZu4evWqytNpm5ubm7BYLMrrbdu2CWdnZ3HhwgXlWHd3t/D09FRjPE3z8/MTtbW1NseuX78uZs6cqXyW3rFjh0hKSlJjPM0LCgoS33///SPXVFdXi6CgIDtNRH9LSkoSgYGBj/wJCAjgPlQFQUFBYvfu3WJoaEisW7dOxMXFidjYWDE4OCiEuP9ZOjMzU8THx6s8qTYlJycLBwcHYTKZlP1mQ0ODqK+vF3q9XnzyySeitLRUlJaWqj2q5jy4D921a5cIDAwUra2tQggh+vr6RGJiosjIyFBpQu1ycXERvb29yuvg4GDx7bff2qypr68Xvr6+9h6NhO1758iRI2LWrFkiODhYHDhwQFitVpWnsz9eCTJJ3NzccOnSJTz77LPKsVu3biExMRF+fn44fPgw7ty5w2/gqMDFxQU9PT3w9vbGrVu38PTTT6Ourg4vv/yysqanpwdhYWG8pFIlzc3NyM7OhoODA0pKSjB//nwAwLRp03D+/HmEhoaqO6BGPfgNnMjISGzatAmpqanKmq6uLsTExPAe+nYWHByMr7/+GnFxcQCA8PBwHDhwAOHh4coas9mMmJgYDA0NqTWmZjk4OGBwcFB57wDADz/8gK1bt+LChQtYvHgx3nzzTcTExCAiIkLFSbXn+eefx7FjxxAeHo7+/n4sWLAAkZGR+O6775Q1586dw6uvvor+/n4VJ9UeNzc3tLe3w9/fXzl27949uLu7o6+vD15eXujr60NISAifF6YCd3d3dHR0YMaMGROuuX79OkJCQvhcKjvLzc3Fzz//jISEhAnXDA8P48svv+Q+1M5cXV3R1dUFHx8f3LhxAz4+PqipqUFSUpKy5vLly4iMjOTtM1Vy7NgxrF+/HuHh4SguLlb+nsN9qLoe3IfGxsbCZDIhKytLWdPe3o5ly5bBYrGoNaYm+fv7o7q6Wtl3hoaG4siRIzAajcqaK1euYN68efw8oIIH96F//vkniouL8fHHH+P27dtIS0tDSkoKYmNj4eXlpfK0k4/PBJkkvr6+6OnpsTlmMBhQW1uL/v5+zJ8/H998841K02mbh4eH8mAgg8EANzc3BAYG2qz5448/4OTkpMJ0BABRUVFoaWlBeno6Fi9ejA8//BB3795VeyzNE0Lgs88+Q2FhIQoLC9HZ2fnQjcDf9zgm+3n33XeRlZWFuro6CCFQUFCAwsJC5X1z7do1vP/++0hOTlZ5Um162OXGr732GlpbW1FeXo47d+4gJycHUVFRKkynbWvXrkVGRgY2btyI2NhY+Pj44ObNm8jLy4PZbEZjYyOys7MRHx+v9qiak5CQgI8++ghWqxUAYLVakZ+fDz8/P2WTdvv2beU2s2RfiYmJWL9+PQYGBh76+4GBAeTm5uKVV16x82S0dOlSODs7Y+/evRP+7Ny5E/wupP25u7sr/6Z5e3vD1dUVs2bNslkzOjrKNipKTU1Fe3s7ZsyYgTlz5qC4uFjtkQj396EVFRUoKytDWVkZOjs7sWDBAps17u7u/LKXClavXo21a9eis7MTAJCXl4fPP/9c+b3VasWWLVuwZMkSlSbUtgf3oXq9HuvWrcOVK1ewdetW1NbWIiUlBd7e3ipNaF+Oag8wVb3++uv46quvEB0dbXP8ySefxE8//YQPPvgAOTk5Kk2nbQkJCWhublY+cJrN5nHfYjt+/Dhmz56txnj0F71ej82bNyMtLQ3vvfcejEYjNwQqW7NmjfLcDwBYuXIlpk+fbrOmvb3d5qoqso/8/HwMDQ0hOTkZ06ZNQ0BAACwWC7y9vWEwGNDb24tly5bhiy++UHtUTXrUv13p6elIT0+HxWLB6dOn7TgVAcCWLVvw1FNPoa6uDikpKdi+fTtGRkaQnp6OOXPmALh/r+O9e/eqPKn27N+/H8nJyfDw8MD06dMxMDAAg8GAEydOKGt+++23cX8EIfsoLi5Wnn8YGhqqPBNkeHgYFosFbW1tiI+PR2Vlpdqjak58fDzOnz//yDWurq7Yvn27nSaiv0VERKCxsVF59kRdXd245xfU1NSMOzFC9mUwGLB//36sXr0aJpMJ5eXlao+keXFxcTb/nxiNxnH70LNnz/JKHRUUFBTg2rVrePHFFxESEoIXXngBv/76KxobG+Ht7Y2LFy/Cz8+Pz9ZTyUT7UFdXV2zcuBEbNmxAU1OTZvahvB3WJLFarbh58yaee+65CdeYzWacOXPG5hI+koPVaoVOp4Orq6vao9BfysrKcOjQIZSUlCAgIEDtcYikdOPGDZw8eRLt7e0YHByEk5MTAgICkJCQwNssEf1Dly5dwt27dzF79mzo9Xq1x9EkIQR+/PFHtLe3w8vLC0lJSZq4VP/fpKWlBcePH0dPTw8GBgbwzDPPICAgAKmpqcrtTInovnv37kGn0ykP136Y7u5u6HQ67nckMTIygk8//RSlpaWoq6tDUFCQ2iMRSam1tRXV1dUwm83j9qFvvPEGP0ur5OrVq/z/5H/wJMgksVgsGBsbs7mPMQBUVlaitLQUTzzxBN555x3emkQFbCO3R/U5ePAg3Nzc2EclfO/Ia6I2FRUVOHToENuojO8debGNvNiGiIiIiIj+X3gT3UmSmZmJiooKm2P79u3DqlWr0NvbC51Oh4yMDFRVVak0oXaxjdwe1aevr499VMT3jrwe1qaoqAhvv/0220iA7x15sY282IaIiIiIiP5vBE0KDw8PcfHiReV1W1ubcHZ2FomJiWJ0dFQIIcTRo0dFRESEWiNqFtvIjX3kxTbyYhu5sY+82EZebPPvNzg4KBwcHNQegx6CbeTFNnJjH3mxjbzYRm5a6sMrQSbJ6OgoDAYDgPv3M87OzoazszNKSkqUe+EtWrQIHR0dao6pSWwjN/aRF9vIi23kxj7yYht5sc3UIHjnZWmxjbzYRm7sIy+2kRfbyE0rfXgSZJIsXLgQ+fn5aG5uRnZ2NpqamrBnzx74+voqa7q6uuDi4qLilNrENnJjH3mxjbzYRm7sIy+2kRfbyO2ll16CXq9/5I+npyd0Op3ao2oO28iLbeTGPvJiG3mxjdzYx5aj2gNMVUVFRVi+fDmio6Oh0+mQm5sLk8lks6aqqgpGo1GlCbWLbeTGPvJiG3mxjdzYR15sIy+2kdvSpUvh5OSEjIyMCddYrVZs3rzZjlMRwDYyYxu5sY+82EZebCM39rGlE1q55kUFo6OjaGtrg6enJ/z8/Mb9vr6+Hl5eXpg7d64K02kb28iNfeTFNvJiG7mxj7zYRl5sI69Tp05hw4YNOHfu3IRrhoaG4OHhgbGxMfsNRmwjMbaRG/vIi23kxTZyYx9bPAlCREREREREj214eBhHjx7FmjVrJlwzMjKC8vJyZGVl2XEyYht5sY3c2EdebCMvtpEb+9jiSRAiIiIiIiIiIiIiIpqS+GB0IiIiIiIiemwWiwU9PT3jjldWViIxMRErV65ETU2NCpMR28iLbeTGPvJiG3mxjdzYxxZPghAREREREdFjy8zMREVFhc2xffv2YdWqVejt7YVOp0NGRgaqqqpUmlC72EZebCM39pEX28iLbeTGPrZ4OywiIiIiIiJ6bJ6envjll18QFhYGADCbzQgPD8eSJUtw8uRJ6PV6VFVVYffu3Th79qzK02oL28iLbeTGPvJiG3mxjdzYxxavBCEiIiIiIqLHNjo6CoPBAAAQQiA7OxvOzs4oKSmBXq8HACxatAgdHR1qjqlJbCMvtpEb+8iLbeTFNnJjH1s8CUJERERERESPbeHChcjPz0dzczOys7PR1NSEPXv2wNfXV1nT1dUFFxcXFafUJraRF9vIjX3kxTbyYhu5sY8tR7UHICIiIiIion+PoqIiLF++HNHR0dDpdMjNzYXJZLJZU1VVBaPRqNKE2sU28mIbubGPvNhGXmwjN/axxWeCEBERERER0T8yOjqKtrY2eHp6ws/Pb9zv6+vr4eXlhblz56ownbaxjbzYRm7sIy+2kRfbyI19/osnQYiIiIiIiIiIiIiIaEriM0GIiIiIiIiIiIiIiGhK4kkQIiIiIiIiIiIiIiKakngShIiIiIiIiIiIiIiIpiSeBCEiIiIiIiIiIiIioimJJ0GIiIiIiIiIiIiIiGhK4kkQIiIiIiIiIiIiIiKakngShIiIiIiIiIiIiIiIpiSeBCEiIiIiIiIiIiIioinpP+6x/xbfM+1pAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_os_scores_f1.plot.bar(figsize=(20,10), title='F1-Score of different os models on each subject')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           E4   E4_DGAN   E4_CGAN\n",
      "S2   0.970588  0.970588  0.882353\n",
      "S3   0.823529  0.794118  0.852941\n",
      "S4   0.971429  0.971429  1.000000\n",
      "S5   1.000000  1.000000  1.000000\n",
      "S6   0.942857  0.971429  0.942857\n",
      "S7   0.942857  0.942857  0.942857\n",
      "S8   0.942857  1.000000  1.000000\n",
      "S9   1.000000  1.000000  0.971429\n",
      "S10  0.972222  0.972222  0.972222\n",
      "S11  0.805556  0.833333  0.833333\n",
      "S13  0.972222  1.000000  1.000000\n",
      "S14  0.277778  0.666667  0.055556\n",
      "S15  0.972222  0.972222  0.972222\n",
      "S16  1.000000  0.972222  0.944444\n",
      "S17  0.666667  0.638889  0.750000\n",
      "\n",
      "E4         0.884052\n",
      "E4_DGAN    0.913732\n",
      "E4_CGAN    0.874681\n",
      "dtype: float64\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Average accuracy of different models on each OS')"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# bar plot of the accuracy of the different loso models\n",
    "print(f'{df_os_scores_acc}\\n')\n",
    "print(f'{df_os_scores_acc.mean()}\\n')\n",
    "sns.barplot(x=df_os_scores_acc.keys(), y=df_os_scores_acc.mean(), palette='pastel').set_title(label='Average accuracy of different models on each OS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           E4   E4_DGAN   E4_CGAN\n",
      "S2   0.970588  0.970588  0.882353\n",
      "S3   0.805970  0.805970  0.852941\n",
      "S4   0.971429  0.971429  1.000000\n",
      "S5   1.000000  1.000000  0.985507\n",
      "S6   0.942857  0.971429  0.942857\n",
      "S7   0.942857  0.942857  0.942857\n",
      "S8   0.956522  0.970588  1.000000\n",
      "S9   1.000000  1.000000  0.971429\n",
      "S10  0.957746  0.972222  0.942857\n",
      "S11  0.788732  0.821918  0.833333\n",
      "S13  0.972222  1.000000  1.000000\n",
      "S14  0.277778  0.666667  0.055556\n",
      "S15  0.972222  0.972222  0.972222\n",
      "S16  1.000000  0.972222  0.944444\n",
      "S17  0.666667  0.657534  0.756757\n",
      "\n",
      "E4         0.881706\n",
      "E4_DGAN    0.913043\n",
      "E4_CGAN    0.872208\n",
      "dtype: float64\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'F1 score of different models on each OS')"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# bar plot of the accuracy of the different loso models\n",
    "print(f'{df_os_scores_f1}\\n')\n",
    "print(f'{df_os_scores_f1.mean()}\\n')\n",
    "sns.barplot(x=df_os_scores_f1.keys(), y=df_os_scores_f1.mean(), palette='pastel').set_title(label='F1 score of different models on each OS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_5_'></a>[Prediction](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = \"./models/E4/wesad_E4_binary_s10_100.h5\"\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "predictions = model.predict(X_test) # make predictions on the test set using the trained model\n",
    "pred_class = np.argmax(predictions, axis=-1) # get the class with the highest probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_classified = 0\n",
    "for i in range(len(pred_class)):\n",
    "    print(\"Prediction: \", predictions[i])\n",
    "    print(\"Prediction: \", pred_class[i])\n",
    "    ground_truth = max(enumerate(y_test[i]),key=lambda x: x[1])[0]\n",
    "    print(\"Ground Truth: \", ground_truth)\n",
    "    print()\n",
    "    if ground_truth == pred_class[i]:\n",
    "        true_classified += 1\n",
    "print(\"Accuracy: \", true_classified/len(pred_class))\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_6_'></a>[MISC](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 23:05:22.839499: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 4s 233ms/step - loss: 0.6605 - accuracy: 0.6090 - precision: 0.6025 - recall: 0.5965\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 1s 117ms/step - loss: 0.4759 - accuracy: 0.7794 - precision: 0.7761 - recall: 0.7644\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 65ms/step - loss: 0.3205 - accuracy: 0.8722 - precision: 0.8737 - recall: 0.8672\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.2513 - accuracy: 0.8847 - precision: 0.8850 - recall: 0.8872\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 45ms/step - loss: 0.1525 - accuracy: 0.9348 - precision: 0.9325 - recall: 0.9348\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 33ms/step - loss: 0.1141 - accuracy: 0.9574 - precision: 0.9572 - recall: 0.9524\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 0.0809 - accuracy: 0.9724 - precision: 0.9747 - recall: 0.9674\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 37ms/step - loss: 0.1555 - accuracy: 0.9424 - precision: 0.9428 - recall: 0.9499\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 32ms/step - loss: 0.0657 - accuracy: 0.9799 - precision: 0.9775 - recall: 0.9799\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0957 - accuracy: 0.9549 - precision: 0.9572 - recall: 0.9524\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 43ms/step - loss: 0.0719 - accuracy: 0.9724 - precision: 0.9700 - recall: 0.9724\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.1305 - accuracy: 0.9373 - precision: 0.9395 - recall: 0.9348\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 32ms/step - loss: 0.0623 - accuracy: 0.9749 - precision: 0.9751 - recall: 0.9825\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 0.0613 - accuracy: 0.9674 - precision: 0.9673 - recall: 0.9649\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 35ms/step - loss: 0.0554 - accuracy: 0.9799 - precision: 0.9799 - recall: 0.9799\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 0.0457 - accuracy: 0.9774 - precision: 0.9798 - recall: 0.9749\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 40ms/step - loss: 0.0455 - accuracy: 0.9900 - precision: 0.9875 - recall: 0.9875\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0621 - accuracy: 0.9774 - precision: 0.9749 - recall: 0.9749\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0616 - accuracy: 0.9774 - precision: 0.9776 - recall: 0.9825\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0859 - accuracy: 0.9749 - precision: 0.9725 - recall: 0.9749\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0503 - accuracy: 0.9825 - precision: 0.9825 - recall: 0.9825\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0517 - accuracy: 0.9850 - precision: 0.9873 - recall: 0.9749\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0473 - accuracy: 0.9850 - precision: 0.9850 - recall: 0.9850\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 32ms/step - loss: 0.0344 - accuracy: 0.9850 - precision: 0.9850 - recall: 0.9850\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.0591 - accuracy: 0.9799 - precision: 0.9799 - recall: 0.9799\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.0504 - accuracy: 0.9825 - precision: 0.9801 - recall: 0.9875\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0361 - accuracy: 0.9900 - precision: 0.9899 - recall: 0.9875\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0415 - accuracy: 0.9850 - precision: 0.9874 - recall: 0.9850\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 33ms/step - loss: 0.0327 - accuracy: 0.9900 - precision: 0.9900 - recall: 0.9900\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0401 - accuracy: 0.9875 - precision: 0.9875 - recall: 0.9875\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0714 - accuracy: 0.9799 - precision: 0.9774 - recall: 0.9749\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0490 - accuracy: 0.9850 - precision: 0.9850 - recall: 0.9850\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 35ms/step - loss: 0.0203 - accuracy: 0.9950 - precision: 0.9925 - recall: 0.9925\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0840 - accuracy: 0.9649 - precision: 0.9673 - recall: 0.9649\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0325 - accuracy: 0.9875 - precision: 0.9875 - recall: 0.9875\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 32ms/step - loss: 0.0185 - accuracy: 0.9950 - precision: 0.9975 - recall: 0.9950\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0406 - accuracy: 0.9850 - precision: 0.9850 - recall: 0.9850\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0272 - accuracy: 0.9875 - precision: 0.9875 - recall: 0.9875\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0309 - accuracy: 0.9875 - precision: 0.9900 - recall: 0.9900\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0840 - accuracy: 0.9799 - precision: 0.9799 - recall: 0.9799\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0193 - accuracy: 0.9925 - precision: 0.9925 - recall: 0.9925\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.0198 - accuracy: 0.9875 - precision: 0.9875 - recall: 0.9875\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0527 - accuracy: 0.9825 - precision: 0.9825 - recall: 0.9825\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0439 - accuracy: 0.9799 - precision: 0.9824 - recall: 0.9799\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0390 - accuracy: 0.9850 - precision: 0.9849 - recall: 0.9825\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0257 - accuracy: 0.9950 - precision: 0.9950 - recall: 0.9950\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.0179 - accuracy: 0.9925 - precision: 0.9900 - recall: 0.9925\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0396 - accuracy: 0.9875 - precision: 0.9875 - recall: 0.9875\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0310 - accuracy: 0.9825 - precision: 0.9850 - recall: 0.9875\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0201 - accuracy: 0.9925 - precision: 0.9950 - recall: 0.9900\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0405 - accuracy: 0.9875 - precision: 0.9875 - recall: 0.9875\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0305 - accuracy: 0.9825 - precision: 0.9874 - recall: 0.9850\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.0495 - accuracy: 0.9825 - precision: 0.9800 - recall: 0.9825\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.0088 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9975\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0552 - accuracy: 0.9799 - precision: 0.9800 - recall: 0.9825\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0282 - accuracy: 0.9875 - precision: 0.9875 - recall: 0.9875\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0311 - accuracy: 0.9875 - precision: 0.9875 - recall: 0.9900\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0379 - accuracy: 0.9875 - precision: 0.9874 - recall: 0.9850\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0136 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9975\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0125 - accuracy: 0.9950 - precision: 0.9950 - recall: 0.9950\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0220 - accuracy: 0.9900 - precision: 0.9900 - recall: 0.9900\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0295 - accuracy: 0.9925 - precision: 0.9925 - recall: 0.9925\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0563 - accuracy: 0.9799 - precision: 0.9774 - recall: 0.9749\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0125 - accuracy: 0.9950 - precision: 0.9950 - recall: 0.9950\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0120 - accuracy: 0.9950 - precision: 0.9950 - recall: 0.9975\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0584 - accuracy: 0.9825 - precision: 0.9825 - recall: 0.9825\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 40ms/step - loss: 0.0290 - accuracy: 0.9850 - precision: 0.9874 - recall: 0.9850\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0123 - accuracy: 0.9950 - precision: 0.9950 - recall: 0.9950\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0292 - accuracy: 0.9925 - precision: 0.9900 - recall: 0.9900\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0383 - accuracy: 0.9900 - precision: 0.9900 - recall: 0.9925\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0099 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9975\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.0154 - accuracy: 0.9950 - precision: 0.9950 - recall: 0.9950\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0296 - accuracy: 0.9850 - precision: 0.9874 - recall: 0.9850\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0276 - accuracy: 0.9900 - precision: 0.9899 - recall: 0.9875\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0268 - accuracy: 0.9900 - precision: 0.9900 - recall: 0.9900\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0281 - accuracy: 0.9900 - precision: 0.9924 - recall: 0.9875\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0380 - accuracy: 0.9875 - precision: 0.9899 - recall: 0.9875\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0230 - accuracy: 0.9925 - precision: 0.9925 - recall: 0.9900\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0104 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9975\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0127 - accuracy: 0.9950 - precision: 0.9925 - recall: 0.9950\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.0632 - accuracy: 0.9825 - precision: 0.9825 - recall: 0.9825\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0414 - accuracy: 0.9925 - precision: 0.9925 - recall: 0.9925\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0216 - accuracy: 0.9900 - precision: 0.9900 - recall: 0.9900\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0323 - accuracy: 0.9850 - precision: 0.9850 - recall: 0.9875\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0129 - accuracy: 0.9950 - precision: 0.9950 - recall: 0.9950\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 32ms/step - loss: 0.0403 - accuracy: 0.9850 - precision: 0.9850 - recall: 0.9850\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0210 - accuracy: 0.9900 - precision: 0.9875 - recall: 0.9875\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0244 - accuracy: 0.9925 - precision: 0.9925 - recall: 0.9925\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0208 - accuracy: 0.9900 - precision: 0.9900 - recall: 0.9900\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.0074 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9975\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0079 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9975\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0350 - accuracy: 0.9950 - precision: 0.9950 - recall: 0.9950\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0380 - accuracy: 0.9875 - precision: 0.9875 - recall: 0.9875\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0163 - accuracy: 0.9925 - precision: 0.9950 - recall: 0.9925\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.0050 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9975\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 0.0157 - accuracy: 0.9950 - precision: 0.9950 - recall: 0.9950\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0367 - accuracy: 0.9850 - precision: 0.9850 - recall: 0.9850\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0118 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9975\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0255 - accuracy: 0.9925 - precision: 0.9925 - recall: 0.9925\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0267 - accuracy: 0.9925 - precision: 0.9925 - recall: 0.9925\n"
     ]
    }
   ],
   "source": [
    "X_test = np.concatenate(np.array([all_subjects_X_os[x] for x in train_index], dtype=object))\n",
    "y_test = np.concatenate(np.array([all_subjects_y[y] for y in train_index], dtype=object))\n",
    "X_train = X\n",
    "y_train = y \n",
    "# X_test = all_subjects_X_os[test_index]\n",
    "# y_test = all_subjects_y[test_index]\n",
    "\n",
    "weight_balance = y_train.tolist().count(0)/y_train.tolist().count(1)\n",
    "\n",
    "X_train = np.asarray(X_train)\n",
    "X_test = np.asarray(X_test)\n",
    "y_train = np.asarray(y_train)\n",
    "y_test = np.asarray(y_test)\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_output_class)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_output_class)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = build_model(num_signals, num_output_class)\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    f\"models/syn/wesad_syn_binary_s_{num_epochs}_2000_epoch_data.h5\",  # Path to save the model file\n",
    "    monitor=\"loss\", # The metric name to monitor\n",
    "    save_best_only=True # If True, it only saves the \"best\" model according to the quantity monitored \n",
    ")\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"loss\",     # Quantity to be monitored.\n",
    "    min_delta=0.001,     # Minimum change in the monitored quantity to qualify as an improvement, i.e. an absolute change of less than min_delta, will count as no improvement.\n",
    "    patience=100,        # Number of epochs with no improvement after which training will be stopped.\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "X_train, \n",
    "y_train,\n",
    "epochs=num_epochs, \n",
    "batch_size=50,\n",
    "verbose=1,\n",
    "class_weight={0: 1, 1: weight_balance}, # to address the imbalance of the class labels\n",
    "callbacks = [checkpoint, early_stopping]\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import BatchNormalization, LayerNormalization\n",
    "\n",
    "def build_model(hp, num_signals: int = 6, num_output_class: int = 2) -> tf.keras.models.Sequential:\n",
    "    num_output_class = 2\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape=[num_signals, 210, 1]))\n",
    "    # Add conv2D layers\n",
    "    for i in range(hp.Int('num_layers', min_value=1, max_value=4)):\n",
    "        model.add(tf.keras.layers.Conv2D(\n",
    "            filters=hp.Choice(f'filters_{i}', values=[32, 64, 128]),\n",
    "            kernel_size=(1,3),\n",
    "            activation=hp.Choice(f'activation_{i}', values=['relu', 'tanh'])\n",
    "        ))\n",
    "        # Add normalization layers\n",
    "        normalization_layer = hp.Choice(f'normalization_{i}', values=['none', 'batch', 'layer'])\n",
    "        if normalization_layer == 'batch':\n",
    "            model.add(BatchNormalization())\n",
    "        elif normalization_layer == 'layer':\n",
    "            model.add(LayerNormalization())\n",
    "\n",
    "        model.add(tf.keras.layers.MaxPooling2D(pool_size=(1,2)))\n",
    "\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "    # Add dense layers\n",
    "    for i in range(hp.Int('num_dense_layers', min_value=1, max_value=4)):\n",
    "        units = hp.Int(f'units_{i}', min_value=16, max_value=128, step=16)\n",
    "        activation = hp.Choice(f'activation_dense_{i}', values=['relu', 'tanh', 'sigmoid'])\n",
    "        dropout_rate = hp.Float(f'dropout_{i}', min_value=0.1, max_value=0.5, step=0.1)\n",
    "        model.add(tf.keras.layers.Dense(units=units, activation=activation, kernel_initializer='glorot_uniform'))\n",
    "        model.add(tf.keras.layers.Dropout(rate=dropout_rate))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(tf.keras.layers.Dense(units=num_output_class, activation='sigmoid'))\n",
    "\n",
    "    # Compile model\n",
    "    optimizer = hp.Choice('optimizer', ['adam', 'rmsprop'])\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "                           tf.keras.metrics.Precision(name='precision'),\n",
    "                           tf.keras.metrics.Recall(name='recall')])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 22:35:08.411781: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYN OS: E4\n",
      "Evaluation of CNN model trained on 100 epochs\n",
      "\n",
      "Subject\t\t Accuracy\tPrecision\tRecall\t\tF1-Score\n",
      "************************************************************************\n",
      "S2\t\t 0.85294\t0.85294\t\t0.85294\t\t0.85294\n",
      "S3\t\t 0.64706\t0.64706\t\t0.64706\t\t0.64706\n",
      "S4\t\t 0.97143\t0.97143\t\t0.97143\t\t0.97143\n",
      "S5\t\t 1.00000\t1.00000\t\t1.00000\t\t1.00000\n",
      "S6\t\t 0.94286\t0.94286\t\t0.94286\t\t0.94286\n",
      "S7\t\t 0.91429\t0.91429\t\t0.91429\t\t0.91429\n",
      "S8\t\t 0.80000\t0.80000\t\t0.80000\t\t0.80000\n",
      "S9\t\t 0.97143\t0.97143\t\t0.97143\t\t0.97143\n",
      "S10\t\t 0.97222\t0.97222\t\t0.97222\t\t0.97222\n",
      "S11\t\t 0.63889\t0.63889\t\t0.63889\t\t0.63889\n",
      "S13\t\t 0.97222\t0.97222\t\t0.97222\t\t0.97222\n",
      "S14\t\t 0.72222\t0.72222\t\t0.72222\t\t0.72222\n",
      "S15\t\t 0.88889\t0.88889\t\t0.88889\t\t0.88889\n",
      "S16\t\t 0.97222\t0.97222\t\t0.97222\t\t0.97222\n",
      "S17\t\t 0.52778\t0.54286\t\t0.52778\t\t0.53521\n",
      "************************************************************************\n",
      "Average\t\t 0.85296\t0.85397\t\t0.85296\t\t0.85346\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# all_subjects_X_os = filter_for_smartwatch_os(os, all_subjects_X)\n",
    "model_path = f'models/syn/wesad_syn_binary_s_100_2000_epoch_data.h5'\n",
    "\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "all_subjects_X_os =  all_subjects_X \n",
    "all_accuracies = []\n",
    "all_precisions = []\n",
    "all_recalls = []\n",
    "all_f1s = []\n",
    "\n",
    "for i, subject_id in enumerate(subject_ids):\n",
    "    X_test = all_subjects_X_os[i]\n",
    "    y_test = all_subjects_y[i]\n",
    "    X_test = np.asarray(X_test)\n",
    "    y_test = np.asarray(y_test)\n",
    "    \n",
    "    y_test = tf.keras.utils.to_categorical(y_test, num_output_class)\n",
    "    \n",
    "\n",
    "    accuracy = model.evaluate(X_test, y_test, verbose=0, )[1]\n",
    "    precision = model.evaluate(X_test, y_test, verbose=0, )[2]\n",
    "    recall = model.evaluate(X_test, y_test, verbose=0, )[3]\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    all_accuracies.append(accuracy)\n",
    "    all_precisions.append(precision)\n",
    "    all_recalls.append(recall)\n",
    "    all_f1s.append(f1)\n",
    "\n",
    "print(f'SYN OS: {smart_os}')\n",
    "print(f'Evaluation of CNN model trained on {num_epochs} epochs\\n')\n",
    "print(f'Subject\\t\\t Accuracy\\tPrecision\\tRecall\\t\\tF1-Score')\n",
    "print(\"************************************************************************\")\n",
    "for i in range(len(all_accuracies)):\n",
    "    print(f'S{subject_ids[i]}\\t\\t {round(all_accuracies[i], 5):.5f}\\t{round(all_precisions[i], 5):.5f}\\t\\t{round(all_recalls[i], 5):.5f}\\t\\t{round(all_f1s[i], 5):.5f}')\n",
    "\n",
    "print(\"************************************************************************\")\n",
    "print(f'Average\\t\\t {round(np.mean(all_accuracies), 5):.5f}\\t{round(np.mean(all_precisions), 5):.5f}\\t\\t{round(np.mean(all_recalls), 5):.5f}\\t\\t{round(np.mean(all_f1s), 5):.5f}\\n\\n\\n')\n",
    "\n",
    "os_scores_acc[smart_os] = all_accuracies\n",
    "os_scores_f1[smart_os] = all_f1s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_os_scores_acc = pd.DataFrame(os_scores_acc)\n",
    "replacements = {l1:f'S{l2}' for l1, l2 in zip(groups_set, subject_ids)}\n",
    "df_os_scores_acc = df_os_scores_acc.rename(replacements)\n",
    "df_os_scores_acc.to_csv('os_scores_acc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: title={'center': 'Accuracy of different os models on each subject'}>"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_os_scores_acc.plot.bar(figsize=(20,10), title='Accuracy of different os models on each subject')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 23:07:39.616560: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYN OS: E4\n",
      "Evaluation of CNN model trained on 100 epochs\n",
      "\n",
      "Subject\t\t Accuracy\tPrecision\tRecall\t\tF1-Score\n",
      "************************************************************************\n",
      "S2\t\t 0.82353\t0.82353\t\t0.82353\t\t0.82353\n",
      "S3\t\t 0.67647\t0.67647\t\t0.67647\t\t0.67647\n",
      "S4\t\t 0.97143\t0.97143\t\t0.97143\t\t0.97143\n",
      "S5\t\t 1.00000\t1.00000\t\t1.00000\t\t1.00000\n",
      "S6\t\t 0.94286\t0.91667\t\t0.94286\t\t0.92958\n",
      "S7\t\t 0.97143\t0.97143\t\t0.97143\t\t0.97143\n",
      "S8\t\t 0.80000\t0.80556\t\t0.82857\t\t0.81690\n",
      "S9\t\t 0.97143\t0.97143\t\t0.97143\t\t0.97143\n",
      "S10\t\t 0.97222\t0.97222\t\t0.97222\t\t0.97222\n",
      "S11\t\t 0.66667\t0.66667\t\t0.66667\t\t0.66667\n",
      "S13\t\t 0.97222\t0.97222\t\t0.97222\t\t0.97222\n",
      "S14\t\t 0.69444\t0.67568\t\t0.69444\t\t0.68493\n",
      "S15\t\t 0.88889\t0.86486\t\t0.88889\t\t0.87671\n",
      "S16\t\t 0.97222\t0.97222\t\t0.97222\t\t0.97222\n",
      "S17\t\t 0.58333\t0.58333\t\t0.58333\t\t0.58333\n",
      "************************************************************************\n",
      "Average\t\t 0.86048\t0.85625\t\t0.86238\t\t0.85927\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: title={'center': 'Accuracy of different os models on each subject'}>"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# all_subjects_X_os = filter_for_smartwatch_os(os, all_subjects_X)\n",
    "model_path = f'models/syn/wesad_syn_binary_s_100_2000_epoch_data.h5'\n",
    "\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "all_subjects_X_os =  all_subjects_X \n",
    "all_accuracies = []\n",
    "all_precisions = []\n",
    "all_recalls = []\n",
    "all_f1s = []\n",
    "\n",
    "for i, subject_id in enumerate(subject_ids):\n",
    "    X_test = all_subjects_X_os[i]\n",
    "    y_test = all_subjects_y[i]\n",
    "    X_test = np.asarray(X_test)\n",
    "    y_test = np.asarray(y_test)\n",
    "    \n",
    "    y_test = tf.keras.utils.to_categorical(y_test, num_output_class)\n",
    "    \n",
    "\n",
    "    accuracy = model.evaluate(X_test, y_test, verbose=0, )[1]\n",
    "    precision = model.evaluate(X_test, y_test, verbose=0, )[2]\n",
    "    recall = model.evaluate(X_test, y_test, verbose=0, )[3]\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    all_accuracies.append(accuracy)\n",
    "    all_precisions.append(precision)\n",
    "    all_recalls.append(recall)\n",
    "    all_f1s.append(f1)\n",
    "\n",
    "print(f'SYN OS: {smart_os}')\n",
    "print(f'Evaluation of CNN model trained on {num_epochs} epochs\\n')\n",
    "print(f'Subject\\t\\t Accuracy\\tPrecision\\tRecall\\t\\tF1-Score')\n",
    "print(\"************************************************************************\")\n",
    "for i in range(len(all_accuracies)):\n",
    "    print(f'S{subject_ids[i]}\\t\\t {round(all_accuracies[i], 5):.5f}\\t{round(all_precisions[i], 5):.5f}\\t\\t{round(all_recalls[i], 5):.5f}\\t\\t{round(all_f1s[i], 5):.5f}')\n",
    "\n",
    "print(\"************************************************************************\")\n",
    "print(f'Average\\t\\t {round(np.mean(all_accuracies), 5):.5f}\\t{round(np.mean(all_precisions), 5):.5f}\\t\\t{round(np.mean(all_recalls), 5):.5f}\\t\\t{round(np.mean(all_f1s), 5):.5f}\\n\\n\\n')\n",
    "\n",
    "os_scores_acc[smart_os] = all_accuracies\n",
    "os_scores_f1[smart_os] = all_f1s\n",
    "\n",
    "df_os_scores_acc = pd.DataFrame(os_scores_acc)\n",
    "replacements = {l1:f'S{l2}' for l1, l2 in zip(groups_set, subject_ids)}\n",
    "df_os_scores_acc = df_os_scores_acc.rename(replacements)\n",
    "df_os_scores_acc.to_csv('os_scores_acc.csv')\n",
    "\n",
    "df_os_scores_acc.plot.bar(figsize=(20,10), title='Accuracy of different os models on each subject')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windows Shape:  (500, 60, 7)\n",
      "X Shape: (499, 6, 210)\n",
      "y Shape: (499,)\n"
     ]
    }
   ],
   "source": [
    "with open(\"/Users/nils/thesis/Data_Generation/syn_gen_data_2806.npy\", \"rb\") as f:\n",
    "    gen_data = np.load(f) \n",
    "X, y = create_preprocessed_subjects_data_gen(gen_data, fs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 13:51:50.325100: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - ETA: 0s - loss: 0.6123 - accuracy: 0.6653 - precision: 0.6612 - recall: 0.6493"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 13:51:54.823606: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 6s 261ms/step - loss: 0.6123 - accuracy: 0.6653 - precision: 0.6612 - recall: 0.6493 - val_loss: 9.7906 - val_accuracy: 0.7621 - val_precision: 0.7620 - val_recall: 0.7681\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 0.4205 - accuracy: 0.7976 - precision: 0.8037 - recall: 0.7876 - val_loss: 10.9562 - val_accuracy: 0.8387 - val_precision: 0.8404 - val_recall: 0.8387\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.3403 - accuracy: 0.8477 - precision: 0.8497 - recall: 0.8497 - val_loss: 6.7723 - val_accuracy: 0.8589 - val_precision: 0.8438 - val_recall: 0.8710\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.3232 - accuracy: 0.8477 - precision: 0.8531 - recall: 0.8497 - val_loss: 5.4760 - val_accuracy: 0.8387 - val_precision: 0.8386 - val_recall: 0.8488\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 0.3104 - accuracy: 0.8697 - precision: 0.8700 - recall: 0.8717 - val_loss: 6.8332 - val_accuracy: 0.8407 - val_precision: 0.8439 - val_recall: 0.8286\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 0.2911 - accuracy: 0.8597 - precision: 0.8591 - recall: 0.8677 - val_loss: 9.4922 - val_accuracy: 0.8690 - val_precision: 0.8690 - val_recall: 0.8690\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.2932 - accuracy: 0.8798 - precision: 0.8775 - recall: 0.8758 - val_loss: 7.7187 - val_accuracy: 0.8508 - val_precision: 0.8511 - val_recall: 0.8528\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.2946 - accuracy: 0.8677 - precision: 0.8591 - recall: 0.8677 - val_loss: 12.4515 - val_accuracy: 0.8649 - val_precision: 0.8632 - val_recall: 0.8649\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.2773 - accuracy: 0.8737 - precision: 0.8755 - recall: 0.8737 - val_loss: 9.7030 - val_accuracy: 0.8528 - val_precision: 0.8497 - val_recall: 0.8548\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 1s 63ms/step - loss: 0.2606 - accuracy: 0.9038 - precision: 0.9036 - recall: 0.9018 - val_loss: 10.0030 - val_accuracy: 0.8367 - val_precision: 0.8415 - val_recall: 0.8347\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 0.2541 - accuracy: 0.9058 - precision: 0.8986 - recall: 0.9058 - val_loss: 8.6704 - val_accuracy: 0.8448 - val_precision: 0.8403 - val_recall: 0.8488\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 0.2602 - accuracy: 0.8858 - precision: 0.8782 - recall: 0.8818 - val_loss: 12.7159 - val_accuracy: 0.8589 - val_precision: 0.8557 - val_recall: 0.8609\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 0.2473 - accuracy: 0.8998 - precision: 0.8982 - recall: 0.9018 - val_loss: 9.2699 - val_accuracy: 0.8528 - val_precision: 0.8525 - val_recall: 0.8508\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.2495 - accuracy: 0.8958 - precision: 0.8943 - recall: 0.8818 - val_loss: 12.6869 - val_accuracy: 0.8508 - val_precision: 0.8488 - val_recall: 0.8488\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.2423 - accuracy: 0.8958 - precision: 0.8980 - recall: 0.8998 - val_loss: 12.3556 - val_accuracy: 0.8488 - val_precision: 0.8396 - val_recall: 0.8548\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.2492 - accuracy: 0.8958 - precision: 0.8958 - recall: 0.8958 - val_loss: 9.3953 - val_accuracy: 0.8488 - val_precision: 0.8516 - val_recall: 0.8448\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.2250 - accuracy: 0.8938 - precision: 0.8978 - recall: 0.8978 - val_loss: 15.6041 - val_accuracy: 0.8085 - val_precision: 0.8106 - val_recall: 0.8024\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.2459 - accuracy: 0.9018 - precision: 0.9026 - recall: 0.9098 - val_loss: 13.8575 - val_accuracy: 0.8427 - val_precision: 0.8431 - val_recall: 0.8448\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.2397 - accuracy: 0.9038 - precision: 0.8994 - recall: 0.8958 - val_loss: 12.0162 - val_accuracy: 0.8488 - val_precision: 0.8496 - val_recall: 0.8427\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.2297 - accuracy: 0.9038 - precision: 0.9054 - recall: 0.9018 - val_loss: 11.5908 - val_accuracy: 0.8508 - val_precision: 0.8508 - val_recall: 0.8508\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.2078 - accuracy: 0.9178 - precision: 0.9163 - recall: 0.9218 - val_loss: 16.7525 - val_accuracy: 0.8508 - val_precision: 0.8491 - val_recall: 0.8508\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.2482 - accuracy: 0.9058 - precision: 0.9000 - recall: 0.9018 - val_loss: 13.4675 - val_accuracy: 0.8508 - val_precision: 0.8494 - val_recall: 0.8528\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.2120 - accuracy: 0.9218 - precision: 0.9202 - recall: 0.9238 - val_loss: 13.2917 - val_accuracy: 0.8448 - val_precision: 0.8407 - val_recall: 0.8407\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.2123 - accuracy: 0.9138 - precision: 0.9153 - recall: 0.9098 - val_loss: 13.1420 - val_accuracy: 0.8448 - val_precision: 0.8448 - val_recall: 0.8448\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.2156 - accuracy: 0.9118 - precision: 0.9178 - recall: 0.9178 - val_loss: 17.2812 - val_accuracy: 0.8468 - val_precision: 0.8468 - val_recall: 0.8468\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.2165 - accuracy: 0.9178 - precision: 0.9214 - recall: 0.9158 - val_loss: 16.0899 - val_accuracy: 0.8387 - val_precision: 0.8380 - val_recall: 0.8448\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.2220 - accuracy: 0.9078 - precision: 0.9102 - recall: 0.9138 - val_loss: 15.9553 - val_accuracy: 0.8246 - val_precision: 0.8279 - val_recall: 0.8246\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.2066 - accuracy: 0.9138 - precision: 0.9160 - recall: 0.9178 - val_loss: 16.6960 - val_accuracy: 0.8367 - val_precision: 0.8435 - val_recall: 0.8367\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.2152 - accuracy: 0.9158 - precision: 0.9172 - recall: 0.9098 - val_loss: 16.1516 - val_accuracy: 0.8387 - val_precision: 0.8370 - val_recall: 0.8387\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.2222 - accuracy: 0.9238 - precision: 0.9222 - recall: 0.9259 - val_loss: 16.4759 - val_accuracy: 0.8327 - val_precision: 0.8367 - val_recall: 0.8266\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.1846 - accuracy: 0.9259 - precision: 0.9259 - recall: 0.9259 - val_loss: 21.2896 - val_accuracy: 0.8286 - val_precision: 0.8303 - val_recall: 0.8286\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.1884 - accuracy: 0.9238 - precision: 0.9218 - recall: 0.9218 - val_loss: 17.6724 - val_accuracy: 0.8266 - val_precision: 0.8246 - val_recall: 0.8246\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.1878 - accuracy: 0.9279 - precision: 0.9280 - recall: 0.9299 - val_loss: 24.2196 - val_accuracy: 0.8367 - val_precision: 0.8367 - val_recall: 0.8367\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.1792 - accuracy: 0.9218 - precision: 0.9240 - recall: 0.9259 - val_loss: 21.5036 - val_accuracy: 0.8286 - val_precision: 0.8266 - val_recall: 0.8266\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.1791 - accuracy: 0.9299 - precision: 0.9352 - recall: 0.9259 - val_loss: 24.2558 - val_accuracy: 0.8185 - val_precision: 0.8164 - val_recall: 0.8246\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.1947 - accuracy: 0.9238 - precision: 0.9293 - recall: 0.9218 - val_loss: 25.9750 - val_accuracy: 0.8206 - val_precision: 0.8184 - val_recall: 0.8266\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 0.1720 - accuracy: 0.9399 - precision: 0.9340 - recall: 0.9359 - val_loss: 25.6317 - val_accuracy: 0.8226 - val_precision: 0.8229 - val_recall: 0.8246\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.1877 - accuracy: 0.9299 - precision: 0.9335 - recall: 0.9279 - val_loss: 29.5907 - val_accuracy: 0.8266 - val_precision: 0.8249 - val_recall: 0.8266\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.1954 - accuracy: 0.9279 - precision: 0.9225 - recall: 0.9299 - val_loss: 25.2251 - val_accuracy: 0.8226 - val_precision: 0.8226 - val_recall: 0.8226\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.1713 - accuracy: 0.9339 - precision: 0.9320 - recall: 0.9339 - val_loss: 25.4700 - val_accuracy: 0.8085 - val_precision: 0.8109 - val_recall: 0.8125\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.1807 - accuracy: 0.9379 - precision: 0.9396 - recall: 0.9359 - val_loss: 30.2380 - val_accuracy: 0.8206 - val_precision: 0.8196 - val_recall: 0.8246\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.1950 - accuracy: 0.9238 - precision: 0.9277 - recall: 0.9259 - val_loss: 25.3442 - val_accuracy: 0.7964 - val_precision: 0.7972 - val_recall: 0.8004\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.1796 - accuracy: 0.9299 - precision: 0.9356 - recall: 0.9319 - val_loss: 35.4200 - val_accuracy: 0.8206 - val_precision: 0.8131 - val_recall: 0.8246\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.1731 - accuracy: 0.9279 - precision: 0.9317 - recall: 0.9299 - val_loss: 29.9397 - val_accuracy: 0.8125 - val_precision: 0.8064 - val_recall: 0.8145\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.2014 - accuracy: 0.9259 - precision: 0.9259 - recall: 0.9259 - val_loss: 29.5684 - val_accuracy: 0.8044 - val_precision: 0.7996 - val_recall: 0.8044\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.1646 - accuracy: 0.9359 - precision: 0.9319 - recall: 0.9319 - val_loss: 35.9340 - val_accuracy: 0.8165 - val_precision: 0.8156 - val_recall: 0.8206\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.1642 - accuracy: 0.9399 - precision: 0.9396 - recall: 0.9359 - val_loss: 38.9888 - val_accuracy: 0.8206 - val_precision: 0.8180 - val_recall: 0.8246\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.1790 - accuracy: 0.9359 - precision: 0.9341 - recall: 0.9379 - val_loss: 46.0794 - val_accuracy: 0.8226 - val_precision: 0.8209 - val_recall: 0.8226\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.1860 - accuracy: 0.9339 - precision: 0.9340 - recall: 0.9359 - val_loss: 30.2142 - val_accuracy: 0.8085 - val_precision: 0.8100 - val_recall: 0.8165\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 0.1591 - accuracy: 0.9479 - precision: 0.9480 - recall: 0.9499 - val_loss: 36.4780 - val_accuracy: 0.8145 - val_precision: 0.8099 - val_recall: 0.8246\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.1688 - accuracy: 0.9339 - precision: 0.9321 - recall: 0.9359 - val_loss: 36.6693 - val_accuracy: 0.8125 - val_precision: 0.8072 - val_recall: 0.8185\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.1858 - accuracy: 0.9319 - precision: 0.9317 - recall: 0.9299 - val_loss: 34.9682 - val_accuracy: 0.8105 - val_precision: 0.8020 - val_recall: 0.8165\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.1591 - accuracy: 0.9359 - precision: 0.9320 - recall: 0.9339 - val_loss: 36.0116 - val_accuracy: 0.8105 - val_precision: 0.8095 - val_recall: 0.8226\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.1555 - accuracy: 0.9439 - precision: 0.9419 - recall: 0.9419 - val_loss: 37.7915 - val_accuracy: 0.8044 - val_precision: 0.8052 - val_recall: 0.8165\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.1653 - accuracy: 0.9279 - precision: 0.9296 - recall: 0.9259 - val_loss: 36.2703 - val_accuracy: 0.8044 - val_precision: 0.7964 - val_recall: 0.8125\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.1678 - accuracy: 0.9379 - precision: 0.9380 - recall: 0.9399 - val_loss: 35.6721 - val_accuracy: 0.8145 - val_precision: 0.8088 - val_recall: 0.8185\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.1769 - accuracy: 0.9439 - precision: 0.9360 - recall: 0.9379 - val_loss: 35.4642 - val_accuracy: 0.8024 - val_precision: 0.7976 - val_recall: 0.8024\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.1638 - accuracy: 0.9359 - precision: 0.9340 - recall: 0.9359 - val_loss: 37.1620 - val_accuracy: 0.8065 - val_precision: 0.7980 - val_recall: 0.8125\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.1692 - accuracy: 0.9339 - precision: 0.9434 - recall: 0.9359 - val_loss: 36.5183 - val_accuracy: 0.8206 - val_precision: 0.8110 - val_recall: 0.8306\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 0.1494 - accuracy: 0.9419 - precision: 0.9477 - recall: 0.9439 - val_loss: 46.1440 - val_accuracy: 0.8165 - val_precision: 0.8144 - val_recall: 0.8226\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.1493 - accuracy: 0.9379 - precision: 0.9356 - recall: 0.9319 - val_loss: 43.3187 - val_accuracy: 0.8145 - val_precision: 0.8111 - val_recall: 0.8226\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.1926 - accuracy: 0.9259 - precision: 0.9299 - recall: 0.9299 - val_loss: 38.5853 - val_accuracy: 0.8165 - val_precision: 0.8135 - val_recall: 0.8266\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 0.1493 - accuracy: 0.9519 - precision: 0.9500 - recall: 0.9519 - val_loss: 42.8965 - val_accuracy: 0.8165 - val_precision: 0.8160 - val_recall: 0.8226\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.1686 - accuracy: 0.9419 - precision: 0.9418 - recall: 0.9399 - val_loss: 44.8040 - val_accuracy: 0.8145 - val_precision: 0.8071 - val_recall: 0.8266\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.1581 - accuracy: 0.9379 - precision: 0.9395 - recall: 0.9339 - val_loss: 46.1199 - val_accuracy: 0.8246 - val_precision: 0.8240 - val_recall: 0.8306\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.1432 - accuracy: 0.9479 - precision: 0.9498 - recall: 0.9479 - val_loss: 42.7602 - val_accuracy: 0.8226 - val_precision: 0.8213 - val_recall: 0.8246\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.1519 - accuracy: 0.9399 - precision: 0.9438 - recall: 0.9419 - val_loss: 40.9718 - val_accuracy: 0.8206 - val_precision: 0.8209 - val_recall: 0.8226\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.1748 - accuracy: 0.9399 - precision: 0.9414 - recall: 0.9339 - val_loss: 43.2024 - val_accuracy: 0.8266 - val_precision: 0.8253 - val_recall: 0.8286\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.1584 - accuracy: 0.9379 - precision: 0.9378 - recall: 0.9359 - val_loss: 52.3513 - val_accuracy: 0.8206 - val_precision: 0.8209 - val_recall: 0.8226\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.1549 - accuracy: 0.9379 - precision: 0.9437 - recall: 0.9399 - val_loss: 49.7466 - val_accuracy: 0.8266 - val_precision: 0.8153 - val_recall: 0.8367\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.1492 - accuracy: 0.9479 - precision: 0.9478 - recall: 0.9459 - val_loss: 50.7291 - val_accuracy: 0.8226 - val_precision: 0.8171 - val_recall: 0.8286\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.1549 - accuracy: 0.9379 - precision: 0.9398 - recall: 0.9379 - val_loss: 42.5499 - val_accuracy: 0.8065 - val_precision: 0.8008 - val_recall: 0.8105\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.1532 - accuracy: 0.9359 - precision: 0.9378 - recall: 0.9359 - val_loss: 42.1516 - val_accuracy: 0.8105 - val_precision: 0.8064 - val_recall: 0.8145\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.1484 - accuracy: 0.9439 - precision: 0.9439 - recall: 0.9439 - val_loss: 45.5054 - val_accuracy: 0.8286 - val_precision: 0.8277 - val_recall: 0.8327\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.1441 - accuracy: 0.9559 - precision: 0.9577 - recall: 0.9539 - val_loss: 46.5843 - val_accuracy: 0.8165 - val_precision: 0.8116 - val_recall: 0.8165\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.1584 - accuracy: 0.9419 - precision: 0.9419 - recall: 0.9419 - val_loss: 44.0993 - val_accuracy: 0.8266 - val_precision: 0.8187 - val_recall: 0.8286\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.1566 - accuracy: 0.9479 - precision: 0.9517 - recall: 0.9479 - val_loss: 42.5093 - val_accuracy: 0.8246 - val_precision: 0.8200 - val_recall: 0.8266\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.1378 - accuracy: 0.9559 - precision: 0.9579 - recall: 0.9579 - val_loss: 54.0044 - val_accuracy: 0.8125 - val_precision: 0.8125 - val_recall: 0.8125\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.1449 - accuracy: 0.9499 - precision: 0.9441 - recall: 0.9479 - val_loss: 50.6673 - val_accuracy: 0.8165 - val_precision: 0.8108 - val_recall: 0.8206\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.1631 - accuracy: 0.9399 - precision: 0.9399 - recall: 0.9399 - val_loss: 53.1120 - val_accuracy: 0.8206 - val_precision: 0.8200 - val_recall: 0.8266\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.1525 - accuracy: 0.9479 - precision: 0.9497 - recall: 0.9459 - val_loss: 52.4971 - val_accuracy: 0.8105 - val_precision: 0.8075 - val_recall: 0.8206\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.1385 - accuracy: 0.9499 - precision: 0.9480 - recall: 0.9499 - val_loss: 52.8388 - val_accuracy: 0.8085 - val_precision: 0.8008 - val_recall: 0.8105\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.1483 - accuracy: 0.9439 - precision: 0.9419 - recall: 0.9419 - val_loss: 55.2298 - val_accuracy: 0.8266 - val_precision: 0.8249 - val_recall: 0.8266\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.1630 - accuracy: 0.9399 - precision: 0.9415 - recall: 0.9359 - val_loss: 52.4706 - val_accuracy: 0.8185 - val_precision: 0.8140 - val_recall: 0.8206\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 0.1356 - accuracy: 0.9419 - precision: 0.9419 - recall: 0.9419 - val_loss: 55.4808 - val_accuracy: 0.8125 - val_precision: 0.8136 - val_recall: 0.8185\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.1423 - accuracy: 0.9479 - precision: 0.9479 - recall: 0.9479 - val_loss: 64.9416 - val_accuracy: 0.8206 - val_precision: 0.8160 - val_recall: 0.8226\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.1450 - accuracy: 0.9499 - precision: 0.9479 - recall: 0.9479 - val_loss: 62.1772 - val_accuracy: 0.8004 - val_precision: 0.7925 - val_recall: 0.8085\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.1428 - accuracy: 0.9519 - precision: 0.9482 - recall: 0.9539 - val_loss: 55.1429 - val_accuracy: 0.8065 - val_precision: 0.8024 - val_recall: 0.8105\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 0.1211 - accuracy: 0.9519 - precision: 0.9537 - recall: 0.9499 - val_loss: 64.6250 - val_accuracy: 0.8165 - val_precision: 0.8140 - val_recall: 0.8206\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.1411 - accuracy: 0.9499 - precision: 0.9499 - recall: 0.9499 - val_loss: 72.4681 - val_accuracy: 0.8165 - val_precision: 0.8169 - val_recall: 0.8185\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.1448 - accuracy: 0.9519 - precision: 0.9481 - recall: 0.9519 - val_loss: 60.2990 - val_accuracy: 0.8044 - val_precision: 0.8044 - val_recall: 0.8044\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.1449 - accuracy: 0.9439 - precision: 0.9422 - recall: 0.9479 - val_loss: 57.8587 - val_accuracy: 0.8085 - val_precision: 0.8072 - val_recall: 0.8105\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.1238 - accuracy: 0.9599 - precision: 0.9621 - recall: 0.9659 - val_loss: 66.5328 - val_accuracy: 0.8105 - val_precision: 0.8116 - val_recall: 0.8165\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.1324 - accuracy: 0.9399 - precision: 0.9437 - recall: 0.9399 - val_loss: 75.7565 - val_accuracy: 0.8165 - val_precision: 0.8115 - val_recall: 0.8246\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.1466 - accuracy: 0.9459 - precision: 0.9421 - recall: 0.9459 - val_loss: 61.1172 - val_accuracy: 0.8125 - val_precision: 0.8112 - val_recall: 0.8145\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.1494 - accuracy: 0.9439 - precision: 0.9440 - recall: 0.9459 - val_loss: 64.5354 - val_accuracy: 0.8185 - val_precision: 0.8136 - val_recall: 0.8185\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.1450 - accuracy: 0.9459 - precision: 0.9459 - recall: 0.9459 - val_loss: 59.8223 - val_accuracy: 0.8185 - val_precision: 0.8136 - val_recall: 0.8185\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.1352 - accuracy: 0.9519 - precision: 0.9519 - recall: 0.9519 - val_loss: 60.2750 - val_accuracy: 0.8004 - val_precision: 0.8028 - val_recall: 0.8044\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.1309 - accuracy: 0.9519 - precision: 0.9520 - recall: 0.9539 - val_loss: 69.9288 - val_accuracy: 0.8165 - val_precision: 0.8147 - val_recall: 0.8246\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.1458 - accuracy: 0.9419 - precision: 0.9416 - recall: 0.9379 - val_loss: 67.5353 - val_accuracy: 0.8185 - val_precision: 0.8124 - val_recall: 0.8206\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "X_test = np.concatenate(np.array([all_subjects_X_os[x] for x in train_index], dtype=object))\n",
    "y_test = np.concatenate(np.array([all_subjects_y[y] for y in train_index], dtype=object))\n",
    "X_train = X\n",
    "y_train = y \n",
    "# X_test = all_subjects_X_os[test_index]\n",
    "# y_test = all_subjects_y[test_index]\n",
    "\n",
    "weight_balance = y_train.tolist().count(0)/y_train.tolist().count(1)\n",
    "\n",
    "X_train = np.asarray(X_train)\n",
    "X_test = np.asarray(X_test)\n",
    "y_train = np.asarray(y_train)\n",
    "y_test = np.asarray(y_test)\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_output_class)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_output_class)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = build_model(num_signals, num_output_class)\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    f\"models/syn/wesad_syn_binary_s_{num_epochs}_2806_epoch_data.h5\",  # Path to save the model file\n",
    "    monitor=\"loss\", # The metric name to monitor\n",
    "    save_best_only=True # If True, it only saves the \"best\" model according to the quantity monitored \n",
    ")\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", # Quantity to be monitored.\n",
    "    patience=5,\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "X_train, \n",
    "y_train,\n",
    "epochs=num_epochs, \n",
    "batch_size=32,\n",
    "verbose=1,\n",
    "class_weight={0: 1, 1: weight_balance}, # to address the imbalance of the class labels\n",
    "callbacks = [checkpoint, early_stopping],\n",
    "validation_data=(X_test, y_test)\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 10:21:27.826194: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYN OS: E4\n",
      "Evaluation of CNN model trained on 1000 epochs\n",
      "\n",
      "Subject\t\t Accuracy\tPrecision\tRecall\t\tF1-Score\n",
      "************************************************************************\n",
      "S2\t\t 0.79412\t0.79412\t\t0.79412\t\t0.79412\n",
      "S3\t\t 0.73529\t0.73529\t\t0.73529\t\t0.73529\n",
      "S4\t\t 0.88571\t0.88571\t\t0.88571\t\t0.88571\n",
      "S5\t\t 0.94286\t0.94286\t\t0.94286\t\t0.94286\n",
      "S6\t\t 0.91429\t0.91176\t\t0.88571\t\t0.89855\n",
      "S7\t\t 0.88571\t0.88571\t\t0.88571\t\t0.88571\n",
      "S8\t\t 0.82857\t0.82857\t\t0.82857\t\t0.82857\n",
      "S9\t\t 0.77143\t0.77143\t\t0.77143\t\t0.77143\n",
      "S10\t\t 0.94444\t0.94444\t\t0.94444\t\t0.94444\n",
      "S11\t\t 0.58333\t0.58333\t\t0.58333\t\t0.58333\n",
      "S13\t\t 0.94444\t0.94444\t\t0.94444\t\t0.94444\n",
      "S14\t\t 0.66667\t0.66667\t\t0.66667\t\t0.66667\n",
      "S15\t\t 0.91667\t0.91667\t\t0.91667\t\t0.91667\n",
      "S16\t\t 0.88889\t0.88889\t\t0.88889\t\t0.88889\n",
      "S17\t\t 0.63889\t0.63889\t\t0.63889\t\t0.63889\n",
      "************************************************************************\n",
      "Average\t\t 0.82275\t0.82259\t\t0.82085\t\t0.82171\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: title={'center': 'Accuracy of different os models on each subject'}>"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# all_subjects_X_os = filter_for_smartwatch_os(os, all_subjects_X)\n",
    "# num_epochs = 10\n",
    "model_path = f'models/syn/wesad_syn_binary_s_{num_epochs}_2806_epoch_data.h5'\n",
    "\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "all_subjects_X_os =  all_subjects_X \n",
    "all_accuracies = []\n",
    "all_precisions = []\n",
    "all_recalls = []\n",
    "all_f1s = []\n",
    "\n",
    "for i, subject_id in enumerate(subject_ids):\n",
    "    X_test = all_subjects_X_os[i]\n",
    "    y_test = all_subjects_y[i]\n",
    "    X_test = np.asarray(X_test)\n",
    "    y_test = np.asarray(y_test)\n",
    "    \n",
    "    y_test = tf.keras.utils.to_categorical(y_test, num_output_class)\n",
    "    \n",
    "\n",
    "    accuracy = model.evaluate(X_test, y_test, verbose=0, )[1]\n",
    "    precision = model.evaluate(X_test, y_test, verbose=0, )[2]\n",
    "    recall = model.evaluate(X_test, y_test, verbose=0, )[3]\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    all_accuracies.append(accuracy)\n",
    "    all_precisions.append(precision)\n",
    "    all_recalls.append(recall)\n",
    "    all_f1s.append(f1)\n",
    "\n",
    "print(f'SYN OS: {smart_os}')\n",
    "print(f'Evaluation of CNN model trained on {num_epochs} epochs\\n')\n",
    "print(f'Subject\\t\\t Accuracy\\tPrecision\\tRecall\\t\\tF1-Score')\n",
    "print(\"************************************************************************\")\n",
    "for i in range(len(all_accuracies)):\n",
    "    print(f'S{subject_ids[i]}\\t\\t {round(all_accuracies[i], 5):.5f}\\t{round(all_precisions[i], 5):.5f}\\t\\t{round(all_recalls[i], 5):.5f}\\t\\t{round(all_f1s[i], 5):.5f}')\n",
    "\n",
    "print(\"************************************************************************\")\n",
    "print(f'Average\\t\\t {round(np.mean(all_accuracies), 5):.5f}\\t{round(np.mean(all_precisions), 5):.5f}\\t\\t{round(np.mean(all_recalls), 5):.5f}\\t\\t{round(np.mean(all_f1s), 5):.5f}\\n\\n\\n')\n",
    "\n",
    "os_scores_acc[smart_os] = all_accuracies\n",
    "os_scores_f1[smart_os] = all_f1s\n",
    "\n",
    "df_os_scores_acc = pd.DataFrame(os_scores_acc)\n",
    "replacements = {l1:f'S{l2}' for l1, l2 in zip(groups_set, subject_ids)}\n",
    "df_os_scores_acc = df_os_scores_acc.rename(replacements)\n",
    "df_os_scores_acc.to_csv('os_scores_acc.csv')\n",
    "\n",
    "df_os_scores_acc.plot.bar(figsize=(20,10), title='Accuracy of different os models on each subject')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 11:54:34.599101: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 11:54:38.488606: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 11:54:42.010100: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 11:54:46.005435: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 11:54:49.827045: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 11:54:53.504377: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 11:54:57.655700: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 11:55:01.233975: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 11:55:04.463226: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 11:55:08.457996: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 11:55:12.120138: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 11:55:15.914885: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 11:55:19.781296: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 11:55:23.006958: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 11:55:26.501945: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smartwatch OS: E4\n",
      "Evaluation of CNN model trained on 100 epochs\n",
      "\n",
      "Subject\t\t Accuracy\tPrecision\tRecall\t\tF1-Score\n",
      "************************************************************************\n",
      "S2\t\t 0.97059\t0.97059\t\t0.97059\t\t0.97059\n",
      "S3\t\t 0.79412\t0.81818\t\t0.79412\t\t0.80597\n",
      "S4\t\t 0.97143\t0.97143\t\t0.97143\t\t0.97143\n",
      "S5\t\t 1.00000\t1.00000\t\t1.00000\t\t1.00000\n",
      "S6\t\t 0.97143\t0.97143\t\t0.97143\t\t0.97143\n",
      "S7\t\t 0.94286\t0.94286\t\t0.94286\t\t0.94286\n",
      "S8\t\t 1.00000\t1.00000\t\t0.94286\t\t0.97059\n",
      "S9\t\t 1.00000\t1.00000\t\t1.00000\t\t1.00000\n",
      "S10\t\t 0.97222\t0.97222\t\t0.97222\t\t0.97222\n",
      "S11\t\t 0.83333\t0.81081\t\t0.83333\t\t0.82192\n",
      "S13\t\t 1.00000\t1.00000\t\t1.00000\t\t1.00000\n",
      "S14\t\t 0.66667\t0.66667\t\t0.66667\t\t0.66667\n",
      "S15\t\t 0.97222\t0.97222\t\t0.97222\t\t0.97222\n",
      "S16\t\t 0.97222\t0.97222\t\t0.97222\t\t0.97222\n",
      "S17\t\t 0.63889\t0.64865\t\t0.66667\t\t0.65753\n",
      "************************************************************************\n",
      "Average\t\t 0.91373\t0.91449\t\t0.91177\t\t0.91304\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluating every models on the corresponding test dataset not seen during training.\n",
    "os_scores_acc = {}\n",
    "os_scores_f1 = {}\n",
    "\n",
    "for smart_os, signals in SMARTWATCH_OS.items():\n",
    "\n",
    "    # all_subjects_X_os = filter_for_smartwatch_os(os, all_subjects_X)\n",
    "\n",
    "    all_subjects_X_os =  all_subjects_X \n",
    "    all_accuracies = []\n",
    "    all_precisions = []\n",
    "    all_recalls = []\n",
    "    all_f1s = []\n",
    "\n",
    "    for i, subject_id in enumerate(subject_ids):\n",
    "        X_test = all_subjects_X_os[i]\n",
    "        y_test = all_subjects_y[i]\n",
    "        X_test = np.asarray(X_test)\n",
    "        y_test = np.asarray(y_test)\n",
    "        \n",
    "        y_test = tf.keras.utils.to_categorical(y_test, num_output_class)\n",
    "        \n",
    "        \n",
    "        model_path = f'models/stress_detector/syn/dgan_30000/{num_epochs}/wesad_30000_s{subject_id}.h5'\n",
    "\n",
    "        model = tf.keras.models.load_model(model_path)\n",
    "        accuracy = model.evaluate(X_test, y_test, verbose=0, )[1]\n",
    "        precision = model.evaluate(X_test, y_test, verbose=0, )[2]\n",
    "        recall = model.evaluate(X_test, y_test, verbose=0, )[3]\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "        all_accuracies.append(accuracy)\n",
    "        all_precisions.append(precision)\n",
    "        all_recalls.append(recall)\n",
    "        all_f1s.append(f1)\n",
    "\n",
    "    print(f'Smartwatch OS: {smart_os}')\n",
    "    print(f'Evaluation of CNN model trained on {num_epochs} epochs\\n')\n",
    "    print(f'Subject\\t\\t Accuracy\\tPrecision\\tRecall\\t\\tF1-Score')\n",
    "    print(\"************************************************************************\")\n",
    "    for i in range(len(all_accuracies)):\n",
    "        print(f'S{subject_ids[i]}\\t\\t {round(all_accuracies[i], 5):.5f}\\t{round(all_precisions[i], 5):.5f}\\t\\t{round(all_recalls[i], 5):.5f}\\t\\t{round(all_f1s[i], 5):.5f}')\n",
    "\n",
    "    print(\"************************************************************************\")\n",
    "    print(f'Average\\t\\t {round(np.mean(all_accuracies), 5):.5f}\\t{round(np.mean(all_precisions), 5):.5f}\\t\\t{round(np.mean(all_recalls), 5):.5f}\\t\\t{round(np.mean(all_f1s), 5):.5f}\\n\\n\\n')\n",
    "\n",
    "    os_scores_acc[smart_os] = all_accuracies\n",
    "    os_scores_f1[smart_os] = all_f1s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Training with synthetic data](#toc0_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Try to load data from disk ***\n",
      "\n",
      "Windows Shape:  (36, 60, 7)\n",
      "X Shape: (35, 6, 210)\n",
      "y Shape: (35,)\n"
     ]
    }
   ],
   "source": [
    "all_subjects_X, all_subjects_y = load_data(DataType.REAL, 1, synthetic_data_path=SYNTHETIC_DATA_PATH)\n",
    "\n",
    "DATA_PATH = \"data/syn/cond_syn_gen.npy\"\n",
    "with open(DATA_PATH, \"rb\") as f:\n",
    "    gen_data = np.load(f) \n",
    "X, y = create_preprocessed_subjects_data_gen(gen_data, fs=1)\n",
    "\n",
    "all_subjects_X.append(X)\n",
    "all_subjects_y.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "SmartwatchOS: E4\n",
      "DataType: DataType.CGAN\n",
      "Signals: ACC_x ACC_y ACC_z TEMP EDA BVP\n",
      "Number of signals: 6\n",
      "Train on: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "Test  on: 0\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 20:15:08.418958: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - ETA: 0s - loss: 0.9590 - accuracy: 0.6384 - precision: 0.6208 - recall: 0.6535"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 20:15:46.208328: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 42s 3s/step - loss: 0.9590 - accuracy: 0.6384 - precision: 0.6208 - recall: 0.6535 - val_loss: 0.4995 - val_accuracy: 0.8235 - val_precision: 0.8125 - val_recall: 0.7647\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 13s 961ms/step - loss: 0.8090 - accuracy: 0.7345 - precision: 0.7255 - recall: 0.7119 - val_loss: 0.4587 - val_accuracy: 0.8235 - val_precision: 0.9259 - val_recall: 0.7353\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 239ms/step - loss: 0.7366 - accuracy: 0.7684 - precision: 0.7723 - recall: 0.7665 - val_loss: 0.3546 - val_accuracy: 0.8235 - val_precision: 0.8485 - val_recall: 0.8235\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 189ms/step - loss: 0.6955 - accuracy: 0.8004 - precision: 0.8083 - recall: 0.8023 - val_loss: 0.3358 - val_accuracy: 0.8235 - val_precision: 0.8485 - val_recall: 0.8235\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 1s 133ms/step - loss: 0.6488 - accuracy: 0.8173 - precision: 0.8112 - recall: 0.8173 - val_loss: 0.3568 - val_accuracy: 0.8529 - val_precision: 0.8529 - val_recall: 0.8529\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 175ms/step - loss: 0.6333 - accuracy: 0.8230 - precision: 0.8185 - recall: 0.8324 - val_loss: 0.3865 - val_accuracy: 0.8529 - val_precision: 0.9062 - val_recall: 0.8529\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 247ms/step - loss: 0.5995 - accuracy: 0.8362 - precision: 0.8365 - recall: 0.8380 - val_loss: 0.5024 - val_accuracy: 0.8824 - val_precision: 0.8750 - val_recall: 0.8235\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 4s 435ms/step - loss: 0.6030 - accuracy: 0.8456 - precision: 0.8482 - recall: 0.8418 - val_loss: 0.3364 - val_accuracy: 0.8529 - val_precision: 0.8788 - val_recall: 0.8529\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 1s 138ms/step - loss: 0.5783 - accuracy: 0.8456 - precision: 0.8401 - recall: 0.8512 - val_loss: 0.3239 - val_accuracy: 0.8529 - val_precision: 0.8529 - val_recall: 0.8529\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.5558 - accuracy: 0.8437 - precision: 0.8431 - recall: 0.8399 - val_loss: 0.5506 - val_accuracy: 0.8235 - val_precision: 0.8333 - val_recall: 0.8824\n",
      "Train on: [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "Test  on: 1\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 20:16:22.338505: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - ETA: 0s - loss: 0.9659 - accuracy: 0.6610 - precision: 0.6323 - recall: 0.6930"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 20:17:04.179704: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 46s 3s/step - loss: 0.9659 - accuracy: 0.6610 - precision: 0.6323 - recall: 0.6930 - val_loss: 0.6214 - val_accuracy: 0.6765 - val_precision: 0.6667 - val_recall: 0.6471\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 4s 416ms/step - loss: 0.8188 - accuracy: 0.7269 - precision: 0.7295 - recall: 0.7213 - val_loss: 0.7162 - val_accuracy: 0.6176 - val_precision: 0.5714 - val_recall: 0.4706\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 3s 309ms/step - loss: 0.7172 - accuracy: 0.7778 - precision: 0.7761 - recall: 0.7571 - val_loss: 0.6334 - val_accuracy: 0.6765 - val_precision: 0.6765 - val_recall: 0.6765\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 4s 382ms/step - loss: 0.6064 - accuracy: 0.8230 - precision: 0.8245 - recall: 0.8230 - val_loss: 0.5207 - val_accuracy: 0.7353 - val_precision: 0.7353 - val_recall: 0.7353\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 189ms/step - loss: 0.5409 - accuracy: 0.8324 - precision: 0.8381 - recall: 0.8286 - val_loss: 0.6371 - val_accuracy: 0.7941 - val_precision: 0.7742 - val_recall: 0.7059\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 1s 142ms/step - loss: 0.5903 - accuracy: 0.8211 - precision: 0.8273 - recall: 0.8211 - val_loss: 0.5742 - val_accuracy: 0.7059 - val_precision: 0.7059 - val_recall: 0.7059\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 150ms/step - loss: 0.6006 - accuracy: 0.8324 - precision: 0.8296 - recall: 0.8343 - val_loss: 0.5210 - val_accuracy: 0.7059 - val_precision: 0.7059 - val_recall: 0.7059\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 0s 42ms/step - loss: 0.5416 - accuracy: 0.8606 - precision: 0.8664 - recall: 0.8550 - val_loss: 0.5185 - val_accuracy: 0.7353 - val_precision: 0.7353 - val_recall: 0.7353\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 245ms/step - loss: 0.5615 - accuracy: 0.8475 - precision: 0.8496 - recall: 0.8512 - val_loss: 0.5086 - val_accuracy: 0.7353 - val_precision: 0.7353 - val_recall: 0.7353\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 1s 118ms/step - loss: 0.5717 - accuracy: 0.8606 - precision: 0.8617 - recall: 0.8569 - val_loss: 0.5405 - val_accuracy: 0.7059 - val_precision: 0.6857 - val_recall: 0.7059\n",
      "Train on: [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "Test  on: 2\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 20:17:30.079110: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - ETA: 0s - loss: 0.9631 - accuracy: 0.6151 - precision: 0.6192 - recall: 0.6321"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 20:18:11.812923: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 46s 3s/step - loss: 0.9631 - accuracy: 0.6151 - precision: 0.6192 - recall: 0.6321 - val_loss: 0.5849 - val_accuracy: 0.9714 - val_precision: 0.9722 - val_recall: 1.0000\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 8s 666ms/step - loss: 0.8294 - accuracy: 0.7226 - precision: 0.7218 - recall: 0.7000 - val_loss: 0.5426 - val_accuracy: 0.9714 - val_precision: 0.9189 - val_recall: 0.9714\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 4s 361ms/step - loss: 0.7418 - accuracy: 0.7566 - precision: 0.7628 - recall: 0.7585 - val_loss: 0.3302 - val_accuracy: 0.9714 - val_precision: 0.9706 - val_recall: 0.9429\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 3s 286ms/step - loss: 0.6926 - accuracy: 0.7887 - precision: 0.7790 - recall: 0.7849 - val_loss: 0.3095 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 200ms/step - loss: 0.6471 - accuracy: 0.8358 - precision: 0.8336 - recall: 0.8321 - val_loss: 0.3711 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 0s 40ms/step - loss: 0.6014 - accuracy: 0.8245 - precision: 0.8298 - recall: 0.8189 - val_loss: 0.2222 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 3s 313ms/step - loss: 0.6068 - accuracy: 0.8283 - precision: 0.8289 - recall: 0.8226 - val_loss: 0.3097 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 0s 37ms/step - loss: 0.6123 - accuracy: 0.8340 - precision: 0.8358 - recall: 0.8358 - val_loss: 0.2910 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 1s 58ms/step - loss: 0.6178 - accuracy: 0.8113 - precision: 0.8144 - recall: 0.8113 - val_loss: 0.2305 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.5799 - accuracy: 0.8377 - precision: 0.8336 - recall: 0.8321 - val_loss: 0.2009 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Train on: [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "Test  on: 3\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 20:18:37.677858: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - ETA: 0s - loss: 1.0097 - accuracy: 0.5698 - precision: 0.5684 - recall: 0.5491"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 20:19:09.937431: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 36s 2s/step - loss: 1.0097 - accuracy: 0.5698 - precision: 0.5684 - recall: 0.5491 - val_loss: 0.6664 - val_accuracy: 0.7429 - val_precision: 0.7429 - val_recall: 0.7429\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 13s 1s/step - loss: 0.8854 - accuracy: 0.6755 - precision: 0.6810 - recall: 0.6566 - val_loss: 0.6135 - val_accuracy: 0.7143 - val_precision: 0.7188 - val_recall: 0.6571\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 3s 311ms/step - loss: 0.7568 - accuracy: 0.7717 - precision: 0.7635 - recall: 0.7491 - val_loss: 0.3844 - val_accuracy: 0.9429 - val_precision: 0.9706 - val_recall: 0.9429\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 184ms/step - loss: 0.6537 - accuracy: 0.8000 - precision: 0.8023 - recall: 0.7962 - val_loss: 0.2815 - val_accuracy: 0.9143 - val_precision: 0.9697 - val_recall: 0.9143\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 3s 291ms/step - loss: 0.6638 - accuracy: 0.8226 - precision: 0.8252 - recall: 0.8283 - val_loss: 0.2629 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 213ms/step - loss: 0.6274 - accuracy: 0.8113 - precision: 0.8083 - recall: 0.8113 - val_loss: 0.2803 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 184ms/step - loss: 0.5701 - accuracy: 0.8604 - precision: 0.8558 - recall: 0.8623 - val_loss: 0.2937 - val_accuracy: 0.9143 - val_precision: 0.9167 - val_recall: 0.9429\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 1s 93ms/step - loss: 0.6063 - accuracy: 0.8245 - precision: 0.8289 - recall: 0.8321 - val_loss: 0.3022 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 1s 56ms/step - loss: 0.5766 - accuracy: 0.8528 - precision: 0.8443 - recall: 0.8491 - val_loss: 0.2138 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 1s 62ms/step - loss: 0.5583 - accuracy: 0.8491 - precision: 0.8472 - recall: 0.8472 - val_loss: 0.3822 - val_accuracy: 0.8857 - val_precision: 0.8857 - val_recall: 0.8857\n",
      "Train on: [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "Test  on: 4\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 20:19:41.782098: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - ETA: 0s - loss: 0.9607 - accuracy: 0.6358 - precision: 0.6216 - recall: 0.6075"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 20:20:25.156547: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 47s 3s/step - loss: 0.9607 - accuracy: 0.6358 - precision: 0.6216 - recall: 0.6075 - val_loss: 0.5896 - val_accuracy: 0.8286 - val_precision: 0.8108 - val_recall: 0.8571\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 5s 415ms/step - loss: 0.8601 - accuracy: 0.6981 - precision: 0.6897 - recall: 0.6792 - val_loss: 0.5742 - val_accuracy: 0.7143 - val_precision: 0.7000 - val_recall: 0.6000\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 4s 385ms/step - loss: 0.7004 - accuracy: 0.7736 - precision: 0.7650 - recall: 0.7679 - val_loss: 0.2692 - val_accuracy: 0.9429 - val_precision: 0.9167 - val_recall: 0.9429\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 181ms/step - loss: 0.6749 - accuracy: 0.7906 - precision: 0.7841 - recall: 0.7811 - val_loss: 0.2526 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 4s 446ms/step - loss: 0.6321 - accuracy: 0.8321 - precision: 0.8327 - recall: 0.8264 - val_loss: 0.2662 - val_accuracy: 0.9429 - val_precision: 0.9412 - val_recall: 0.9143\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 188ms/step - loss: 0.6465 - accuracy: 0.8283 - precision: 0.8163 - recall: 0.8302 - val_loss: 0.2689 - val_accuracy: 0.9143 - val_precision: 0.9143 - val_recall: 0.9143\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 220ms/step - loss: 0.6022 - accuracy: 0.8245 - precision: 0.8199 - recall: 0.8245 - val_loss: 0.2707 - val_accuracy: 0.9143 - val_precision: 0.9143 - val_recall: 0.9143\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 1s 123ms/step - loss: 0.5906 - accuracy: 0.8377 - precision: 0.8371 - recall: 0.8340 - val_loss: 0.2100 - val_accuracy: 0.9143 - val_precision: 0.9143 - val_recall: 0.9143\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 1s 136ms/step - loss: 0.5890 - accuracy: 0.8245 - precision: 0.8258 - recall: 0.8321 - val_loss: 0.2226 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 3s 261ms/step - loss: 0.5444 - accuracy: 0.8358 - precision: 0.8337 - recall: 0.8226 - val_loss: 0.2179 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Train on: [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "Test  on: 5\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 20:20:54.771459: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - ETA: 0s - loss: 0.9617 - accuracy: 0.6113 - precision: 0.6217 - recall: 0.6264"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 20:21:35.965546: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 45s 3s/step - loss: 0.9617 - accuracy: 0.6113 - precision: 0.6217 - recall: 0.6264 - val_loss: 0.7163 - val_accuracy: 0.2857 - val_precision: 0.2941 - val_recall: 0.2857\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 10s 1s/step - loss: 0.8628 - accuracy: 0.7264 - precision: 0.7250 - recall: 0.7264 - val_loss: 0.7392 - val_accuracy: 0.2857 - val_precision: 0.2941 - val_recall: 0.2857\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 3s 325ms/step - loss: 0.7395 - accuracy: 0.7528 - precision: 0.7528 - recall: 0.7528 - val_loss: 0.2332 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 237ms/step - loss: 0.7181 - accuracy: 0.7623 - precision: 0.7686 - recall: 0.7585 - val_loss: 0.3196 - val_accuracy: 0.9143 - val_precision: 0.9143 - val_recall: 0.9143\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 1s 123ms/step - loss: 0.5972 - accuracy: 0.8434 - precision: 0.8447 - recall: 0.8415 - val_loss: 0.4087 - val_accuracy: 0.8857 - val_precision: 0.8857 - val_recall: 0.8857\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 3s 255ms/step - loss: 0.5858 - accuracy: 0.8283 - precision: 0.8231 - recall: 0.8340 - val_loss: 0.1893 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 1s 124ms/step - loss: 0.6365 - accuracy: 0.8377 - precision: 0.8302 - recall: 0.8302 - val_loss: 0.3486 - val_accuracy: 0.9143 - val_precision: 0.9143 - val_recall: 0.9143\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 1s 125ms/step - loss: 0.5996 - accuracy: 0.8377 - precision: 0.8349 - recall: 0.8396 - val_loss: 0.2606 - val_accuracy: 0.9143 - val_precision: 0.9143 - val_recall: 0.9143\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 0s 40ms/step - loss: 0.5537 - accuracy: 0.8547 - precision: 0.8528 - recall: 0.8528 - val_loss: 0.5358 - val_accuracy: 0.7429 - val_precision: 0.7429 - val_recall: 0.7429\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 1s 94ms/step - loss: 0.6055 - accuracy: 0.8302 - precision: 0.8264 - recall: 0.8264 - val_loss: 0.4857 - val_accuracy: 0.8286 - val_precision: 0.8286 - val_recall: 0.8286\n",
      "Train on: [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "Test  on: 6\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 20:22:04.575516: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - ETA: 0s - loss: 0.9847 - accuracy: 0.6132 - precision: 0.6106 - recall: 0.5887"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 20:22:43.290276: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 43s 3s/step - loss: 0.9847 - accuracy: 0.6132 - precision: 0.6106 - recall: 0.5887 - val_loss: 0.5682 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 10s 807ms/step - loss: 0.8541 - accuracy: 0.7321 - precision: 0.7151 - recall: 0.7340 - val_loss: 0.4130 - val_accuracy: 0.9429 - val_precision: 0.9706 - val_recall: 0.9429\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 243ms/step - loss: 0.7261 - accuracy: 0.7660 - precision: 0.7685 - recall: 0.7642 - val_loss: 0.3105 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 3s 268ms/step - loss: 0.6607 - accuracy: 0.8151 - precision: 0.8127 - recall: 0.8189 - val_loss: 0.2541 - val_accuracy: 0.9143 - val_precision: 0.9143 - val_recall: 0.9143\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 156ms/step - loss: 0.6393 - accuracy: 0.8226 - precision: 0.8153 - recall: 0.8245 - val_loss: 0.2856 - val_accuracy: 0.9143 - val_precision: 0.9143 - val_recall: 0.9143\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 169ms/step - loss: 0.6477 - accuracy: 0.8113 - precision: 0.7970 - recall: 0.8151 - val_loss: 0.2518 - val_accuracy: 0.9429 - val_precision: 0.9444 - val_recall: 0.9714\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 157ms/step - loss: 0.5936 - accuracy: 0.8377 - precision: 0.8302 - recall: 0.8396 - val_loss: 0.2190 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 1s 137ms/step - loss: 0.5792 - accuracy: 0.8415 - precision: 0.8408 - recall: 0.8472 - val_loss: 0.1986 - val_accuracy: 0.9429 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 4s 425ms/step - loss: 0.5838 - accuracy: 0.8283 - precision: 0.8284 - recall: 0.8377 - val_loss: 0.1996 - val_accuracy: 0.9143 - val_precision: 0.9143 - val_recall: 0.9143\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 1s 133ms/step - loss: 0.5283 - accuracy: 0.8415 - precision: 0.8399 - recall: 0.8415 - val_loss: 0.2044 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Train on: [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "Test  on: 7\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 20:23:16.481076: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - ETA: 0s - loss: 0.9806 - accuracy: 0.6283 - precision: 0.6308 - recall: 0.5868"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 20:23:53.799100: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 41s 2s/step - loss: 0.9806 - accuracy: 0.6283 - precision: 0.6308 - recall: 0.5868 - val_loss: 0.6966 - val_accuracy: 0.4286 - val_precision: 0.4783 - val_recall: 0.6286\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 14s 1s/step - loss: 0.8670 - accuracy: 0.6774 - precision: 0.6742 - recall: 0.6755 - val_loss: 0.4715 - val_accuracy: 0.7429 - val_precision: 0.7317 - val_recall: 0.8571\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 4s 359ms/step - loss: 0.7186 - accuracy: 0.7962 - precision: 0.7825 - recall: 0.7943 - val_loss: 0.3292 - val_accuracy: 0.8857 - val_precision: 0.8947 - val_recall: 0.9714\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 3s 331ms/step - loss: 0.6695 - accuracy: 0.8094 - precision: 0.8075 - recall: 0.8075 - val_loss: 0.2782 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 3s 319ms/step - loss: 0.7119 - accuracy: 0.7849 - precision: 0.7836 - recall: 0.7925 - val_loss: 0.3163 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 176ms/step - loss: 0.6020 - accuracy: 0.8340 - precision: 0.8374 - recall: 0.8358 - val_loss: 0.2265 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 3s 259ms/step - loss: 0.5951 - accuracy: 0.8472 - precision: 0.8412 - recall: 0.8396 - val_loss: 0.2780 - val_accuracy: 0.9143 - val_precision: 0.8889 - val_recall: 0.9143\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 1s 130ms/step - loss: 0.6256 - accuracy: 0.8113 - precision: 0.8045 - recall: 0.8151 - val_loss: 0.2538 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 1s 108ms/step - loss: 0.5550 - accuracy: 0.8491 - precision: 0.8539 - recall: 0.8491 - val_loss: 0.2942 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 1s 138ms/step - loss: 0.5966 - accuracy: 0.8396 - precision: 0.8399 - recall: 0.8415 - val_loss: 0.2153 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714\n",
      "Train on: [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15]\n",
      "Test  on: 8\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 20:24:31.103727: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - ETA: 0s - loss: 0.9945 - accuracy: 0.5671 - precision: 0.5787 - recall: 0.5142"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 20:25:12.847701: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 46s 3s/step - loss: 0.9945 - accuracy: 0.5671 - precision: 0.5787 - recall: 0.5142 - val_loss: 0.6588 - val_accuracy: 0.8056 - val_precision: 0.7857 - val_recall: 0.9167\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 9s 774ms/step - loss: 0.8805 - accuracy: 0.7089 - precision: 0.6968 - recall: 0.6994 - val_loss: 0.6374 - val_accuracy: 0.5556 - val_precision: 0.5526 - val_recall: 0.5833\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 5s 472ms/step - loss: 0.8070 - accuracy: 0.6881 - precision: 0.6751 - recall: 0.7032 - val_loss: 0.4886 - val_accuracy: 0.9722 - val_precision: 0.9459 - val_recall: 0.9722\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 222ms/step - loss: 0.6819 - accuracy: 0.7864 - precision: 0.7817 - recall: 0.7921 - val_loss: 0.2825 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 1s 73ms/step - loss: 0.6563 - accuracy: 0.8223 - precision: 0.8190 - recall: 0.8299 - val_loss: 0.3773 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 243ms/step - loss: 0.6115 - accuracy: 0.8185 - precision: 0.8129 - recall: 0.8129 - val_loss: 0.2242 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 214ms/step - loss: 0.6092 - accuracy: 0.8412 - precision: 0.8406 - recall: 0.8374 - val_loss: 0.2789 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.5915 - accuracy: 0.8223 - precision: 0.8240 - recall: 0.8318 - val_loss: 0.2728 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 1s 125ms/step - loss: 0.5827 - accuracy: 0.8469 - precision: 0.8447 - recall: 0.8431 - val_loss: 0.2794 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 1s 57ms/step - loss: 0.5652 - accuracy: 0.8412 - precision: 0.8336 - recall: 0.8431 - val_loss: 0.2556 - val_accuracy: 0.9167 - val_precision: 0.9167 - val_recall: 0.9167\n",
      "Train on: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15]\n",
      "Test  on: 9\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 20:25:42.261022: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - ETA: 0s - loss: 0.9617 - accuracy: 0.6200 - precision: 0.6435 - recall: 0.5766"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 20:26:22.398329: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 44s 3s/step - loss: 0.9617 - accuracy: 0.6200 - precision: 0.6435 - recall: 0.5766 - val_loss: 0.6664 - val_accuracy: 0.5833 - val_precision: 0.5676 - val_recall: 0.5833\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 6s 564ms/step - loss: 0.8506 - accuracy: 0.7146 - precision: 0.7077 - recall: 0.7278 - val_loss: 0.6577 - val_accuracy: 0.6667 - val_precision: 0.6765 - val_recall: 0.6389\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 8s 749ms/step - loss: 0.7337 - accuracy: 0.7618 - precision: 0.7560 - recall: 0.7732 - val_loss: 0.5634 - val_accuracy: 0.6111 - val_precision: 0.6154 - val_recall: 0.6667\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 3s 321ms/step - loss: 0.6637 - accuracy: 0.7940 - precision: 0.7955 - recall: 0.8015 - val_loss: 0.4871 - val_accuracy: 0.7500 - val_precision: 0.7297 - val_recall: 0.7500\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 214ms/step - loss: 0.6153 - accuracy: 0.8336 - precision: 0.8237 - recall: 0.8393 - val_loss: 0.6462 - val_accuracy: 0.7222 - val_precision: 0.6829 - val_recall: 0.7778\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 0.5862 - accuracy: 0.8431 - precision: 0.8445 - recall: 0.8318 - val_loss: 0.6317 - val_accuracy: 0.7778 - val_precision: 0.6905 - val_recall: 0.8056\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 1s 95ms/step - loss: 0.5568 - accuracy: 0.8488 - precision: 0.8414 - recall: 0.8526 - val_loss: 0.4304 - val_accuracy: 0.8056 - val_precision: 0.7619 - val_recall: 0.8889\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.6216 - accuracy: 0.8280 - precision: 0.8263 - recall: 0.8185 - val_loss: 0.4560 - val_accuracy: 0.7500 - val_precision: 0.6977 - val_recall: 0.8333\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 180ms/step - loss: 0.5426 - accuracy: 0.8677 - precision: 0.8627 - recall: 0.8790 - val_loss: 0.5042 - val_accuracy: 0.8056 - val_precision: 0.7692 - val_recall: 0.8333\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 165ms/step - loss: 0.5310 - accuracy: 0.8582 - precision: 0.8582 - recall: 0.8582 - val_loss: 0.6326 - val_accuracy: 0.8056 - val_precision: 0.7436 - val_recall: 0.8056\n",
      "Train on: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15]\n",
      "Test  on: 10\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 20:26:52.828795: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - ETA: 0s - loss: 0.9896 - accuracy: 0.5936 - precision: 0.5939 - recall: 0.5558"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 20:27:29.134226: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 40s 3s/step - loss: 0.9896 - accuracy: 0.5936 - precision: 0.5939 - recall: 0.5558 - val_loss: 0.5658 - val_accuracy: 0.9167 - val_precision: 0.9429 - val_recall: 0.9167\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 7s 710ms/step - loss: 0.8923 - accuracy: 0.6938 - precision: 0.7101 - recall: 0.6900 - val_loss: 0.4215 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 8s 756ms/step - loss: 0.8071 - accuracy: 0.7127 - precision: 0.7222 - recall: 0.7127 - val_loss: 0.2984 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 3s 295ms/step - loss: 0.7425 - accuracy: 0.7750 - precision: 0.7688 - recall: 0.7732 - val_loss: 0.3125 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 3s 321ms/step - loss: 0.6731 - accuracy: 0.8185 - precision: 0.8190 - recall: 0.8129 - val_loss: 0.3318 - val_accuracy: 0.9167 - val_precision: 0.9143 - val_recall: 0.8889\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 1s 130ms/step - loss: 0.5932 - accuracy: 0.8166 - precision: 0.8194 - recall: 0.8147 - val_loss: 0.3045 - val_accuracy: 0.8889 - val_precision: 0.8889 - val_recall: 0.8889\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 223ms/step - loss: 0.6292 - accuracy: 0.8299 - precision: 0.8243 - recall: 0.8336 - val_loss: 0.2869 - val_accuracy: 0.9444 - val_precision: 0.9714 - val_recall: 0.9444\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 1s 131ms/step - loss: 0.5998 - accuracy: 0.8204 - precision: 0.8248 - recall: 0.8185 - val_loss: 0.1415 - val_accuracy: 0.9722 - val_precision: 1.0000 - val_recall: 0.9722\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 3s 268ms/step - loss: 0.5446 - accuracy: 0.8299 - precision: 0.8356 - recall: 0.8261 - val_loss: 0.1387 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 3s 336ms/step - loss: 0.5756 - accuracy: 0.8355 - precision: 0.8372 - recall: 0.8261 - val_loss: 0.1691 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Train on: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15]\n",
      "Test  on: 11\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 20:28:06.552568: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - ETA: 0s - loss: 0.9417 - accuracy: 0.6181 - precision: 0.6185 - recall: 0.6314"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 20:28:49.107072: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 47s 3s/step - loss: 0.9417 - accuracy: 0.6181 - precision: 0.6185 - recall: 0.6314 - val_loss: 0.7774 - val_accuracy: 0.4722 - val_precision: 0.4571 - val_recall: 0.4444\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 7s 684ms/step - loss: 0.8005 - accuracy: 0.7316 - precision: 0.7268 - recall: 0.7391 - val_loss: 0.8419 - val_accuracy: 0.4722 - val_precision: 0.4722 - val_recall: 0.4722\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 3s 258ms/step - loss: 0.6710 - accuracy: 0.7940 - precision: 0.7841 - recall: 0.7826 - val_loss: 0.9639 - val_accuracy: 0.4722 - val_precision: 0.4722 - val_recall: 0.4722\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 3s 257ms/step - loss: 0.6417 - accuracy: 0.8204 - precision: 0.8177 - recall: 0.8223 - val_loss: 0.9047 - val_accuracy: 0.3611 - val_precision: 0.3611 - val_recall: 0.3611\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 215ms/step - loss: 0.5765 - accuracy: 0.8469 - precision: 0.8386 - recall: 0.8544 - val_loss: 0.8794 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5278\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 241ms/step - loss: 0.5596 - accuracy: 0.8601 - precision: 0.8585 - recall: 0.8601 - val_loss: 1.0480 - val_accuracy: 0.3611 - val_precision: 0.3611 - val_recall: 0.3611\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 172ms/step - loss: 0.5823 - accuracy: 0.8318 - precision: 0.8290 - recall: 0.8431 - val_loss: 0.8710 - val_accuracy: 0.4444 - val_precision: 0.4615 - val_recall: 0.5000\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 167ms/step - loss: 0.5173 - accuracy: 0.8677 - precision: 0.8710 - recall: 0.8677 - val_loss: 0.9998 - val_accuracy: 0.3889 - val_precision: 0.3889 - val_recall: 0.3889\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 1s 68ms/step - loss: 0.5203 - accuracy: 0.8563 - precision: 0.8544 - recall: 0.8544 - val_loss: 0.8770 - val_accuracy: 0.5278 - val_precision: 0.5278 - val_recall: 0.5278\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.4965 - accuracy: 0.8715 - precision: 0.8638 - recall: 0.8752 - val_loss: 0.9196 - val_accuracy: 0.4444 - val_precision: 0.4706 - val_recall: 0.4444\n",
      "Train on: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15]\n",
      "Test  on: 12\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 20:29:15.610669: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - ETA: 0s - loss: 0.9617 - accuracy: 0.6181 - precision: 0.6152 - recall: 0.6106"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 20:29:53.561873: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 42s 3s/step - loss: 0.9617 - accuracy: 0.6181 - precision: 0.6152 - recall: 0.6106 - val_loss: 0.6190 - val_accuracy: 0.7222 - val_precision: 0.7222 - val_recall: 0.7222\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 9s 820ms/step - loss: 0.8819 - accuracy: 0.7051 - precision: 0.6890 - recall: 0.6994 - val_loss: 0.4995 - val_accuracy: 0.6944 - val_precision: 0.6944 - val_recall: 0.6944\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 4s 389ms/step - loss: 0.7423 - accuracy: 0.7713 - precision: 0.7752 - recall: 0.7694 - val_loss: 0.3578 - val_accuracy: 0.8611 - val_precision: 0.8824 - val_recall: 0.8333\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 3s 309ms/step - loss: 0.6566 - accuracy: 0.7940 - precision: 0.7893 - recall: 0.8072 - val_loss: 0.2884 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 3s 324ms/step - loss: 0.6305 - accuracy: 0.8280 - precision: 0.8299 - recall: 0.8299 - val_loss: 0.3581 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 3s 286ms/step - loss: 0.6751 - accuracy: 0.7883 - precision: 0.7815 - recall: 0.7845 - val_loss: 0.2690 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 1s 111ms/step - loss: 0.6216 - accuracy: 0.8299 - precision: 0.8289 - recall: 0.8336 - val_loss: 0.2957 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 179ms/step - loss: 0.5681 - accuracy: 0.8412 - precision: 0.8330 - recall: 0.8299 - val_loss: 0.2483 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 1s 113ms/step - loss: 0.6064 - accuracy: 0.8336 - precision: 0.8314 - recall: 0.8299 - val_loss: 0.2383 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 1s 83ms/step - loss: 0.5831 - accuracy: 0.8355 - precision: 0.8410 - recall: 0.8299 - val_loss: 0.2061 - val_accuracy: 0.9722 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Train on: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15]\n",
      "Test  on: 13\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 20:30:25.484424: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - ETA: 0s - loss: 0.9617 - accuracy: 0.6673 - precision: 0.6505 - recall: 0.6578"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 20:31:06.734741: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 46s 3s/step - loss: 0.9617 - accuracy: 0.6673 - precision: 0.6505 - recall: 0.6578 - val_loss: 0.7501 - val_accuracy: 0.3889 - val_precision: 0.4054 - val_recall: 0.4167\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 8s 460ms/step - loss: 0.8035 - accuracy: 0.7429 - precision: 0.7451 - recall: 0.7240 - val_loss: 0.6850 - val_accuracy: 0.6111 - val_precision: 0.5862 - val_recall: 0.4722\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 229ms/step - loss: 0.7368 - accuracy: 0.7486 - precision: 0.7505 - recall: 0.7448 - val_loss: 0.6235 - val_accuracy: 0.6389 - val_precision: 0.6452 - val_recall: 0.5556\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 235ms/step - loss: 0.6323 - accuracy: 0.8242 - precision: 0.8201 - recall: 0.8185 - val_loss: 0.5160 - val_accuracy: 0.7778 - val_precision: 0.7436 - val_recall: 0.8056\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 165ms/step - loss: 0.6197 - accuracy: 0.8185 - precision: 0.8216 - recall: 0.8185 - val_loss: 0.5008 - val_accuracy: 0.7500 - val_precision: 0.7105 - val_recall: 0.7500\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 202ms/step - loss: 0.6277 - accuracy: 0.8261 - precision: 0.8232 - recall: 0.8185 - val_loss: 0.4539 - val_accuracy: 0.8333 - val_precision: 0.8286 - val_recall: 0.8056\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 3s 266ms/step - loss: 0.5658 - accuracy: 0.8620 - precision: 0.8620 - recall: 0.8620 - val_loss: 0.4451 - val_accuracy: 0.8056 - val_precision: 0.8056 - val_recall: 0.8056\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.6105 - accuracy: 0.8299 - precision: 0.8267 - recall: 0.8204 - val_loss: 0.4523 - val_accuracy: 0.9167 - val_precision: 0.9062 - val_recall: 0.8056\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 1s 138ms/step - loss: 0.5690 - accuracy: 0.8488 - precision: 0.8440 - recall: 0.8488 - val_loss: 0.3804 - val_accuracy: 0.9167 - val_precision: 0.9429 - val_recall: 0.9167\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 0.6339 - accuracy: 0.8261 - precision: 0.8258 - recall: 0.8242 - val_loss: 0.4489 - val_accuracy: 0.8889 - val_precision: 0.9143 - val_recall: 0.8889\n",
      "Train on: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15]\n",
      "Test  on: 14\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 20:31:33.842290: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - ETA: 0s - loss: 0.9859 - accuracy: 0.6163 - precision: 0.5996 - recall: 0.6087"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 20:32:09.471156: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 40s 2s/step - loss: 0.9859 - accuracy: 0.6163 - precision: 0.5996 - recall: 0.6087 - val_loss: 0.7102 - val_accuracy: 0.3056 - val_precision: 0.3056 - val_recall: 0.3056\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 14s 1s/step - loss: 0.8642 - accuracy: 0.6805 - precision: 0.6691 - recall: 0.6843 - val_loss: 0.6105 - val_accuracy: 0.7500 - val_precision: 0.7667 - val_recall: 0.6389\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 5s 472ms/step - loss: 0.7201 - accuracy: 0.7750 - precision: 0.7656 - recall: 0.7656 - val_loss: 0.6098 - val_accuracy: 0.5833 - val_precision: 0.5714 - val_recall: 0.5556\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 5s 527ms/step - loss: 0.6184 - accuracy: 0.8412 - precision: 0.8425 - recall: 0.8393 - val_loss: 0.7509 - val_accuracy: 0.4722 - val_precision: 0.4857 - val_recall: 0.4722\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 4s 203ms/step - loss: 0.5631 - accuracy: 0.8469 - precision: 0.8472 - recall: 0.8488 - val_loss: 0.7135 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.6667\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 1s 135ms/step - loss: 0.5817 - accuracy: 0.8658 - precision: 0.8582 - recall: 0.8582 - val_loss: 0.8780 - val_accuracy: 0.5556 - val_precision: 0.5676 - val_recall: 0.5833\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 1s 137ms/step - loss: 0.5673 - accuracy: 0.8507 - precision: 0.8544 - recall: 0.8431 - val_loss: 0.7426 - val_accuracy: 0.5833 - val_precision: 0.5882 - val_recall: 0.5556\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 1s 117ms/step - loss: 0.5461 - accuracy: 0.8677 - precision: 0.8721 - recall: 0.8639 - val_loss: 0.6915 - val_accuracy: 0.5833 - val_precision: 0.5714 - val_recall: 0.5556\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 1s 89ms/step - loss: 0.5281 - accuracy: 0.8715 - precision: 0.8745 - recall: 0.8696 - val_loss: 0.7493 - val_accuracy: 0.5000 - val_precision: 0.5135 - val_recall: 0.5278\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 1s 86ms/step - loss: 0.5327 - accuracy: 0.8696 - precision: 0.8674 - recall: 0.8658 - val_loss: 0.7440 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000\n",
      "Train on: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "Test  on: 15\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 20:32:47.820331: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - ETA: 0s - loss: 0.9408 - accuracy: 0.6623 - precision: 0.6577 - recall: 0.6491"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 20:33:28.012562: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 44s 3s/step - loss: 0.9408 - accuracy: 0.6623 - precision: 0.6577 - recall: 0.6491 - val_loss: 0.6734 - val_accuracy: 0.5714 - val_precision: 0.5882 - val_recall: 0.5714\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 8s 720ms/step - loss: 0.8280 - accuracy: 0.6774 - precision: 0.6925 - recall: 0.6925 - val_loss: 0.7628 - val_accuracy: 0.5714 - val_precision: 0.5758 - val_recall: 0.5429\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 3s 293ms/step - loss: 0.6837 - accuracy: 0.7868 - precision: 0.7805 - recall: 0.7717 - val_loss: 0.7197 - val_accuracy: 0.6286 - val_precision: 0.6286 - val_recall: 0.6286\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 1s 82ms/step - loss: 0.5660 - accuracy: 0.8509 - precision: 0.8544 - recall: 0.8415 - val_loss: 0.8568 - val_accuracy: 0.6286 - val_precision: 0.6286 - val_recall: 0.6286\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 3s 258ms/step - loss: 0.5514 - accuracy: 0.8340 - precision: 0.8388 - recall: 0.8245 - val_loss: 0.9194 - val_accuracy: 0.6286 - val_precision: 0.6286 - val_recall: 0.6286\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 1s 141ms/step - loss: 0.5004 - accuracy: 0.8528 - precision: 0.8536 - recall: 0.8472 - val_loss: 0.7870 - val_accuracy: 0.6286 - val_precision: 0.6286 - val_recall: 0.6286\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 5s 506ms/step - loss: 0.5132 - accuracy: 0.8585 - precision: 0.8555 - recall: 0.8491 - val_loss: 1.2364 - val_accuracy: 0.5714 - val_precision: 0.5758 - val_recall: 0.5429\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 3s 301ms/step - loss: 0.4750 - accuracy: 0.8774 - precision: 0.8790 - recall: 0.8774 - val_loss: 0.8016 - val_accuracy: 0.6286 - val_precision: 0.6286 - val_recall: 0.6286\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 1s 146ms/step - loss: 0.4903 - accuracy: 0.8755 - precision: 0.8774 - recall: 0.8774 - val_loss: 0.9069 - val_accuracy: 0.6286 - val_precision: 0.6286 - val_recall: 0.6286\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 155ms/step - loss: 0.4915 - accuracy: 0.8717 - precision: 0.8698 - recall: 0.8698 - val_loss: 0.7966 - val_accuracy: 0.6286 - val_precision: 0.6286 - val_recall: 0.6286\n"
     ]
    }
   ],
   "source": [
    "# for smart_os, signals in SMARTWATCH_OS.items():\n",
    "train(\"E4\", SIGNALS, all_subjects_X, all_subjects_y, DataType.CGAN, num_epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 19:26:36.040211: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 19:26:44.439652: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 19:26:51.687079: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 19:27:00.465593: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 19:27:07.808944: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 19:27:15.249665: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 19:27:23.560686: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 19:27:31.135153: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 19:27:39.359890: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 19:27:47.572158: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 19:27:54.469594: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 19:28:01.985607: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 19:28:09.397257: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 19:28:18.177501: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 19:28:25.721261: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smartwatch OS: E4\n",
      "Evaluation of CNN model trained on 10 epochs\n",
      "\n",
      "Subject\t\t Accuracy\tPrecision\tRecall\t\tF1-Score\n",
      "************************************************************************\n",
      "S2\t\t 0.82353\t0.82353\t\t0.82353\t\t0.82353\n",
      "S3\t\t 0.70588\t0.72727\t\t0.70588\t\t0.71642\n",
      "S4\t\t 0.97143\t0.97143\t\t0.97143\t\t0.97143\n",
      "S5\t\t 0.94286\t0.94286\t\t0.94286\t\t0.94286\n",
      "S6\t\t 0.94286\t0.91667\t\t0.94286\t\t0.92958\n",
      "S7\t\t 0.91429\t0.94118\t\t0.91429\t\t0.92754\n",
      "S8\t\t 0.94286\t0.96970\t\t0.91429\t\t0.94118\n",
      "S9\t\t 0.97143\t0.97143\t\t0.97143\t\t0.97143\n",
      "S10\t\t 0.91667\t0.91667\t\t0.91667\t\t0.91667\n",
      "S11\t\t 0.72222\t0.70270\t\t0.72222\t\t0.71233\n",
      "S13\t\t 0.97222\t0.97222\t\t0.97222\t\t0.97222\n",
      "S14\t\t 0.19444\t0.18919\t\t0.19444\t\t0.19178\n",
      "S15\t\t 0.97222\t0.97222\t\t0.97222\t\t0.97222\n",
      "S16\t\t 0.91667\t0.91429\t\t0.88889\t\t0.90141\n",
      "S17\t\t 0.55556\t0.54545\t\t0.50000\t\t0.52174\n",
      "************************************************************************\n",
      "Average\t\t 0.83101\t0.83179\t\t0.82355\t\t0.82749\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 19:28:33.002933: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 19:28:40.216472: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 19:28:48.637668: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 19:28:56.938644: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 19:29:04.961084: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 19:29:14.101968: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 19:29:22.654022: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 19:29:31.526145: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 19:29:39.357833: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 19:29:47.259057: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 19:29:55.702945: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 19:30:04.723636: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 19:30:13.499573: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 19:30:22.171891: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-25 19:30:30.901270: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smartwatch OS: E4_SYN\n",
      "Evaluation of CNN model trained on 10 epochs\n",
      "\n",
      "Subject\t\t Accuracy\tPrecision\tRecall\t\tF1-Score\n",
      "************************************************************************\n",
      "S2\t\t 0.91176\t0.91176\t\t0.91176\t\t0.91176\n",
      "S3\t\t 0.76471\t0.76471\t\t0.76471\t\t0.76471\n",
      "S4\t\t 0.97143\t0.97143\t\t0.97143\t\t0.97143\n",
      "S5\t\t 1.00000\t1.00000\t\t1.00000\t\t1.00000\n",
      "S6\t\t 0.94286\t0.94286\t\t0.94286\t\t0.94286\n",
      "S7\t\t 0.94286\t0.94286\t\t0.94286\t\t0.94286\n",
      "S8\t\t 0.97143\t0.97143\t\t0.97143\t\t0.97143\n",
      "S9\t\t 0.97143\t0.97143\t\t0.97143\t\t0.97143\n",
      "S10\t\t 0.97222\t0.97222\t\t0.97222\t\t0.97222\n",
      "S11\t\t 0.80556\t0.78378\t\t0.80556\t\t0.79452\n",
      "S13\t\t 0.97222\t0.97222\t\t0.97222\t\t0.97222\n",
      "S14\t\t 0.52778\t0.51351\t\t0.52778\t\t0.52055\n",
      "S15\t\t 0.97222\t0.97222\t\t0.97222\t\t0.97222\n",
      "S16\t\t 0.97222\t0.97222\t\t0.97222\t\t0.97222\n",
      "S17\t\t 0.66667\t0.66667\t\t0.66667\t\t0.66667\n",
      "************************************************************************\n",
      "Average\t\t 0.89102\t0.88862\t\t0.89102\t\t0.88981\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "# Evaluating every models on the corresponding test dataset not seen during training.\n",
    "os_scores_acc = {}\n",
    "os_scores_f1 = {}\n",
    "\n",
    "for smart_os, signals in SMARTWATCH_OS.items():\n",
    "    if \"SYN\" in smart_os:\n",
    "        evaluate(os_scores_acc, os_scores_f1, smart_os, signals, all_subjects_X, all_subjects_y, DataType.SYNTHETIC, num_epochs=num_epochs)\n",
    "    else:\n",
    "        evaluate(os_scores_acc, os_scores_f1, smart_os, signals, all_subjects_X, all_subjects_y, DataType.REAL, num_epochs=num_epochs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gretel synthetics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_PATH = 'data/wesad/wesad_preprocessed_64hz.csv'\n",
    "DATA_PATH = '/Users/nils/master/Stress-Detection-From-Wearables/data/WESAD'\n",
    "SYN_DATA_PATH = '/Users/nils/thesis/gretel-synthetics/src/syn_df_30000_1hz'\n",
    "SAMPLING_RATE = 1\n",
    "SUBJECT_IDS = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17]\n",
    "\n",
    "# df = pd.read_csv(DATA_PATH, index_col=0)\n",
    "# trainX, label_trainX = WESADDataset.create_windows(df, SAMPLING_RATE)\n",
    "\n",
    "syn_df = pd.read_csv(SYN_DATA_PATH, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_data = dataset.get_subject_dataframes(sampling_rate=SAMPLING_RATE)\n",
    "subjects_data['SYN'] = syn_df\n",
    "subjects_preprocessed_data = create_preprocessed_subjects_data(subjects_data, fs=SAMPLING_RATE)\n",
    "all_subjects_X, all_subjects_y = get_subject_window_data(subjects_preprocessed_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BVP</th>\n",
       "      <th>EDA</th>\n",
       "      <th>ACC_x</th>\n",
       "      <th>ACC_y</th>\n",
       "      <th>ACC_z</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.619737</td>\n",
       "      <td>0.295460</td>\n",
       "      <td>0.572373</td>\n",
       "      <td>0.775961</td>\n",
       "      <td>0.839140</td>\n",
       "      <td>0.979114</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.601685</td>\n",
       "      <td>0.060976</td>\n",
       "      <td>0.515926</td>\n",
       "      <td>0.183508</td>\n",
       "      <td>0.756277</td>\n",
       "      <td>0.428422</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.555147</td>\n",
       "      <td>0.839586</td>\n",
       "      <td>0.967286</td>\n",
       "      <td>0.341172</td>\n",
       "      <td>0.485396</td>\n",
       "      <td>0.668259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.566313</td>\n",
       "      <td>0.023452</td>\n",
       "      <td>0.891925</td>\n",
       "      <td>0.545660</td>\n",
       "      <td>0.583488</td>\n",
       "      <td>0.616938</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.384480</td>\n",
       "      <td>0.040064</td>\n",
       "      <td>0.228503</td>\n",
       "      <td>0.480697</td>\n",
       "      <td>0.159565</td>\n",
       "      <td>0.126774</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>0.734322</td>\n",
       "      <td>0.508121</td>\n",
       "      <td>0.265761</td>\n",
       "      <td>0.837071</td>\n",
       "      <td>0.669429</td>\n",
       "      <td>0.986866</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>0.618105</td>\n",
       "      <td>0.373451</td>\n",
       "      <td>0.491923</td>\n",
       "      <td>0.709599</td>\n",
       "      <td>0.872413</td>\n",
       "      <td>0.981580</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>0.507747</td>\n",
       "      <td>0.204751</td>\n",
       "      <td>0.932291</td>\n",
       "      <td>0.470586</td>\n",
       "      <td>0.458527</td>\n",
       "      <td>0.598324</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>0.552663</td>\n",
       "      <td>0.527488</td>\n",
       "      <td>0.671434</td>\n",
       "      <td>0.294088</td>\n",
       "      <td>0.047836</td>\n",
       "      <td>0.032211</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>0.523227</td>\n",
       "      <td>0.917195</td>\n",
       "      <td>0.916569</td>\n",
       "      <td>0.451211</td>\n",
       "      <td>0.503033</td>\n",
       "      <td>0.535491</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           BVP       EDA     ACC_x     ACC_y     ACC_z      TEMP  label\n",
       "0     0.619737  0.295460  0.572373  0.775961  0.839140  0.979114      0\n",
       "1     0.601685  0.060976  0.515926  0.183508  0.756277  0.428422      0\n",
       "2     0.555147  0.839586  0.967286  0.341172  0.485396  0.668259      1\n",
       "3     0.566313  0.023452  0.891925  0.545660  0.583488  0.616938      0\n",
       "4     0.384480  0.040064  0.228503  0.480697  0.159565  0.126774      1\n",
       "...        ...       ...       ...       ...       ...       ...    ...\n",
       "2495  0.734322  0.508121  0.265761  0.837071  0.669429  0.986866      0\n",
       "2496  0.618105  0.373451  0.491923  0.709599  0.872413  0.981580      0\n",
       "2497  0.507747  0.204751  0.932291  0.470586  0.458527  0.598324      0\n",
       "2498  0.552663  0.527488  0.671434  0.294088  0.047836  0.032211      1\n",
       "2499  0.523227  0.917195  0.916569  0.451211  0.503033  0.535491      1\n",
       "\n",
       "[2500 rows x 7 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjects_data['SYN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 14:53:09.400680: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 0.0000e+00 - accuracy: 0.3000 - precision: 0.3750 - recall: 0.3000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 14:53:12.735082: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 6s 6s/step - loss: 0.0000e+00 - accuracy: 0.3000 - precision: 0.3750 - recall: 0.3000 - val_loss: 0.6867 - val_accuracy: 0.7170 - val_precision: 0.7579 - val_recall: 0.6321\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 1s 914ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - precision: 0.4667 - recall: 0.3500 - val_loss: 0.6867 - val_accuracy: 0.7170 - val_precision: 0.7579 - val_recall: 0.6321\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 1s 508ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - precision: 0.4667 - recall: 0.3500 - val_loss: 0.6867 - val_accuracy: 0.7170 - val_precision: 0.7579 - val_recall: 0.6321\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 1s 680ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - precision: 0.4828 - recall: 0.3500 - val_loss: 0.6867 - val_accuracy: 0.7170 - val_precision: 0.7579 - val_recall: 0.6321\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - precision: 0.4688 - recall: 0.3750 - val_loss: 0.6867 - val_accuracy: 0.7170 - val_precision: 0.7579 - val_recall: 0.6321\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.0000e+00 - accuracy: 0.3750 - precision: 0.4643 - recall: 0.3250 - val_loss: 0.6867 - val_accuracy: 0.7170 - val_precision: 0.7579 - val_recall: 0.6321\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - precision: 0.4483 - recall: 0.3250 - val_loss: 0.6867 - val_accuracy: 0.7170 - val_precision: 0.7579 - val_recall: 0.6321\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - precision: 0.4839 - recall: 0.3750 - val_loss: 0.6867 - val_accuracy: 0.7170 - val_precision: 0.7579 - val_recall: 0.6321\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - precision: 0.4483 - recall: 0.3250 - val_loss: 0.6867 - val_accuracy: 0.7170 - val_precision: 0.7579 - val_recall: 0.6321\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - precision: 0.4483 - recall: 0.3250 - val_loss: 0.6867 - val_accuracy: 0.7170 - val_precision: 0.7579 - val_recall: 0.6321\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.0000e+00 - accuracy: 0.4000 - precision: 0.4667 - recall: 0.3500 - val_loss: 0.6867 - val_accuracy: 0.7170 - val_precision: 0.7579 - val_recall: 0.6321\n"
     ]
    }
   ],
   "source": [
    "# all_subjects_X_os = all_subjects_X\n",
    "# groups_set = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
    "# subject_ids = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17] # ids for subjects in WESAD dataset\n",
    "# num_signals = len(signals) # Number of signals in the WESAD dataset measured by the empatica e4\n",
    "# num_output_class = 2 # Number of output classes (2 - non-stress vs stress)\n",
    "# num_epochs = 100\n",
    "\n",
    "train_index = 15\n",
    "test_index = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
    "num_signals = 6 # Number of signals in the WESAD dataset measured by the empatica e4\n",
    "num_output_class = 2 # Number of output classes (2 - non-stress vs stress)\n",
    "num_epochs = 100\n",
    "\n",
    "print(train_index, test_index)\n",
    "\n",
    "# X_train = np.concatenate(np.array([all_subjects_X_os[x] for x in train_index], dtype=object))\n",
    "# y_train = np.concatenate(np.array([all_subjects_y[y] for y in train_index], dtype=object))\n",
    "# X_test = all_subjects_X_os[test_index]\n",
    "# y_test = all_subjects_y[test_index]\n",
    "\n",
    "X_train = all_subjects_X[train_index]\n",
    "y_train = all_subjects_y[train_index]\n",
    "X_test = np.concatenate(np.array([all_subjects_X[x] for x in test_index], dtype=object))\n",
    "y_test = np.concatenate(np.array([all_subjects_y[y] for y in test_index], dtype=object))\n",
    "\n",
    "weight_balance = y_train.tolist().count(0)/y_train.tolist().count(1)\n",
    "\n",
    "X_train = np.asarray(X_train)\n",
    "X_test = np.asarray(X_test)\n",
    "y_train = np.asarray(y_train)\n",
    "y_test = np.asarray(y_test)\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_output_class)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_output_class)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = build_model(num_signals, num_output_class)\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        # f\"models/{smart_os}/wesad_{smart_os}_binary_s{subject_ids[test_index]}_{num_epochs}.h5\",  # Path to save the model file\n",
    "        f\"models/{smart_os}/wesad_{smart_os}_binary_syn_gretel_{num_epochs}.h5\",  # Path to save the model file\n",
    "        monitor=\"loss\", # The metric name to monitor\n",
    "        save_best_only=True # If True, it only saves the \"best\" model according to the quantity monitored \n",
    "    ),\n",
    "    tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)  \n",
    "]\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    epochs=num_epochs, \n",
    "    batch_size=50,\n",
    "    verbose=1,\n",
    "    class_weight={0: 1, 1: weight_balance}, # to address the imbalance of the class labels\n",
    "    callbacks = callbacks,\n",
    "    validation_data=(X_test, y_test)\n",
    ")\n",
    "\n",
    "#     tuner.search(\n",
    "#         X_train, y_train,\n",
    "#         epochs=num_epochs, \n",
    "#         batch_size=50,\n",
    "#         verbose=2,\n",
    "#         class_weight={0: 1, 1: weight_balance}, # to address the imbalance of the class labels\n",
    "#         callbacks = callbacks,\n",
    "#         validation_data=(X_test, y_test)\n",
    "# )   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old Path: models/stress_detector/syn/dgan_30000/100/wesad_30000_s8.h5\n",
      "New Path: models/stress_detector/syn/dgan_30000/100/wesad_s8.h5\n",
      "\n",
      "Old Path: models/stress_detector/syn/dgan_30000/100/wesad_30000_s9.h5\n",
      "New Path: models/stress_detector/syn/dgan_30000/100/wesad_s9.h5\n",
      "\n",
      "Old Path: models/stress_detector/syn/dgan_30000/100/wesad_30000_s6.h5\n",
      "New Path: models/stress_detector/syn/dgan_30000/100/wesad_s6.h5\n",
      "\n",
      "Old Path: models/stress_detector/syn/dgan_30000/100/wesad_30000_sSYN.h5\n",
      "New Path: models/stress_detector/syn/dgan_30000/100/wesad_sSYN.h5\n",
      "\n",
      "Old Path: models/stress_detector/syn/dgan_30000/100/wesad_30000_s17.h5\n",
      "New Path: models/stress_detector/syn/dgan_30000/100/wesad_s17.h5\n",
      "\n",
      "Old Path: models/stress_detector/syn/dgan_30000/100/wesad_30000_s2.h5\n",
      "New Path: models/stress_detector/syn/dgan_30000/100/wesad_s2.h5\n",
      "\n",
      "Old Path: models/stress_detector/syn/dgan_30000/100/wesad_30000_s13.h5\n",
      "New Path: models/stress_detector/syn/dgan_30000/100/wesad_s13.h5\n",
      "\n",
      "Old Path: models/stress_detector/syn/dgan_30000/100/wesad_30000_s3.h5\n",
      "New Path: models/stress_detector/syn/dgan_30000/100/wesad_s3.h5\n",
      "\n",
      "Old Path: models/stress_detector/syn/dgan_30000/100/wesad_30000_s7.h5\n",
      "New Path: models/stress_detector/syn/dgan_30000/100/wesad_s7.h5\n",
      "\n",
      "Old Path: models/stress_detector/syn/dgan_30000/100/wesad_30000_s16.h5\n",
      "New Path: models/stress_detector/syn/dgan_30000/100/wesad_s16.h5\n",
      "\n",
      "Old Path: models/stress_detector/syn/dgan_30000/100/wesad_30000_s11.h5\n",
      "New Path: models/stress_detector/syn/dgan_30000/100/wesad_s11.h5\n",
      "\n",
      "Old Path: models/stress_detector/syn/dgan_30000/100/wesad_30000_s4.h5\n",
      "New Path: models/stress_detector/syn/dgan_30000/100/wesad_s4.h5\n",
      "\n",
      "Old Path: models/stress_detector/syn/dgan_30000/100/wesad_30000_s15.h5\n",
      "New Path: models/stress_detector/syn/dgan_30000/100/wesad_s15.h5\n",
      "\n",
      "Old Path: models/stress_detector/syn/dgan_30000/100/wesad_30000_s5.h5\n",
      "New Path: models/stress_detector/syn/dgan_30000/100/wesad_s5.h5\n",
      "\n",
      "Old Path: models/stress_detector/syn/dgan_30000/100/wesad_30000_s14.h5\n",
      "New Path: models/stress_detector/syn/dgan_30000/100/wesad_s14.h5\n",
      "\n",
      "Old Path: models/stress_detector/syn/dgan_30000/100/wesad_30000_s10.h5\n",
      "New Path: models/stress_detector/syn/dgan_30000/100/wesad_s10.h5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "directory = \"models/stress_detector/syn/dgan_30000/100\"\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.startswith(\"wesad_\"):\n",
    "        old_path = os.path.join(directory, filename)\n",
    "        print(f'Old Path: {old_path}')\n",
    "        new_filename = \"wesad_\" + filename.split(\"_\")[-1]\n",
    "        new_path = os.path.join(directory, new_filename)\n",
    "        print(f'New Path: {new_path}')\n",
    "        print(\"\")\n",
    "        os.rename(old_path, new_path)\n",
    "    #     old_path = os.path.join(directory, filename)\n",
    "    #     new_filename = \"wesad_\" + filename.split(\"_\")[-1]\n",
    "    #     new_path = os.path.join(directory, new_filename)\n",
    "    #     os.rename(old_path, new_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "c10594c322a1d947e8fe401957d564bca2bfab6035555ae665b20819d7ff0423"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
